{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c69a80a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf \n",
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5c6bb9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import math\n",
    "\n",
    "\n",
    "def merge(images, size):\n",
    "    # Extract the height and width dimensions of the images\n",
    "    h, w = images.shape[1], images.shape[2]\n",
    "\n",
    "    # Check if the images have 3 or 4 color channels (RGB or RGBA)\n",
    "    if (images.shape[3] in (3, 4)):\n",
    "        # Set the number of color channels\n",
    "        c = images.shape[3]  # size = 8 X 8 for 64 batch size\n",
    "\n",
    "        # Create an empty image grid with the specified size\n",
    "        img = np.zeros((h * size[0], w * size[1], c))\n",
    "\n",
    "        # Iterate over the images and place each image in the grid\n",
    "        for idx, image in enumerate(images):\n",
    "            i = idx % size[1]  # Calculate the column index of the grid\n",
    "            j = idx // size[1]  # Calculate the row index of the grid\n",
    "            img[j * h:j * h + h, i * w:i * w + w, :] = image\n",
    "\n",
    "        # Return the merged image grid\n",
    "        return img\n",
    "\n",
    "    # If the images have a single color channel\n",
    "    elif images.shape[3] == 1:\n",
    "        # Create an empty image grid without color channels\n",
    "        img = np.zeros((h * size[0], w * size[1]))\n",
    "\n",
    "        # Iterate over the images and place each image in the grid\n",
    "        for idx, image in enumerate(images):\n",
    "            i = idx % size[1]  # Calculate the column index of the grid\n",
    "            j = idx // size[1]  # Calculate the row index of the grid\n",
    "            img[j * h:j * h + h, i * w:i * w + w] = image[:, :, 0]\n",
    "\n",
    "        # Return the merged image grid\n",
    "        return img\n",
    "\n",
    "def image_manifold_size(num_images):\n",
    "    # Calculate the height and width dimensions of the image grid\n",
    "    manifold_h = int(np.floor(np.sqrt(num_images)))  # Rounded down square root of num_images\n",
    "    manifold_w = int(np.ceil(np.sqrt(num_images)))  # Rounded up square root of num_images\n",
    "\n",
    "    # Ensure that the product of height and width is equal to num_images\n",
    "    assert manifold_h * manifold_w == num_images\n",
    "\n",
    "    # Return the calculated dimensions of the image grid\n",
    "    return manifold_h, manifold_w\n",
    "\n",
    "def layout_point(final_pred, output_height, output_width):\n",
    "    # Reshape the final_pred tensor to shape [64, 128, 2]\n",
    "    bbox_pred = tf.reshape(final_pred, [64, 128, 2])\n",
    "\n",
    "    # Create a tensor with values ranging from 0 to output_width - 1\n",
    "    x_r = tf.reshape(tf.range(output_width, dtype=tf.float32),\n",
    "                     [1, output_width, 1, 1])\n",
    "    x_r = tf.reshape(tf.tile(x_r, [1, 1, output_width, 1]), [\n",
    "                     1, output_width * output_width, 1, 1])\n",
    "    x_r = tf.tile(x_r, [64, 1, 128, 1])\n",
    "\n",
    "    # Create a tensor with values ranging from 0 to output_height - 1\n",
    "    y_r = tf.reshape(tf.range(output_height, dtype=tf.float32), [\n",
    "                     1, 1, output_height, 1])\n",
    "    y_r = tf.reshape(tf.tile(y_r, [1, output_height, 1, 1]), [\n",
    "                     1, output_height * output_height, 1, 1])\n",
    "    y_r = tf.tile(y_r, [64, 1, 128, 1])\n",
    "\n",
    "    # Extract the x-coordinates from bbox_pred and scale them\n",
    "    x_pred = tf.reshape(\n",
    "        tf.slice(bbox_pred, [0, 0, 0], [-1, -1, 1]), [64, 1, 128, 1])\n",
    "    x_pred = tf.tile(x_pred, [1, output_width * output_width, 1, 1])\n",
    "    x_pred = (output_width - 1.0) * x_pred\n",
    "\n",
    "    # Extract the y-coordinates from bbox_pred and scale them\n",
    "    y_pred = tf.reshape(\n",
    "        tf.slice(bbox_pred, [0, 0, 1], [-1, -1, 1]), [64, 1, 128, 1])\n",
    "    y_pred = tf.tile(y_pred, [1, output_height * output_height, 1, 1])\n",
    "    y_pred = (output_height - 1.0) * y_pred\n",
    "\n",
    "    # Calculate the difference between x_r and x_pred, and clamp it between 0 and 1\n",
    "    x_diff = tf.maximum(0.0, 1.0 - tf.abs(x_r - x_pred))\n",
    "\n",
    "    # Calculate the difference between y_r and y_pred, and clamp it between 0 and 1\n",
    "    y_diff = tf.maximum(0.0, 1.0 - tf.abs(y_r - y_pred))\n",
    "\n",
    "    # Calculate the element-wise product of x_diff and y_diff\n",
    "    xy_diff = x_diff * y_diff\n",
    "\n",
    "    # Perform max pooling on xy_diff with a kernel size of [1, 1, 128, 1] and strides [1, 1, 1, 1]\n",
    "    xy_max = tf.nn.max_pool(xy_diff, ksize=[1, 1, 128, 1], strides=[\n",
    "                            1, 1, 1, 1], padding='VALID')\n",
    "\n",
    "    # Reshape the resulting tensor to [64, output_height, output_width, 1]\n",
    "    xy_max = tf.reshape(xy_max, [64, output_height, output_width, 1])\n",
    "\n",
    "    # Return the final result\n",
    "    return xy_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8373db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import math\n",
    "from glob import glob\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random\n",
    "#from mnist_utils import *\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "class RelationModule(tf.keras.Model):\n",
    "    def __init__(self, channels=128, output_dim=128, key_dim=128, **kwargs):\n",
    "        super(RelationModule, self).__init__(**kwargs)\n",
    "        self.key_dim = key_dim  # Dimension of the key feature\n",
    "        self.output_dim = output_dim  # Dimension of the output feature\n",
    "        self.channels = channels  # Number of channels in the input\n",
    "\n",
    "        # Define the convolutional layers\n",
    "        self.key = tf.keras.layers.Conv2D(\n",
    "            output_dim, (1, 1), strides=(1, 1), padding='valid')  # Key convolutional layer\n",
    "        self.query = tf.keras.layers.Conv2D(\n",
    "            key_dim, (1, 1), strides=(1, 1), padding='valid')  # Query convolutional layer\n",
    "        self.value = tf.keras.layers.Conv2D(\n",
    "            key_dim, (1, 1), strides=(1, 1), padding='valid')  # Value convolutional layer\n",
    "        self.projection = tf.keras.layers.Conv2D(\n",
    "            channels, (1, 1), strides=(1, 1), padding='valid')  # Projection convolutional layer\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # Reshape inputs to match the shape expected by the convolutional layers\n",
    "        f_k = tf.reshape(self.key(inputs), [\n",
    "                        inputs.shape[0], inputs.shape[1]*inputs.shape[2], self.key_dim])\n",
    "        f_q = tf.reshape(self.query(inputs), [\n",
    "                        inputs.shape[0], inputs.shape[1]*inputs.shape[2], self.key_dim])\n",
    "\n",
    "        # Transpose f_q to perform matrix multiplication\n",
    "        f_q = tf.transpose(f_q, perm=[0, 2, 1])\n",
    "\n",
    "        # Reshape the value inputs\n",
    "        f_v = tf.reshape(self.value(inputs), [\n",
    "                        inputs.shape[0], inputs.shape[1]*inputs.shape[2], self.output_dim])\n",
    "\n",
    "        # Compute attention weight using matrix multiplication and scaling\n",
    "        attention_weight = tf.matmul(\n",
    "            f_k, f_q)/math.sqrt(inputs.shape[1]*inputs.shape[2])\n",
    "\n",
    "        # Apply attention weights to the value inputs\n",
    "        out = tf.matmul(tf.transpose(attention_weight, perm=[0, 2, 1]), f_v)\n",
    "\n",
    "        # Reshape the output tensor\n",
    "        out = tf.reshape(\n",
    "            out, [inputs.shape[0], inputs.shape[1], inputs.shape[2], self.output_dim])\n",
    "\n",
    "        # Apply projection convolutional layer to the output tensor\n",
    "        out = self.projection(out)\n",
    "\n",
    "        # Return the output tensor\n",
    "        return out\n",
    "\n",
    "\n",
    "\n",
    "class Discriminator(tf.keras.Model):\n",
    "    def __init__(self, n_filters=32, n_hidden=128, layout_dim=(28, 28), render=layout_point, **kwargs):\n",
    "        super(Discriminator, self).__init__(**kwargs)\n",
    "        \n",
    "        # Initialize the discriminator with the provided parameters\n",
    "        self.layout_dim = layout_dim\n",
    "        self.render = render\n",
    "        self.act = tf.keras.layers.LeakyReLU()\n",
    "        \n",
    "        # Define the convolutional layers\n",
    "        self.conv1 = tf.keras.layers.Conv2D(\n",
    "            n_filters, (5, 5), input_shape=layout_dim, strides=(2, 2), padding='valid')\n",
    "        self.bn1 = tf.keras.layers.BatchNormalization()\n",
    "\n",
    "        self.conv2 = tf.keras.layers.Conv2D(\n",
    "            n_filters*2, (5, 5), strides=(2, 2), padding='valid')\n",
    "        self.bn2 = tf.keras.layers.BatchNormalization()\n",
    "        self.bn3 = tf.keras.layers.BatchNormalization()\n",
    "\n",
    "        # Flatten the feature maps\n",
    "        self.flatten = tf.keras.layers.Flatten()\n",
    "        \n",
    "        # Define the fully connected layers\n",
    "        self.fc1 = tf.keras.layers.Dense(512)\n",
    "        self.bn4 = tf.keras.layers.BatchNormalization()\n",
    "        self.fc2 = tf.keras.layers.Dense(1)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # Render the inputs using the specified layout dimensions\n",
    "        x = self.render(inputs, self.layout_dim[0], self.layout_dim[1])\n",
    "        \n",
    "        # Apply the activation, convolution, and batch normalization operations\n",
    "        x = self.act(self.bn1(self.conv1(x)))\n",
    "        x = self.act(self.bn2(self.conv2(x)))\n",
    "        \n",
    "        # Flatten the feature maps\n",
    "        x = self.flatten(x)\n",
    "        \n",
    "        # Apply the activation, fully connected, and batch normalization operations\n",
    "        x = self.act(self.bn4(self.fc1(x)))\n",
    "        \n",
    "        # Generate the discriminator output\n",
    "        out = self.fc2(x)\n",
    "        \n",
    "        # Return the output tensor\n",
    "        return out\n",
    "\n",
    "\n",
    "class Generator(tf.keras.Model):\n",
    "    def __init__(self, n_filters=128, output_dim=2, n_component=128, n_class=1, include_probability=False, **kwargs):\n",
    "        super(Generator, self).__init__(**kwargs)\n",
    "        \n",
    "        # Initialize the Generator with the provided parameters\n",
    "        self.n_filters = n_filters\n",
    "        self.output_dim = output_dim\n",
    "        self.n_component = n_component\n",
    "        self.n_class = n_class\n",
    "        self.include_probability = include_probability\n",
    "\n",
    "        self.act = tf.keras.layers.ReLU()\n",
    "        \n",
    "        # Define the first set of convolutional layers\n",
    "        self.conv1_1 = tf.keras.layers.Conv2D(n_filters, (1, 1), input_shape=(\n",
    "            self.n_component, self.n_class, self.output_dim), strides=(1, 1), padding='valid')\n",
    "        self.bn1_1 = tf.keras.layers.BatchNormalization()\n",
    "        self.conv1_2 = tf.keras.layers.Conv2D(\n",
    "            n_filters//4, (1, 1), strides=(1, 1), padding='valid')\n",
    "        self.bn1_2 = tf.keras.layers.BatchNormalization()\n",
    "        self.conv1_3 = tf.keras.layers.Conv2D(\n",
    "            n_filters//4, (1, 1), strides=(1, 1), padding='valid')\n",
    "        self.bn1_3 = tf.keras.layers.BatchNormalization()\n",
    "        self.conv1_4 = tf.keras.layers.Conv2D(\n",
    "            n_filters, (1, 1), strides=(1, 1), padding='valid')\n",
    "        self.bn1_4 = tf.keras.layers.BatchNormalization()\n",
    "\n",
    "        # Define the relation modules\n",
    "        self.relation1 = RelationModule(\n",
    "            channels=n_class*n_filters, output_dim=n_filters, key_dim=n_filters)\n",
    "        self.relation2 = RelationModule(\n",
    "            channels=n_class*n_filters, output_dim=n_filters, key_dim=n_filters)\n",
    "        self.bn_x1 = tf.keras.layers.BatchNormalization()\n",
    "        self.bn_x2 = tf.keras.layers.BatchNormalization()\n",
    "        self.bn_x3 = tf.keras.layers.BatchNormalization()\n",
    "        self.bn_x4 = tf.keras.layers.BatchNormalization()\n",
    "\n",
    "        # Define the second set of convolutional layers\n",
    "        self.conv2_1 = tf.keras.layers.Conv2D(\n",
    "            n_filters, (1, 1), strides=(1, 1), padding='valid')\n",
    "        self.bn2_1 = tf.keras.layers.BatchNormalization()\n",
    "        self.conv2_2 = tf.keras.layers.Conv2D(\n",
    "            n_filters//4, (1, 1), strides=(1, 1), padding='valid')\n",
    "        self.bn2_2 = tf.keras.layers.BatchNormalization()\n",
    "        self.conv2_3 = tf.keras.layers.Conv2D(\n",
    "            n_filters//4, (1, 1), strides=(1, 1), padding='valid')\n",
    "        self.bn2_3 = tf.keras.layers.BatchNormalization()\n",
    "        self.conv2_4 = tf.keras.layers.Conv2D(\n",
    "            n_filters, (1, 1), strides=(1, 1), padding='valid')\n",
    "        self.bn2_4 = tf.keras.layers.BatchNormalization()\n",
    "        \n",
    "        # Define the final geometric parameter output layer\n",
    "        self.geometric_param = tf.keras.layers.Conv2D(\n",
    "            output_dim, (1, 1), strides=(1, 1), padding='valid')\n",
    "        \n",
    "        # Define the final class score output layer\n",
    "        self.class_score = tf.keras.layers.Conv2D(\n",
    "            n_class, (1, 1), strides=(1, 1), padding='valid')\n",
    "\n",
    "    def call(self, x):\n",
    "        x = tf.reshape(x, [x.shape[0], self.n_component,\n",
    "                       self.n_class, self.output_dim])\n",
    "        \n",
    "        # Pass input through the first set of convolutional layers\n",
    "        h1_0 = self.bn1_1(self.conv1_1(x))\n",
    "        h1_1 = self.act(self.bn1_2(self.conv1_2(x)))\n",
    "        h1_2 = self.act(self.bn1_3(self.conv1_3(h1_1)))\n",
    "        h1_3 = self.act(self.bn1_4(self.conv1_4(h1_2)))\n",
    "\n",
    "        # Combine the outputs of the first set of layers\n",
    "        embedding = self.act(tf.add(h1_0, h1_3))\n",
    "        embedding = tf.reshape(\n",
    "            embedding, [x.shape[0], self.n_component, 1, -1])\n",
    "\n",
    "        # Pass the embedding through the relation modules\n",
    "        context = self.act(self.bn_x2(\n",
    "            tf.add(embedding, self.bn_x1(self.relation1(embedding)))))\n",
    "        context = self.act(self.bn_x4(\n",
    "            tf.add(context, self.bn_x3(self.relation2(context)))))\n",
    "\n",
    "        # Pass the context through the second set of convolutional layers\n",
    "        h2_0 = self.bn2_1(self.conv2_1(context))\n",
    "        h2_1 = self.act(self.bn2_2(self.conv2_2(h2_0)))\n",
    "        h2_2 = self.act(self.bn2_3(self.conv2_3(h2_1)))\n",
    "        h2_3 = self.act(self.bn2_4(self.conv2_4(h2_2)))\n",
    "\n",
    "        # Combine the outputs of the second set of layers\n",
    "        decoded = self.act(tf.add(h2_0, h2_3))\n",
    "        out = self.geometric_param(decoded)\n",
    "        out = tf.sigmoid(tf.reshape(\n",
    "            out, [-1, self.n_component, self.output_dim]))\n",
    "\n",
    "        # Add class score and probability if multiple classes are present\n",
    "        if(self.n_class > 1):\n",
    "            cls_score = self.class_score(decoded)\n",
    "            cls_prob = tf.sigmoid(tf.reshape(\n",
    "                cls_score, [-1, self.n_component, self.n_class]))\n",
    "            out = tf.concat([out, cls_prob], axis=-1)\n",
    "\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e301993",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\conda_temp/ipykernel_2608/1620466511.py:117: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  samples[img_ind, :, :]).astype(np.int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Sample] d_loss: 1.57420373, g_loss: 0.80555606\n",
      "Epoch: [ 0] [   8/1093] time: 7.8579, d_loss: 1.5308, g_loss: 0.7539\n",
      "[Sample] d_loss: 1.53612506, g_loss: 0.77451146\n",
      "Epoch: [ 0] [  18/1093] time: 11.6708, d_loss: 1.5533, g_loss: 0.7333\n",
      "[Sample] d_loss: 1.54320896, g_loss: 0.81375784\n",
      "Epoch: [ 0] [  28/1093] time: 15.5957, d_loss: 1.5270, g_loss: 0.7561\n",
      "[Sample] d_loss: 1.51309288, g_loss: 0.79589760\n",
      "Epoch: [ 0] [  38/1093] time: 19.4485, d_loss: 1.4945, g_loss: 0.7605\n",
      "[Sample] d_loss: 1.49149323, g_loss: 0.78128874\n",
      "Epoch: [ 0] [  48/1093] time: 23.3102, d_loss: 1.4937, g_loss: 0.7344\n",
      "[Sample] d_loss: 1.50405943, g_loss: 0.77403218\n",
      "Epoch: [ 0] [  58/1093] time: 27.1590, d_loss: 1.4827, g_loss: 0.7280\n",
      "[Sample] d_loss: 1.47901988, g_loss: 0.75979155\n",
      "Epoch: [ 0] [  68/1093] time: 31.0113, d_loss: 1.4800, g_loss: 0.7386\n",
      "[Sample] d_loss: 1.46684599, g_loss: 0.73672330\n",
      "Epoch: [ 0] [  78/1093] time: 34.9234, d_loss: 1.4739, g_loss: 0.7253\n",
      "[Sample] d_loss: 1.47104228, g_loss: 0.73887879\n",
      "Epoch: [ 0] [  88/1093] time: 38.8456, d_loss: 1.4475, g_loss: 0.7271\n",
      "[Sample] d_loss: 1.47287488, g_loss: 0.74757135\n",
      "Epoch: [ 0] [  98/1093] time: 42.7463, d_loss: 1.4945, g_loss: 0.7265\n",
      "[Sample] d_loss: 1.45876002, g_loss: 0.75588042\n",
      "Epoch: [ 0] [ 108/1093] time: 46.6504, d_loss: 1.4499, g_loss: 0.7288\n",
      "[Sample] d_loss: 1.45446253, g_loss: 0.72827333\n",
      "Epoch: [ 0] [ 118/1093] time: 50.5782, d_loss: 1.4588, g_loss: 0.7187\n",
      "[Sample] d_loss: 1.46899462, g_loss: 0.72673464\n",
      "Epoch: [ 0] [ 128/1093] time: 54.4595, d_loss: 1.4646, g_loss: 0.7195\n",
      "[Sample] d_loss: 1.45871472, g_loss: 0.74585378\n",
      "Epoch: [ 0] [ 138/1093] time: 58.3760, d_loss: 1.4440, g_loss: 0.7182\n",
      "[Sample] d_loss: 1.45244312, g_loss: 0.72620696\n",
      "Epoch: [ 0] [ 148/1093] time: 62.3073, d_loss: 1.4670, g_loss: 0.7200\n",
      "[Sample] d_loss: 1.44446492, g_loss: 0.73354352\n",
      "Epoch: [ 0] [ 158/1093] time: 66.4873, d_loss: 1.4346, g_loss: 0.7225\n",
      "[Sample] d_loss: 1.45984101, g_loss: 0.72736824\n",
      "Epoch: [ 0] [ 168/1093] time: 70.4652, d_loss: 1.4402, g_loss: 0.6948\n",
      "[Sample] d_loss: 1.43459380, g_loss: 0.74169284\n",
      "Epoch: [ 0] [ 178/1093] time: 74.4687, d_loss: 1.4192, g_loss: 0.7011\n",
      "[Sample] d_loss: 1.45055640, g_loss: 0.72454309\n",
      "Epoch: [ 0] [ 188/1093] time: 78.4655, d_loss: 1.4433, g_loss: 0.7189\n",
      "[Sample] d_loss: 1.44230485, g_loss: 0.74584240\n",
      "Epoch: [ 0] [ 198/1093] time: 82.3821, d_loss: 1.4393, g_loss: 0.7025\n",
      "[Sample] d_loss: 1.44087410, g_loss: 0.73242807\n",
      "Epoch: [ 0] [ 208/1093] time: 86.4140, d_loss: 1.4441, g_loss: 0.7136\n",
      "[Sample] d_loss: 1.42985249, g_loss: 0.72512794\n",
      "Epoch: [ 0] [ 218/1093] time: 90.3967, d_loss: 1.4355, g_loss: 0.7047\n",
      "[Sample] d_loss: 1.42641401, g_loss: 0.72767586\n",
      "Epoch: [ 0] [ 228/1093] time: 94.3441, d_loss: 1.4300, g_loss: 0.7092\n",
      "[Sample] d_loss: 1.42246103, g_loss: 0.73277056\n",
      "Epoch: [ 0] [ 238/1093] time: 98.4106, d_loss: 1.4500, g_loss: 0.7081\n",
      "[Sample] d_loss: 1.43085313, g_loss: 0.72664434\n",
      "Epoch: [ 0] [ 248/1093] time: 102.4659, d_loss: 1.4201, g_loss: 0.7043\n",
      "[Sample] d_loss: 1.43423641, g_loss: 0.73083764\n",
      "Epoch: [ 0] [ 258/1093] time: 106.6735, d_loss: 1.4524, g_loss: 0.7042\n",
      "[Sample] d_loss: 1.44386780, g_loss: 0.72348893\n",
      "Epoch: [ 0] [ 268/1093] time: 110.9184, d_loss: 1.4319, g_loss: 0.7035\n",
      "[Sample] d_loss: 1.42770886, g_loss: 0.73653525\n",
      "Epoch: [ 0] [ 278/1093] time: 115.4141, d_loss: 1.4259, g_loss: 0.7114\n",
      "[Sample] d_loss: 1.42942703, g_loss: 0.73757923\n",
      "Epoch: [ 0] [ 288/1093] time: 119.6615, d_loss: 1.4316, g_loss: 0.7076\n",
      "[Sample] d_loss: 1.42573190, g_loss: 0.72157258\n",
      "Epoch: [ 0] [ 298/1093] time: 124.0521, d_loss: 1.4372, g_loss: 0.6901\n",
      "[Sample] d_loss: 1.43738675, g_loss: 0.72593153\n",
      "Epoch: [ 0] [ 308/1093] time: 128.5989, d_loss: 1.4297, g_loss: 0.6904\n",
      "[Sample] d_loss: 1.41077638, g_loss: 0.72955304\n",
      "Epoch: [ 0] [ 318/1093] time: 132.9379, d_loss: 1.4095, g_loss: 0.7046\n",
      "[Sample] d_loss: 1.42481673, g_loss: 0.73385322\n",
      "Epoch: [ 0] [ 328/1093] time: 137.4561, d_loss: 1.3972, g_loss: 0.7202\n",
      "[Sample] d_loss: 1.42997909, g_loss: 0.72302985\n",
      "Epoch: [ 0] [ 338/1093] time: 141.8023, d_loss: 1.4206, g_loss: 0.7094\n",
      "[Sample] d_loss: 1.42316508, g_loss: 0.72147775\n",
      "Epoch: [ 0] [ 348/1093] time: 145.9540, d_loss: 1.4070, g_loss: 0.7080\n",
      "[Sample] d_loss: 1.42524993, g_loss: 0.74062228\n",
      "Epoch: [ 0] [ 358/1093] time: 150.2917, d_loss: 1.4143, g_loss: 0.6997\n",
      "[Sample] d_loss: 1.42654765, g_loss: 0.74189031\n",
      "Epoch: [ 0] [ 368/1093] time: 154.6825, d_loss: 1.4162, g_loss: 0.7132\n",
      "[Sample] d_loss: 1.42625451, g_loss: 0.72387224\n",
      "Epoch: [ 0] [ 378/1093] time: 159.1087, d_loss: 1.4107, g_loss: 0.7024\n",
      "[Sample] d_loss: 1.42044318, g_loss: 0.71790689\n",
      "Epoch: [ 0] [ 388/1093] time: 163.5964, d_loss: 1.4122, g_loss: 0.7060\n",
      "[Sample] d_loss: 1.41685081, g_loss: 0.72086090\n",
      "Epoch: [ 0] [ 398/1093] time: 167.9082, d_loss: 1.4334, g_loss: 0.7057\n",
      "[Sample] d_loss: 1.41977406, g_loss: 0.72880745\n",
      "Epoch: [ 0] [ 408/1093] time: 172.0217, d_loss: 1.3933, g_loss: 0.6987\n",
      "[Sample] d_loss: 1.41055012, g_loss: 0.72121060\n",
      "Epoch: [ 0] [ 418/1093] time: 176.1470, d_loss: 1.4203, g_loss: 0.7196\n",
      "[Sample] d_loss: 1.41342723, g_loss: 0.71947086\n",
      "Epoch: [ 0] [ 428/1093] time: 180.2733, d_loss: 1.4286, g_loss: 0.7079\n",
      "[Sample] d_loss: 1.41477251, g_loss: 0.72329235\n",
      "Epoch: [ 0] [ 438/1093] time: 184.5130, d_loss: 1.4124, g_loss: 0.6972\n",
      "[Sample] d_loss: 1.41529107, g_loss: 0.72400582\n",
      "Epoch: [ 0] [ 448/1093] time: 188.6975, d_loss: 1.4098, g_loss: 0.7058\n",
      "[Sample] d_loss: 1.40685856, g_loss: 0.73232913\n",
      "Epoch: [ 0] [ 458/1093] time: 193.0501, d_loss: 1.4172, g_loss: 0.7011\n",
      "[Sample] d_loss: 1.41214943, g_loss: 0.73341727\n",
      "Epoch: [ 0] [ 468/1093] time: 197.2907, d_loss: 1.4086, g_loss: 0.7119\n",
      "[Sample] d_loss: 1.41578805, g_loss: 0.72003126\n",
      "Epoch: [ 0] [ 478/1093] time: 201.4301, d_loss: 1.4237, g_loss: 0.7071\n",
      "[Sample] d_loss: 1.40428829, g_loss: 0.72653461\n",
      "Epoch: [ 0] [ 488/1093] time: 205.5941, d_loss: 1.4035, g_loss: 0.6979\n",
      "[Sample] d_loss: 1.41384923, g_loss: 0.72235990\n",
      "Epoch: [ 0] [ 498/1093] time: 209.7008, d_loss: 1.4238, g_loss: 0.7209\n",
      "[Sample] d_loss: 1.40867031, g_loss: 0.72079509\n",
      "Epoch: [ 0] [ 508/1093] time: 213.8055, d_loss: 1.4103, g_loss: 0.7058\n",
      "[Sample] d_loss: 1.40837646, g_loss: 0.72870672\n",
      "Epoch: [ 0] [ 518/1093] time: 217.9194, d_loss: 1.3997, g_loss: 0.7029\n",
      "[Sample] d_loss: 1.40826988, g_loss: 0.72780323\n",
      "Epoch: [ 0] [ 528/1093] time: 222.0904, d_loss: 1.4041, g_loss: 0.7003\n",
      "[Sample] d_loss: 1.40195346, g_loss: 0.71476901\n",
      "Epoch: [ 0] [ 538/1093] time: 226.3614, d_loss: 1.4052, g_loss: 0.7105\n",
      "[Sample] d_loss: 1.41069949, g_loss: 0.71988678\n",
      "Epoch: [ 0] [ 548/1093] time: 230.4878, d_loss: 1.4192, g_loss: 0.6960\n",
      "[Sample] d_loss: 1.40515661, g_loss: 0.72740734\n",
      "Epoch: [ 0] [ 558/1093] time: 234.6528, d_loss: 1.4211, g_loss: 0.6994\n",
      "[Sample] d_loss: 1.41279566, g_loss: 0.72508478\n",
      "Epoch: [ 0] [ 568/1093] time: 238.8075, d_loss: 1.4132, g_loss: 0.6982\n",
      "[Sample] d_loss: 1.41623521, g_loss: 0.71934831\n",
      "Epoch: [ 0] [ 578/1093] time: 242.9415, d_loss: 1.4200, g_loss: 0.6944\n",
      "[Sample] d_loss: 1.41466999, g_loss: 0.72417039\n",
      "Epoch: [ 0] [ 588/1093] time: 247.2011, d_loss: 1.3980, g_loss: 0.6989\n",
      "[Sample] d_loss: 1.42274010, g_loss: 0.71682853\n",
      "Epoch: [ 0] [ 598/1093] time: 251.2899, d_loss: 1.4022, g_loss: 0.7120\n",
      "[Sample] d_loss: 1.40404606, g_loss: 0.72430998\n",
      "Epoch: [ 0] [ 608/1093] time: 255.4915, d_loss: 1.3938, g_loss: 0.7031\n",
      "[Sample] d_loss: 1.39818633, g_loss: 0.72890174\n",
      "Epoch: [ 0] [ 618/1093] time: 259.6890, d_loss: 1.3995, g_loss: 0.7089\n",
      "[Sample] d_loss: 1.41099954, g_loss: 0.72322369\n",
      "Epoch: [ 0] [ 628/1093] time: 263.8439, d_loss: 1.4105, g_loss: 0.7146\n",
      "[Sample] d_loss: 1.39582920, g_loss: 0.73702562\n",
      "Epoch: [ 0] [ 638/1093] time: 268.2410, d_loss: 1.3979, g_loss: 0.7133\n",
      "[Sample] d_loss: 1.39824641, g_loss: 0.73264754\n",
      "Epoch: [ 0] [ 648/1093] time: 273.0699, d_loss: 1.3849, g_loss: 0.7058\n",
      "[Sample] d_loss: 1.39952374, g_loss: 0.73433566\n",
      "Epoch: [ 0] [ 658/1093] time: 277.3922, d_loss: 1.3928, g_loss: 0.7070\n",
      "[Sample] d_loss: 1.40702820, g_loss: 0.71990120\n",
      "Epoch: [ 0] [ 668/1093] time: 281.8805, d_loss: 1.4267, g_loss: 0.6989\n",
      "[Sample] d_loss: 1.40579557, g_loss: 0.72374415\n",
      "Epoch: [ 0] [ 678/1093] time: 286.4084, d_loss: 1.4128, g_loss: 0.7111\n",
      "[Sample] d_loss: 1.41341186, g_loss: 0.72577357\n",
      "Epoch: [ 0] [ 688/1093] time: 290.8359, d_loss: 1.4186, g_loss: 0.6923\n",
      "[Sample] d_loss: 1.39642251, g_loss: 0.74121213\n",
      "Epoch: [ 0] [ 698/1093] time: 295.0987, d_loss: 1.3956, g_loss: 0.7067\n",
      "[Sample] d_loss: 1.39732516, g_loss: 0.72802770\n",
      "Epoch: [ 0] [ 708/1093] time: 299.2159, d_loss: 1.4055, g_loss: 0.7045\n",
      "[Sample] d_loss: 1.40075076, g_loss: 0.71881366\n",
      "Epoch: [ 0] [ 718/1093] time: 303.3945, d_loss: 1.3928, g_loss: 0.6960\n",
      "[Sample] d_loss: 1.38625979, g_loss: 0.73133564\n",
      "Epoch: [ 0] [ 728/1093] time: 307.5915, d_loss: 1.4276, g_loss: 0.6993\n",
      "[Sample] d_loss: 1.39901423, g_loss: 0.72503340\n",
      "Epoch: [ 0] [ 738/1093] time: 311.8121, d_loss: 1.3855, g_loss: 0.7107\n",
      "[Sample] d_loss: 1.39867640, g_loss: 0.72637683\n",
      "Epoch: [ 0] [ 748/1093] time: 316.0501, d_loss: 1.3886, g_loss: 0.7210\n",
      "[Sample] d_loss: 1.40157032, g_loss: 0.73219824\n",
      "Epoch: [ 0] [ 758/1093] time: 320.3142, d_loss: 1.3935, g_loss: 0.7242\n",
      "[Sample] d_loss: 1.39924467, g_loss: 0.72663558\n",
      "Epoch: [ 0] [ 768/1093] time: 324.4798, d_loss: 1.4022, g_loss: 0.7051\n",
      "[Sample] d_loss: 1.40299892, g_loss: 0.71917117\n",
      "Epoch: [ 0] [ 778/1093] time: 328.6065, d_loss: 1.4103, g_loss: 0.7103\n",
      "[Sample] d_loss: 1.39396405, g_loss: 0.72970527\n",
      "Epoch: [ 0] [ 788/1093] time: 332.7088, d_loss: 1.3958, g_loss: 0.7074\n",
      "[Sample] d_loss: 1.41321802, g_loss: 0.70862049\n",
      "Epoch: [ 0] [ 798/1093] time: 336.7695, d_loss: 1.3901, g_loss: 0.7017\n",
      "[Sample] d_loss: 1.38807893, g_loss: 0.73341870\n",
      "Epoch: [ 0] [ 808/1093] time: 340.9130, d_loss: 1.3661, g_loss: 0.7042\n",
      "[Sample] d_loss: 1.40475702, g_loss: 0.71462488\n",
      "Epoch: [ 0] [ 818/1093] time: 345.0683, d_loss: 1.3953, g_loss: 0.7087\n",
      "[Sample] d_loss: 1.39162326, g_loss: 0.72520196\n",
      "Epoch: [ 0] [ 828/1093] time: 350.0037, d_loss: 1.3692, g_loss: 0.7122\n",
      "[Sample] d_loss: 1.38961017, g_loss: 0.71566737\n",
      "Epoch: [ 0] [ 838/1093] time: 355.3694, d_loss: 1.3889, g_loss: 0.7067\n",
      "[Sample] d_loss: 1.38800919, g_loss: 0.73228407\n",
      "Epoch: [ 0] [ 848/1093] time: 360.0109, d_loss: 1.3698, g_loss: 0.7060\n",
      "[Sample] d_loss: 1.41327834, g_loss: 0.71605825\n",
      "Epoch: [ 0] [ 858/1093] time: 364.7492, d_loss: 1.4103, g_loss: 0.7097\n",
      "[Sample] d_loss: 1.39168167, g_loss: 0.71810025\n",
      "Epoch: [ 0] [ 868/1093] time: 369.3084, d_loss: 1.4150, g_loss: 0.7018\n",
      "[Sample] d_loss: 1.39380598, g_loss: 0.72373837\n",
      "Epoch: [ 0] [ 878/1093] time: 373.7063, d_loss: 1.3900, g_loss: 0.7125\n",
      "[Sample] d_loss: 1.39615369, g_loss: 0.72488427\n",
      "Epoch: [ 0] [ 888/1093] time: 378.2383, d_loss: 1.3771, g_loss: 0.7036\n",
      "[Sample] d_loss: 1.39660454, g_loss: 0.72987592\n",
      "Epoch: [ 0] [ 898/1093] time: 382.8900, d_loss: 1.3920, g_loss: 0.7099\n",
      "[Sample] d_loss: 1.40013945, g_loss: 0.72041142\n",
      "Epoch: [ 0] [ 908/1093] time: 387.0984, d_loss: 1.3698, g_loss: 0.7176\n",
      "[Sample] d_loss: 1.37583113, g_loss: 0.73750222\n",
      "Epoch: [ 0] [ 918/1093] time: 391.3848, d_loss: 1.3778, g_loss: 0.7132\n",
      "[Sample] d_loss: 1.38578439, g_loss: 0.72848266\n",
      "Epoch: [ 0] [ 928/1093] time: 395.8210, d_loss: 1.4029, g_loss: 0.7066\n",
      "[Sample] d_loss: 1.38296294, g_loss: 0.72336709\n",
      "Epoch: [ 0] [ 938/1093] time: 400.2741, d_loss: 1.3903, g_loss: 0.7101\n",
      "[Sample] d_loss: 1.39314938, g_loss: 0.72606564\n",
      "Epoch: [ 0] [ 948/1093] time: 404.4610, d_loss: 1.4091, g_loss: 0.6987\n",
      "[Sample] d_loss: 1.38252234, g_loss: 0.72887123\n",
      "Epoch: [ 0] [ 958/1093] time: 408.7264, d_loss: 1.3786, g_loss: 0.6948\n",
      "[Sample] d_loss: 1.39317477, g_loss: 0.71778536\n",
      "Epoch: [ 0] [ 968/1093] time: 413.1366, d_loss: 1.3744, g_loss: 0.7143\n",
      "[Sample] d_loss: 1.38829517, g_loss: 0.72350848\n",
      "Epoch: [ 0] [ 978/1093] time: 417.4141, d_loss: 1.3741, g_loss: 0.7077\n",
      "[Sample] d_loss: 1.38510931, g_loss: 0.72658539\n",
      "Epoch: [ 0] [ 988/1093] time: 421.6233, d_loss: 1.3735, g_loss: 0.7155\n",
      "[Sample] d_loss: 1.38777626, g_loss: 0.72363466\n",
      "Epoch: [ 0] [ 998/1093] time: 425.8926, d_loss: 1.3706, g_loss: 0.7163\n",
      "[Sample] d_loss: 1.39941084, g_loss: 0.72966182\n",
      "Epoch: [ 0] [1008/1093] time: 430.0517, d_loss: 1.3916, g_loss: 0.7097\n",
      "[Sample] d_loss: 1.39449954, g_loss: 0.72036356\n",
      "Epoch: [ 0] [1018/1093] time: 434.3306, d_loss: 1.3909, g_loss: 0.7102\n",
      "[Sample] d_loss: 1.39234638, g_loss: 0.72182071\n",
      "Epoch: [ 0] [1028/1093] time: 438.6136, d_loss: 1.3793, g_loss: 0.7060\n",
      "[Sample] d_loss: 1.38171744, g_loss: 0.71606797\n",
      "Epoch: [ 0] [1038/1093] time: 443.0467, d_loss: 1.3712, g_loss: 0.7192\n",
      "[Sample] d_loss: 1.37631643, g_loss: 0.73404896\n",
      "Epoch: [ 0] [1048/1093] time: 447.3142, d_loss: 1.3861, g_loss: 0.7114\n",
      "[Sample] d_loss: 1.37731075, g_loss: 0.73968565\n",
      "Epoch: [ 0] [1058/1093] time: 451.5386, d_loss: 1.3938, g_loss: 0.7170\n",
      "[Sample] d_loss: 1.36505806, g_loss: 0.74184668\n",
      "Epoch: [ 0] [1068/1093] time: 455.7674, d_loss: 1.3845, g_loss: 0.7084\n",
      "[Sample] d_loss: 1.38833487, g_loss: 0.72364044\n",
      "Epoch: [ 0] [1078/1093] time: 459.9857, d_loss: 1.3954, g_loss: 0.7016\n",
      "[Sample] d_loss: 1.37340665, g_loss: 0.73401433\n",
      "Epoch: [ 0] [1088/1093] time: 464.2299, d_loss: 1.3668, g_loss: 0.7131\n",
      "[Sample] d_loss: 1.37924635, g_loss: 0.73219377\n",
      "[Sample] d_loss: 1.37827039, g_loss: 0.73207021\n",
      "Epoch: [ 1] [   5/1093] time: 468.5020, d_loss: 1.3461, g_loss: 0.7038\n",
      "[Sample] d_loss: 1.37347436, g_loss: 0.73249090\n",
      "Epoch: [ 1] [  15/1093] time: 472.9376, d_loss: 1.3648, g_loss: 0.7062\n",
      "[Sample] d_loss: 1.38820910, g_loss: 0.73846108\n",
      "Epoch: [ 1] [  25/1093] time: 477.1977, d_loss: 1.3788, g_loss: 0.7202\n",
      "[Sample] d_loss: 1.39176476, g_loss: 0.73052526\n",
      "Epoch: [ 1] [  35/1093] time: 481.3866, d_loss: 1.3753, g_loss: 0.7090\n",
      "[Sample] d_loss: 1.37366629, g_loss: 0.72963858\n",
      "Epoch: [ 1] [  45/1093] time: 485.5804, d_loss: 1.3693, g_loss: 0.7241\n",
      "[Sample] d_loss: 1.38063717, g_loss: 0.72425473\n",
      "Epoch: [ 1] [  55/1093] time: 489.8855, d_loss: 1.3651, g_loss: 0.7096\n",
      "[Sample] d_loss: 1.38280630, g_loss: 0.72808760\n",
      "Epoch: [ 1] [  65/1093] time: 494.1182, d_loss: 1.3749, g_loss: 0.7173\n",
      "[Sample] d_loss: 1.38428104, g_loss: 0.72439885\n",
      "Epoch: [ 1] [  75/1093] time: 498.3197, d_loss: 1.3807, g_loss: 0.7148\n",
      "[Sample] d_loss: 1.38385439, g_loss: 0.72500038\n",
      "Epoch: [ 1] [  85/1093] time: 502.6155, d_loss: 1.3938, g_loss: 0.7158\n",
      "[Sample] d_loss: 1.38110614, g_loss: 0.72853440\n",
      "Epoch: [ 1] [  95/1093] time: 506.9833, d_loss: 1.3543, g_loss: 0.7089\n",
      "[Sample] d_loss: 1.37476254, g_loss: 0.72518569\n",
      "Epoch: [ 1] [ 105/1093] time: 511.1992, d_loss: 1.3721, g_loss: 0.7082\n",
      "[Sample] d_loss: 1.38128042, g_loss: 0.72191656\n",
      "Epoch: [ 1] [ 115/1093] time: 515.4398, d_loss: 1.3937, g_loss: 0.7134\n",
      "[Sample] d_loss: 1.38502049, g_loss: 0.72489649\n",
      "Epoch: [ 1] [ 125/1093] time: 519.5733, d_loss: 1.3952, g_loss: 0.7040\n",
      "[Sample] d_loss: 1.37496376, g_loss: 0.72416770\n",
      "Epoch: [ 1] [ 135/1093] time: 523.7831, d_loss: 1.3682, g_loss: 0.7146\n",
      "[Sample] d_loss: 1.37831855, g_loss: 0.72363538\n",
      "Epoch: [ 1] [ 145/1093] time: 528.0850, d_loss: 1.3743, g_loss: 0.7227\n",
      "[Sample] d_loss: 1.37381196, g_loss: 0.72326493\n",
      "Epoch: [ 1] [ 155/1093] time: 532.3143, d_loss: 1.3766, g_loss: 0.7072\n",
      "[Sample] d_loss: 1.38593113, g_loss: 0.72681648\n",
      "Epoch: [ 1] [ 165/1093] time: 536.7278, d_loss: 1.3825, g_loss: 0.7061\n",
      "[Sample] d_loss: 1.36719990, g_loss: 0.74314916\n",
      "Epoch: [ 1] [ 175/1093] time: 541.0449, d_loss: 1.3860, g_loss: 0.7098\n",
      "[Sample] d_loss: 1.37597513, g_loss: 0.72915447\n",
      "Epoch: [ 1] [ 185/1093] time: 545.2047, d_loss: 1.4002, g_loss: 0.7071\n",
      "[Sample] d_loss: 1.38427591, g_loss: 0.71994132\n",
      "Epoch: [ 1] [ 195/1093] time: 549.3772, d_loss: 1.3730, g_loss: 0.7101\n",
      "[Sample] d_loss: 1.38568747, g_loss: 0.71242523\n",
      "Epoch: [ 1] [ 205/1093] time: 553.6126, d_loss: 1.3890, g_loss: 0.7087\n",
      "[Sample] d_loss: 1.37562978, g_loss: 0.73220152\n",
      "Epoch: [ 1] [ 215/1093] time: 557.9711, d_loss: 1.3608, g_loss: 0.7253\n",
      "[Sample] d_loss: 1.38012171, g_loss: 0.71962219\n",
      "Epoch: [ 1] [ 225/1093] time: 562.3117, d_loss: 1.3531, g_loss: 0.7264\n",
      "[Sample] d_loss: 1.37487590, g_loss: 0.73803818\n",
      "Epoch: [ 1] [ 235/1093] time: 566.7949, d_loss: 1.3731, g_loss: 0.7203\n",
      "[Sample] d_loss: 1.36827397, g_loss: 0.72970885\n",
      "Epoch: [ 1] [ 245/1093] time: 571.0105, d_loss: 1.3683, g_loss: 0.7100\n",
      "[Sample] d_loss: 1.36133766, g_loss: 0.73310977\n",
      "Epoch: [ 1] [ 255/1093] time: 575.2869, d_loss: 1.3723, g_loss: 0.7123\n",
      "[Sample] d_loss: 1.37928939, g_loss: 0.72312254\n",
      "Epoch: [ 1] [ 265/1093] time: 579.5013, d_loss: 1.3595, g_loss: 0.7205\n",
      "[Sample] d_loss: 1.37398875, g_loss: 0.72936660\n",
      "Epoch: [ 1] [ 275/1093] time: 583.6170, d_loss: 1.3797, g_loss: 0.7040\n",
      "[Sample] d_loss: 1.37622404, g_loss: 0.72222722\n",
      "Epoch: [ 1] [ 285/1093] time: 587.8115, d_loss: 1.3648, g_loss: 0.7175\n",
      "[Sample] d_loss: 1.37737381, g_loss: 0.73358577\n",
      "Epoch: [ 1] [ 295/1093] time: 592.0160, d_loss: 1.3728, g_loss: 0.7078\n",
      "[Sample] d_loss: 1.36311686, g_loss: 0.73521531\n",
      "Epoch: [ 1] [ 305/1093] time: 596.5657, d_loss: 1.3760, g_loss: 0.7182\n",
      "[Sample] d_loss: 1.36572921, g_loss: 0.73893178\n",
      "Epoch: [ 1] [ 315/1093] time: 600.9217, d_loss: 1.3735, g_loss: 0.7217\n",
      "[Sample] d_loss: 1.36632264, g_loss: 0.73571908\n",
      "Epoch: [ 1] [ 325/1093] time: 605.2271, d_loss: 1.3690, g_loss: 0.7087\n",
      "[Sample] d_loss: 1.37295091, g_loss: 0.72968554\n",
      "Epoch: [ 1] [ 335/1093] time: 609.3708, d_loss: 1.3669, g_loss: 0.7184\n",
      "[Sample] d_loss: 1.37539053, g_loss: 0.72126180\n",
      "Epoch: [ 1] [ 345/1093] time: 613.5414, d_loss: 1.3728, g_loss: 0.7059\n",
      "[Sample] d_loss: 1.35839009, g_loss: 0.73912895\n",
      "Epoch: [ 1] [ 355/1093] time: 617.6933, d_loss: 1.3697, g_loss: 0.7255\n",
      "[Sample] d_loss: 1.37576687, g_loss: 0.73752332\n",
      "Epoch: [ 1] [ 365/1093] time: 621.8884, d_loss: 1.3905, g_loss: 0.7177\n",
      "[Sample] d_loss: 1.36170769, g_loss: 0.72655082\n",
      "Epoch: [ 1] [ 375/1093] time: 626.1706, d_loss: 1.3537, g_loss: 0.7221\n",
      "[Sample] d_loss: 1.37246799, g_loss: 0.72277147\n",
      "Epoch: [ 1] [ 385/1093] time: 630.4897, d_loss: 1.3749, g_loss: 0.7197\n",
      "[Sample] d_loss: 1.36389339, g_loss: 0.72571695\n",
      "Epoch: [ 1] [ 395/1093] time: 634.7014, d_loss: 1.3639, g_loss: 0.7210\n",
      "[Sample] d_loss: 1.35946989, g_loss: 0.73541522\n",
      "Epoch: [ 1] [ 405/1093] time: 638.9074, d_loss: 1.3549, g_loss: 0.7148\n",
      "[Sample] d_loss: 1.35385513, g_loss: 0.73293197\n",
      "Epoch: [ 1] [ 415/1093] time: 643.1826, d_loss: 1.3467, g_loss: 0.7282\n",
      "[Sample] d_loss: 1.36596847, g_loss: 0.72451186\n",
      "Epoch: [ 1] [ 425/1093] time: 647.4532, d_loss: 1.3709, g_loss: 0.7134\n",
      "[Sample] d_loss: 1.37199759, g_loss: 0.73103458\n",
      "Epoch: [ 1] [ 435/1093] time: 651.6996, d_loss: 1.3616, g_loss: 0.7223\n",
      "[Sample] d_loss: 1.36129069, g_loss: 0.73370183\n",
      "Epoch: [ 1] [ 445/1093] time: 655.8849, d_loss: 1.3730, g_loss: 0.7271\n",
      "[Sample] d_loss: 1.35903144, g_loss: 0.73746669\n",
      "Epoch: [ 1] [ 455/1093] time: 660.3767, d_loss: 1.3915, g_loss: 0.7077\n",
      "[Sample] d_loss: 1.35046828, g_loss: 0.74823415\n",
      "Epoch: [ 1] [ 465/1093] time: 664.5958, d_loss: 1.3577, g_loss: 0.7208\n",
      "[Sample] d_loss: 1.35110855, g_loss: 0.73480666\n",
      "Epoch: [ 1] [ 475/1093] time: 668.8263, d_loss: 1.3744, g_loss: 0.7208\n",
      "[Sample] d_loss: 1.37286043, g_loss: 0.72002769\n",
      "Epoch: [ 1] [ 485/1093] time: 672.9979, d_loss: 1.3818, g_loss: 0.7127\n",
      "[Sample] d_loss: 1.36203480, g_loss: 0.72763109\n",
      "Epoch: [ 1] [ 495/1093] time: 677.2725, d_loss: 1.3521, g_loss: 0.7322\n",
      "[Sample] d_loss: 1.36139202, g_loss: 0.73812395\n",
      "Epoch: [ 1] [ 505/1093] time: 681.5285, d_loss: 1.3681, g_loss: 0.7142\n",
      "[Sample] d_loss: 1.36109900, g_loss: 0.72735190\n",
      "Epoch: [ 1] [ 515/1093] time: 685.7267, d_loss: 1.3729, g_loss: 0.7135\n",
      "[Sample] d_loss: 1.36869860, g_loss: 0.73078489\n",
      "Epoch: [ 1] [ 525/1093] time: 689.9951, d_loss: 1.3964, g_loss: 0.7109\n",
      "[Sample] d_loss: 1.36895788, g_loss: 0.73364443\n",
      "Epoch: [ 1] [ 535/1093] time: 694.4148, d_loss: 1.3449, g_loss: 0.7157\n",
      "[Sample] d_loss: 1.35029268, g_loss: 0.73964936\n",
      "Epoch: [ 1] [ 545/1093] time: 698.5381, d_loss: 1.3370, g_loss: 0.7271\n",
      "[Sample] d_loss: 1.36231041, g_loss: 0.73001397\n",
      "Epoch: [ 1] [ 555/1093] time: 702.8385, d_loss: 1.3530, g_loss: 0.7161\n",
      "[Sample] d_loss: 1.35349345, g_loss: 0.74276263\n",
      "Epoch: [ 1] [ 565/1093] time: 707.0451, d_loss: 1.3446, g_loss: 0.7300\n",
      "[Sample] d_loss: 1.35523403, g_loss: 0.72857744\n",
      "Epoch: [ 1] [ 575/1093] time: 711.3793, d_loss: 1.3360, g_loss: 0.7142\n",
      "[Sample] d_loss: 1.35683775, g_loss: 0.73063105\n",
      "Epoch: [ 1] [ 585/1093] time: 715.5486, d_loss: 1.3516, g_loss: 0.7205\n",
      "[Sample] d_loss: 1.35912657, g_loss: 0.72660458\n",
      "Epoch: [ 1] [ 595/1093] time: 719.8578, d_loss: 1.3539, g_loss: 0.7171\n",
      "[Sample] d_loss: 1.36933196, g_loss: 0.72332513\n",
      "Epoch: [ 1] [ 605/1093] time: 724.2576, d_loss: 1.3785, g_loss: 0.7054\n",
      "[Sample] d_loss: 1.35452151, g_loss: 0.73657590\n",
      "Epoch: [ 1] [ 615/1093] time: 728.4857, d_loss: 1.3446, g_loss: 0.7270\n",
      "[Sample] d_loss: 1.35477531, g_loss: 0.74013948\n",
      "Epoch: [ 1] [ 625/1093] time: 732.7210, d_loss: 1.3704, g_loss: 0.7035\n",
      "[Sample] d_loss: 1.34753060, g_loss: 0.73935992\n",
      "Epoch: [ 1] [ 635/1093] time: 736.9845, d_loss: 1.3444, g_loss: 0.7267\n",
      "[Sample] d_loss: 1.35513794, g_loss: 0.73079389\n",
      "Epoch: [ 1] [ 645/1093] time: 741.1223, d_loss: 1.3348, g_loss: 0.7278\n",
      "[Sample] d_loss: 1.34572077, g_loss: 0.74249327\n",
      "Epoch: [ 1] [ 655/1093] time: 745.3427, d_loss: 1.3536, g_loss: 0.7193\n",
      "[Sample] d_loss: 1.34397531, g_loss: 0.74476141\n",
      "Epoch: [ 1] [ 665/1093] time: 749.6018, d_loss: 1.3537, g_loss: 0.7219\n",
      "[Sample] d_loss: 1.35188937, g_loss: 0.74056274\n",
      "Epoch: [ 1] [ 675/1093] time: 754.1361, d_loss: 1.3581, g_loss: 0.7290\n",
      "[Sample] d_loss: 1.35841703, g_loss: 0.73229039\n",
      "Epoch: [ 1] [ 685/1093] time: 758.4194, d_loss: 1.3288, g_loss: 0.7309\n",
      "[Sample] d_loss: 1.36065841, g_loss: 0.72671568\n",
      "Epoch: [ 1] [ 695/1093] time: 762.6232, d_loss: 1.3561, g_loss: 0.7284\n",
      "[Sample] d_loss: 1.35054457, g_loss: 0.74019146\n",
      "Epoch: [ 1] [ 705/1093] time: 766.7784, d_loss: 1.3566, g_loss: 0.7196\n",
      "[Sample] d_loss: 1.35717165, g_loss: 0.73998851\n",
      "Epoch: [ 1] [ 715/1093] time: 770.9412, d_loss: 1.3509, g_loss: 0.7268\n",
      "[Sample] d_loss: 1.34757149, g_loss: 0.73516655\n",
      "Epoch: [ 1] [ 725/1093] time: 775.0714, d_loss: 1.3612, g_loss: 0.7229\n",
      "[Sample] d_loss: 1.34540772, g_loss: 0.74051803\n",
      "Epoch: [ 1] [ 735/1093] time: 779.3089, d_loss: 1.3597, g_loss: 0.7111\n",
      "[Sample] d_loss: 1.33901262, g_loss: 0.74894726\n",
      "Epoch: [ 1] [ 745/1093] time: 783.5732, d_loss: 1.3429, g_loss: 0.7253\n",
      "[Sample] d_loss: 1.36097884, g_loss: 0.72238624\n",
      "Epoch: [ 1] [ 755/1093] time: 787.9872, d_loss: 1.3612, g_loss: 0.7181\n",
      "[Sample] d_loss: 1.35349286, g_loss: 0.73361635\n",
      "Epoch: [ 1] [ 765/1093] time: 792.2720, d_loss: 1.3636, g_loss: 0.7139\n",
      "[Sample] d_loss: 1.34387755, g_loss: 0.73733395\n",
      "Epoch: [ 1] [ 775/1093] time: 796.4591, d_loss: 1.3621, g_loss: 0.7200\n",
      "[Sample] d_loss: 1.34119201, g_loss: 0.73542809\n",
      "Epoch: [ 1] [ 785/1093] time: 800.7870, d_loss: 1.3367, g_loss: 0.7194\n",
      "[Sample] d_loss: 1.34807396, g_loss: 0.73240453\n",
      "Epoch: [ 1] [ 795/1093] time: 804.9064, d_loss: 1.3368, g_loss: 0.7308\n",
      "[Sample] d_loss: 1.34467125, g_loss: 0.74629807\n",
      "Epoch: [ 1] [ 805/1093] time: 809.1040, d_loss: 1.3375, g_loss: 0.7139\n",
      "[Sample] d_loss: 1.34964204, g_loss: 0.74240768\n",
      "Epoch: [ 1] [ 815/1093] time: 813.3581, d_loss: 1.3739, g_loss: 0.7263\n",
      "[Sample] d_loss: 1.35526490, g_loss: 0.72868264\n",
      "Epoch: [ 1] [ 825/1093] time: 817.8762, d_loss: 1.3370, g_loss: 0.7294\n",
      "[Sample] d_loss: 1.34726906, g_loss: 0.73970979\n",
      "Epoch: [ 1] [ 835/1093] time: 822.1833, d_loss: 1.3423, g_loss: 0.7290\n",
      "[Sample] d_loss: 1.33394730, g_loss: 0.74144459\n",
      "Epoch: [ 1] [ 845/1093] time: 826.3939, d_loss: 1.3340, g_loss: 0.7245\n",
      "[Sample] d_loss: 1.34125853, g_loss: 0.74132466\n",
      "Epoch: [ 1] [ 855/1093] time: 830.7327, d_loss: 1.3508, g_loss: 0.7325\n",
      "[Sample] d_loss: 1.34073639, g_loss: 0.74493992\n",
      "Epoch: [ 1] [ 865/1093] time: 834.9219, d_loss: 1.3591, g_loss: 0.7218\n",
      "[Sample] d_loss: 1.34259081, g_loss: 0.73667395\n",
      "Epoch: [ 1] [ 875/1093] time: 839.1761, d_loss: 1.3391, g_loss: 0.7269\n",
      "[Sample] d_loss: 1.34346986, g_loss: 0.73139238\n",
      "Epoch: [ 1] [ 885/1093] time: 843.3851, d_loss: 1.3659, g_loss: 0.7080\n",
      "[Sample] d_loss: 1.33826113, g_loss: 0.74992216\n",
      "Epoch: [ 1] [ 895/1093] time: 847.7187, d_loss: 1.3428, g_loss: 0.7253\n",
      "[Sample] d_loss: 1.34476876, g_loss: 0.74188673\n",
      "Epoch: [ 1] [ 905/1093] time: 851.9688, d_loss: 1.3538, g_loss: 0.7279\n",
      "[Sample] d_loss: 1.33955526, g_loss: 0.74831283\n",
      "Epoch: [ 1] [ 915/1093] time: 856.2031, d_loss: 1.3481, g_loss: 0.7219\n",
      "[Sample] d_loss: 1.34562874, g_loss: 0.72545397\n",
      "Epoch: [ 1] [ 925/1093] time: 860.3848, d_loss: 1.3568, g_loss: 0.7083\n",
      "[Sample] d_loss: 1.34188104, g_loss: 0.74187160\n",
      "Epoch: [ 1] [ 935/1093] time: 864.5296, d_loss: 1.3352, g_loss: 0.7270\n",
      "[Sample] d_loss: 1.33889246, g_loss: 0.75008857\n",
      "Epoch: [ 1] [ 945/1093] time: 868.7253, d_loss: 1.3425, g_loss: 0.7243\n",
      "[Sample] d_loss: 1.34586978, g_loss: 0.73775828\n",
      "Epoch: [ 1] [ 955/1093] time: 872.9075, d_loss: 1.3611, g_loss: 0.7154\n",
      "[Sample] d_loss: 1.33260345, g_loss: 0.74401343\n",
      "Epoch: [ 1] [ 965/1093] time: 877.1665, d_loss: 1.3466, g_loss: 0.7198\n",
      "[Sample] d_loss: 1.33422565, g_loss: 0.74325579\n",
      "Epoch: [ 1] [ 975/1093] time: 881.5199, d_loss: 1.3190, g_loss: 0.7316\n",
      "[Sample] d_loss: 1.33078277, g_loss: 0.74782848\n",
      "Epoch: [ 1] [ 985/1093] time: 885.6891, d_loss: 1.3375, g_loss: 0.7335\n",
      "[Sample] d_loss: 1.33480585, g_loss: 0.73613274\n",
      "Epoch: [ 1] [ 995/1093] time: 889.8571, d_loss: 1.3576, g_loss: 0.7276\n",
      "[Sample] d_loss: 1.34129047, g_loss: 0.74317664\n",
      "Epoch: [ 1] [1005/1093] time: 894.1028, d_loss: 1.3476, g_loss: 0.7351\n",
      "[Sample] d_loss: 1.34382105, g_loss: 0.73710382\n",
      "Epoch: [ 1] [1015/1093] time: 898.3000, d_loss: 1.3442, g_loss: 0.7220\n",
      "[Sample] d_loss: 1.32999992, g_loss: 0.74763328\n",
      "Epoch: [ 1] [1025/1093] time: 902.5107, d_loss: 1.3577, g_loss: 0.7284\n",
      "[Sample] d_loss: 1.34138167, g_loss: 0.74130225\n",
      "Epoch: [ 1] [1035/1093] time: 906.6985, d_loss: 1.3356, g_loss: 0.7386\n",
      "[Sample] d_loss: 1.33529997, g_loss: 0.74424052\n",
      "Epoch: [ 1] [1045/1093] time: 911.1080, d_loss: 1.3393, g_loss: 0.7260\n",
      "[Sample] d_loss: 1.33217239, g_loss: 0.74835008\n",
      "Epoch: [ 1] [1055/1093] time: 915.3372, d_loss: 1.3629, g_loss: 0.7263\n",
      "[Sample] d_loss: 1.31953883, g_loss: 0.76008952\n",
      "Epoch: [ 1] [1065/1093] time: 919.5553, d_loss: 1.3381, g_loss: 0.7374\n",
      "[Sample] d_loss: 1.33428073, g_loss: 0.74186403\n",
      "Epoch: [ 1] [1075/1093] time: 923.8684, d_loss: 1.3497, g_loss: 0.7271\n",
      "[Sample] d_loss: 1.33007503, g_loss: 0.74888575\n",
      "Epoch: [ 1] [1085/1093] time: 928.0805, d_loss: 1.3380, g_loss: 0.7292\n",
      "[Sample] d_loss: 1.31773400, g_loss: 0.75602734\n",
      "[Sample] d_loss: 1.32078719, g_loss: 0.74481970\n",
      "Epoch: [ 2] [   2/1093] time: 932.4343, d_loss: 1.3272, g_loss: 0.7182\n",
      "[Sample] d_loss: 1.33975184, g_loss: 0.73325503\n",
      "Epoch: [ 2] [  12/1093] time: 936.5969, d_loss: 1.3050, g_loss: 0.7361\n",
      "[Sample] d_loss: 1.32893300, g_loss: 0.73986918\n",
      "Epoch: [ 2] [  22/1093] time: 940.9185, d_loss: 1.3577, g_loss: 0.7177\n",
      "[Sample] d_loss: 1.31993806, g_loss: 0.75410593\n",
      "Epoch: [ 2] [  32/1093] time: 945.1895, d_loss: 1.3439, g_loss: 0.7307\n",
      "[Sample] d_loss: 1.32688463, g_loss: 0.74125063\n",
      "Epoch: [ 2] [  42/1093] time: 949.4169, d_loss: 1.3100, g_loss: 0.7388\n",
      "[Sample] d_loss: 1.32454348, g_loss: 0.75312066\n",
      "Epoch: [ 2] [  52/1093] time: 953.6669, d_loss: 1.3495, g_loss: 0.7309\n",
      "[Sample] d_loss: 1.32792521, g_loss: 0.74649453\n",
      "Epoch: [ 2] [  62/1093] time: 957.8859, d_loss: 1.3253, g_loss: 0.7265\n",
      "[Sample] d_loss: 1.33092213, g_loss: 0.74193877\n",
      "Epoch: [ 2] [  72/1093] time: 962.2055, d_loss: 1.3651, g_loss: 0.7345\n",
      "[Sample] d_loss: 1.31761408, g_loss: 0.74927819\n",
      "Epoch: [ 2] [  82/1093] time: 966.4879, d_loss: 1.3468, g_loss: 0.7282\n",
      "[Sample] d_loss: 1.32379627, g_loss: 0.74899685\n",
      "Epoch: [ 2] [  92/1093] time: 971.0521, d_loss: 1.3459, g_loss: 0.7392\n",
      "[Sample] d_loss: 1.32284617, g_loss: 0.74975348\n",
      "Epoch: [ 2] [ 102/1093] time: 975.4908, d_loss: 1.3477, g_loss: 0.7339\n",
      "[Sample] d_loss: 1.32400656, g_loss: 0.74150115\n",
      "Epoch: [ 2] [ 112/1093] time: 979.8423, d_loss: 1.3298, g_loss: 0.7381\n",
      "[Sample] d_loss: 1.31776321, g_loss: 0.74796909\n",
      "Epoch: [ 2] [ 122/1093] time: 984.0551, d_loss: 1.3199, g_loss: 0.7303\n",
      "[Sample] d_loss: 1.32063293, g_loss: 0.74917579\n",
      "Epoch: [ 2] [ 132/1093] time: 988.2915, d_loss: 1.3453, g_loss: 0.7337\n",
      "[Sample] d_loss: 1.32239771, g_loss: 0.74585664\n",
      "Epoch: [ 2] [ 142/1093] time: 992.5220, d_loss: 1.3237, g_loss: 0.7334\n",
      "[Sample] d_loss: 1.32014573, g_loss: 0.75441098\n",
      "Epoch: [ 2] [ 152/1093] time: 996.8673, d_loss: 1.3252, g_loss: 0.7371\n",
      "[Sample] d_loss: 1.32948303, g_loss: 0.73816806\n",
      "Epoch: [ 2] [ 162/1093] time: 1001.2027, d_loss: 1.3063, g_loss: 0.7294\n",
      "[Sample] d_loss: 1.32597661, g_loss: 0.74263847\n",
      "Epoch: [ 2] [ 172/1093] time: 1005.5272, d_loss: 1.3591, g_loss: 0.7179\n",
      "[Sample] d_loss: 1.32309747, g_loss: 0.74628776\n",
      "Epoch: [ 2] [ 182/1093] time: 1009.7847, d_loss: 1.3221, g_loss: 0.7379\n",
      "[Sample] d_loss: 1.31467938, g_loss: 0.75237012\n",
      "Epoch: [ 2] [ 192/1093] time: 1014.0798, d_loss: 1.3133, g_loss: 0.7363\n",
      "[Sample] d_loss: 1.31681252, g_loss: 0.74441093\n",
      "Epoch: [ 2] [ 202/1093] time: 1018.2308, d_loss: 1.3402, g_loss: 0.7319\n",
      "[Sample] d_loss: 1.31621730, g_loss: 0.76276863\n",
      "Epoch: [ 2] [ 212/1093] time: 1022.5037, d_loss: 1.3461, g_loss: 0.7286\n",
      "[Sample] d_loss: 1.32428646, g_loss: 0.74863929\n",
      "Epoch: [ 2] [ 222/1093] time: 1026.7540, d_loss: 1.3566, g_loss: 0.7423\n",
      "[Sample] d_loss: 1.31989455, g_loss: 0.74937040\n",
      "Epoch: [ 2] [ 232/1093] time: 1031.0553, d_loss: 1.3397, g_loss: 0.7201\n",
      "[Sample] d_loss: 1.31548452, g_loss: 0.74349809\n",
      "Epoch: [ 2] [ 242/1093] time: 1035.4225, d_loss: 1.3448, g_loss: 0.7434\n",
      "[Sample] d_loss: 1.31465495, g_loss: 0.75134414\n",
      "Epoch: [ 2] [ 252/1093] time: 1039.6952, d_loss: 1.3547, g_loss: 0.7348\n",
      "[Sample] d_loss: 1.31024218, g_loss: 0.75648993\n",
      "Epoch: [ 2] [ 262/1093] time: 1044.0298, d_loss: 1.3277, g_loss: 0.7342\n",
      "[Sample] d_loss: 1.31625128, g_loss: 0.75186253\n",
      "Epoch: [ 2] [ 272/1093] time: 1048.2861, d_loss: 1.3504, g_loss: 0.7202\n",
      "[Sample] d_loss: 1.32367027, g_loss: 0.75287461\n",
      "Epoch: [ 2] [ 282/1093] time: 1052.5099, d_loss: 1.3009, g_loss: 0.7395\n",
      "[Sample] d_loss: 1.30846548, g_loss: 0.75149649\n",
      "Epoch: [ 2] [ 292/1093] time: 1056.7234, d_loss: 1.3296, g_loss: 0.7316\n",
      "[Sample] d_loss: 1.31531692, g_loss: 0.75360638\n",
      "Epoch: [ 2] [ 302/1093] time: 1060.9541, d_loss: 1.3418, g_loss: 0.7349\n",
      "[Sample] d_loss: 1.31663060, g_loss: 0.75694698\n",
      "Epoch: [ 2] [ 312/1093] time: 1065.2921, d_loss: 1.3280, g_loss: 0.7316\n",
      "[Sample] d_loss: 1.31573224, g_loss: 0.75779331\n",
      "Epoch: [ 2] [ 322/1093] time: 1069.5191, d_loss: 1.3252, g_loss: 0.7424\n",
      "[Sample] d_loss: 1.31337333, g_loss: 0.74969232\n",
      "Epoch: [ 2] [ 332/1093] time: 1073.8374, d_loss: 1.3374, g_loss: 0.7360\n",
      "[Sample] d_loss: 1.31218266, g_loss: 0.75392389\n",
      "Epoch: [ 2] [ 342/1093] time: 1078.1274, d_loss: 1.3487, g_loss: 0.7260\n",
      "[Sample] d_loss: 1.30813777, g_loss: 0.75139517\n",
      "Epoch: [ 2] [ 352/1093] time: 1082.3517, d_loss: 1.3407, g_loss: 0.7377\n",
      "[Sample] d_loss: 1.31287146, g_loss: 0.74633729\n",
      "Epoch: [ 2] [ 362/1093] time: 1086.5221, d_loss: 1.3147, g_loss: 0.7348\n",
      "[Sample] d_loss: 1.31189346, g_loss: 0.75610602\n",
      "Epoch: [ 2] [ 372/1093] time: 1090.7655, d_loss: 1.3343, g_loss: 0.7297\n",
      "[Sample] d_loss: 1.30619252, g_loss: 0.75154388\n",
      "Epoch: [ 2] [ 382/1093] time: 1095.2274, d_loss: 1.3148, g_loss: 0.7320\n",
      "[Sample] d_loss: 1.30343437, g_loss: 0.75320506\n",
      "Epoch: [ 2] [ 392/1093] time: 1099.5102, d_loss: 1.3247, g_loss: 0.7398\n",
      "[Sample] d_loss: 1.31120300, g_loss: 0.75216389\n",
      "Epoch: [ 2] [ 402/1093] time: 1103.8801, d_loss: 1.3202, g_loss: 0.7278\n",
      "[Sample] d_loss: 1.30790949, g_loss: 0.74865198\n",
      "Epoch: [ 2] [ 412/1093] time: 1108.1238, d_loss: 1.3446, g_loss: 0.7346\n",
      "[Sample] d_loss: 1.31257105, g_loss: 0.74690044\n",
      "Epoch: [ 2] [ 422/1093] time: 1112.3211, d_loss: 1.3080, g_loss: 0.7420\n",
      "[Sample] d_loss: 1.31493390, g_loss: 0.74162853\n",
      "Epoch: [ 2] [ 432/1093] time: 1116.5342, d_loss: 1.3258, g_loss: 0.7327\n",
      "[Sample] d_loss: 1.31696784, g_loss: 0.75281739\n",
      "Epoch: [ 2] [ 442/1093] time: 1120.7500, d_loss: 1.3134, g_loss: 0.7458\n",
      "[Sample] d_loss: 1.31077051, g_loss: 0.74570620\n",
      "Epoch: [ 2] [ 452/1093] time: 1125.0753, d_loss: 1.3237, g_loss: 0.7287\n",
      "[Sample] d_loss: 1.31161535, g_loss: 0.75368881\n",
      "Epoch: [ 2] [ 462/1093] time: 1129.4282, d_loss: 1.3263, g_loss: 0.7378\n",
      "[Sample] d_loss: 1.30016518, g_loss: 0.75996089\n",
      "Epoch: [ 2] [ 472/1093] time: 1133.6224, d_loss: 1.3087, g_loss: 0.7351\n",
      "[Sample] d_loss: 1.31414151, g_loss: 0.74628955\n",
      "Epoch: [ 2] [ 482/1093] time: 1137.8260, d_loss: 1.3200, g_loss: 0.7274\n",
      "[Sample] d_loss: 1.30391490, g_loss: 0.75204515\n",
      "Epoch: [ 2] [ 492/1093] time: 1142.0476, d_loss: 1.3019, g_loss: 0.7377\n",
      "[Sample] d_loss: 1.29691970, g_loss: 0.76450866\n",
      "Epoch: [ 2] [ 502/1093] time: 1146.1839, d_loss: 1.3111, g_loss: 0.7419\n",
      "[Sample] d_loss: 1.29317212, g_loss: 0.76229411\n",
      "Epoch: [ 2] [ 512/1093] time: 1150.3634, d_loss: 1.2921, g_loss: 0.7416\n",
      "[Sample] d_loss: 1.31081915, g_loss: 0.74837470\n",
      "Epoch: [ 2] [ 522/1093] time: 1154.5593, d_loss: 1.3110, g_loss: 0.7356\n",
      "[Sample] d_loss: 1.29847646, g_loss: 0.75737834\n",
      "Epoch: [ 2] [ 532/1093] time: 1158.7969, d_loss: 1.3349, g_loss: 0.7392\n",
      "[Sample] d_loss: 1.31200719, g_loss: 0.74829382\n",
      "Epoch: [ 2] [ 542/1093] time: 1163.0218, d_loss: 1.2891, g_loss: 0.7493\n",
      "[Sample] d_loss: 1.29147792, g_loss: 0.76374698\n",
      "Epoch: [ 2] [ 552/1093] time: 1167.3226, d_loss: 1.3050, g_loss: 0.7407\n",
      "[Sample] d_loss: 1.29510725, g_loss: 0.76604414\n",
      "Epoch: [ 2] [ 562/1093] time: 1171.4780, d_loss: 1.2796, g_loss: 0.7423\n",
      "[Sample] d_loss: 1.28955841, g_loss: 0.76844203\n",
      "Epoch: [ 2] [ 572/1093] time: 1175.6423, d_loss: 1.3307, g_loss: 0.7428\n",
      "[Sample] d_loss: 1.30295992, g_loss: 0.75737286\n",
      "Epoch: [ 2] [ 582/1093] time: 1180.0420, d_loss: 1.2880, g_loss: 0.7466\n",
      "[Sample] d_loss: 1.30201387, g_loss: 0.74761415\n",
      "Epoch: [ 2] [ 592/1093] time: 1184.4041, d_loss: 1.3339, g_loss: 0.7382\n",
      "[Sample] d_loss: 1.30055070, g_loss: 0.75207341\n",
      "Epoch: [ 2] [ 602/1093] time: 1188.7082, d_loss: 1.2981, g_loss: 0.7611\n",
      "[Sample] d_loss: 1.29592562, g_loss: 0.75853276\n",
      "Epoch: [ 2] [ 612/1093] time: 1192.9944, d_loss: 1.2991, g_loss: 0.7355\n",
      "[Sample] d_loss: 1.30104733, g_loss: 0.75324726\n",
      "Epoch: [ 2] [ 622/1093] time: 1197.2491, d_loss: 1.3160, g_loss: 0.7460\n",
      "[Sample] d_loss: 1.29202306, g_loss: 0.75918055\n",
      "Epoch: [ 2] [ 632/1093] time: 1201.4361, d_loss: 1.2974, g_loss: 0.7424\n",
      "[Sample] d_loss: 1.30217624, g_loss: 0.74565876\n",
      "Epoch: [ 2] [ 642/1093] time: 1205.6736, d_loss: 1.3041, g_loss: 0.7530\n",
      "[Sample] d_loss: 1.29471982, g_loss: 0.76198083\n",
      "Epoch: [ 2] [ 652/1093] time: 1209.9153, d_loss: 1.3011, g_loss: 0.7440\n",
      "[Sample] d_loss: 1.29674673, g_loss: 0.76066589\n",
      "Epoch: [ 2] [ 662/1093] time: 1214.1633, d_loss: 1.2938, g_loss: 0.7469\n",
      "[Sample] d_loss: 1.29088557, g_loss: 0.75912726\n",
      "Epoch: [ 2] [ 672/1093] time: 1218.4759, d_loss: 1.3434, g_loss: 0.7434\n",
      "[Sample] d_loss: 1.30527771, g_loss: 0.74470973\n",
      "Epoch: [ 2] [ 682/1093] time: 1222.7354, d_loss: 1.3144, g_loss: 0.7353\n",
      "[Sample] d_loss: 1.30128860, g_loss: 0.74803078\n",
      "Epoch: [ 2] [ 692/1093] time: 1227.0660, d_loss: 1.3362, g_loss: 0.7369\n",
      "[Sample] d_loss: 1.29450667, g_loss: 0.75391972\n",
      "Epoch: [ 2] [ 702/1093] time: 1231.3223, d_loss: 1.3093, g_loss: 0.7571\n",
      "[Sample] d_loss: 1.29707921, g_loss: 0.74859059\n",
      "Epoch: [ 2] [ 712/1093] time: 1235.5248, d_loss: 1.3140, g_loss: 0.7443\n",
      "[Sample] d_loss: 1.29371202, g_loss: 0.75043464\n",
      "Epoch: [ 2] [ 722/1093] time: 1239.7622, d_loss: 1.3168, g_loss: 0.7318\n",
      "[Sample] d_loss: 1.28636861, g_loss: 0.76753688\n",
      "Epoch: [ 2] [ 732/1093] time: 1244.0889, d_loss: 1.3091, g_loss: 0.7406\n",
      "[Sample] d_loss: 1.28643453, g_loss: 0.76285815\n",
      "Epoch: [ 2] [ 742/1093] time: 1248.3893, d_loss: 1.3316, g_loss: 0.7491\n",
      "[Sample] d_loss: 1.27895200, g_loss: 0.76994121\n",
      "Epoch: [ 2] [ 752/1093] time: 1252.7832, d_loss: 1.3144, g_loss: 0.7436\n",
      "[Sample] d_loss: 1.28635359, g_loss: 0.75681067\n",
      "Epoch: [ 2] [ 762/1093] time: 1257.0652, d_loss: 1.3053, g_loss: 0.7472\n",
      "[Sample] d_loss: 1.28033352, g_loss: 0.77388465\n",
      "Epoch: [ 2] [ 772/1093] time: 1261.3802, d_loss: 1.3169, g_loss: 0.7476\n",
      "[Sample] d_loss: 1.28514123, g_loss: 0.76423609\n",
      "Epoch: [ 2] [ 782/1093] time: 1265.6001, d_loss: 1.3050, g_loss: 0.7483\n",
      "[Sample] d_loss: 1.28518701, g_loss: 0.76707077\n",
      "Epoch: [ 2] [ 792/1093] time: 1269.8132, d_loss: 1.2721, g_loss: 0.7568\n",
      "[Sample] d_loss: 1.27450156, g_loss: 0.76826608\n",
      "Epoch: [ 2] [ 802/1093] time: 1274.0156, d_loss: 1.3010, g_loss: 0.7393\n",
      "[Sample] d_loss: 1.28853488, g_loss: 0.76287287\n",
      "Epoch: [ 2] [ 812/1093] time: 1278.2046, d_loss: 1.2957, g_loss: 0.7495\n",
      "[Sample] d_loss: 1.28547657, g_loss: 0.75733393\n",
      "Epoch: [ 2] [ 822/1093] time: 1282.5723, d_loss: 1.3079, g_loss: 0.7465\n",
      "[Sample] d_loss: 1.27906001, g_loss: 0.77552050\n",
      "Epoch: [ 2] [ 832/1093] time: 1286.8462, d_loss: 1.3002, g_loss: 0.7517\n",
      "[Sample] d_loss: 1.27778327, g_loss: 0.76457614\n",
      "Epoch: [ 2] [ 842/1093] time: 1291.4277, d_loss: 1.2896, g_loss: 0.7499\n",
      "[Sample] d_loss: 1.28625846, g_loss: 0.76388395\n",
      "Epoch: [ 2] [ 852/1093] time: 1295.7457, d_loss: 1.2997, g_loss: 0.7500\n",
      "[Sample] d_loss: 1.27839971, g_loss: 0.76894927\n",
      "Epoch: [ 2] [ 862/1093] time: 1299.9693, d_loss: 1.3071, g_loss: 0.7467\n",
      "[Sample] d_loss: 1.28441787, g_loss: 0.75314778\n",
      "Epoch: [ 2] [ 872/1093] time: 1304.2458, d_loss: 1.2827, g_loss: 0.7573\n",
      "[Sample] d_loss: 1.27402687, g_loss: 0.77064931\n",
      "Epoch: [ 2] [ 882/1093] time: 1308.5249, d_loss: 1.2881, g_loss: 0.7376\n",
      "[Sample] d_loss: 1.27012801, g_loss: 0.78211486\n",
      "Epoch: [ 2] [ 892/1093] time: 1313.3509, d_loss: 1.3343, g_loss: 0.7406\n",
      "[Sample] d_loss: 1.27393806, g_loss: 0.77167946\n",
      "Epoch: [ 2] [ 902/1093] time: 1317.8759, d_loss: 1.2358, g_loss: 0.7669\n",
      "[Sample] d_loss: 1.27978003, g_loss: 0.75995314\n",
      "Epoch: [ 2] [ 912/1093] time: 1322.4628, d_loss: 1.3035, g_loss: 0.7524\n",
      "[Sample] d_loss: 1.28267169, g_loss: 0.77357787\n",
      "Epoch: [ 2] [ 922/1093] time: 1326.8256, d_loss: 1.2914, g_loss: 0.7603\n",
      "[Sample] d_loss: 1.28295660, g_loss: 0.75982523\n",
      "Epoch: [ 2] [ 932/1093] time: 1331.3285, d_loss: 1.3218, g_loss: 0.7586\n",
      "[Sample] d_loss: 1.27510190, g_loss: 0.76783049\n",
      "Epoch: [ 2] [ 942/1093] time: 1335.6276, d_loss: 1.3093, g_loss: 0.7516\n",
      "[Sample] d_loss: 1.28883076, g_loss: 0.76006848\n",
      "Epoch: [ 2] [ 952/1093] time: 1339.9185, d_loss: 1.2879, g_loss: 0.7545\n",
      "[Sample] d_loss: 1.27529347, g_loss: 0.77491552\n",
      "Epoch: [ 2] [ 962/1093] time: 1344.6084, d_loss: 1.2755, g_loss: 0.7678\n",
      "[Sample] d_loss: 1.28565419, g_loss: 0.76377207\n",
      "Epoch: [ 2] [ 972/1093] time: 1348.9810, d_loss: 1.3206, g_loss: 0.7451\n",
      "[Sample] d_loss: 1.28073537, g_loss: 0.76172012\n",
      "Epoch: [ 2] [ 982/1093] time: 1353.2925, d_loss: 1.3022, g_loss: 0.7536\n",
      "[Sample] d_loss: 1.26783705, g_loss: 0.77278244\n",
      "Epoch: [ 2] [ 992/1093] time: 1357.6088, d_loss: 1.3017, g_loss: 0.7641\n",
      "[Sample] d_loss: 1.27413356, g_loss: 0.76578534\n",
      "Epoch: [ 2] [1002/1093] time: 1361.8824, d_loss: 1.2805, g_loss: 0.7559\n",
      "[Sample] d_loss: 1.27974081, g_loss: 0.76413405\n",
      "Epoch: [ 2] [1012/1093] time: 1366.4551, d_loss: 1.3017, g_loss: 0.7489\n",
      "[Sample] d_loss: 1.26496994, g_loss: 0.78054678\n",
      "Epoch: [ 2] [1022/1093] time: 1370.8926, d_loss: 1.2704, g_loss: 0.7548\n",
      "[Sample] d_loss: 1.26624548, g_loss: 0.77312165\n",
      "Epoch: [ 2] [1032/1093] time: 1375.2674, d_loss: 1.2446, g_loss: 0.7557\n",
      "[Sample] d_loss: 1.28086162, g_loss: 0.76823878\n",
      "Epoch: [ 2] [1042/1093] time: 1379.8704, d_loss: 1.3132, g_loss: 0.7526\n",
      "[Sample] d_loss: 1.27734923, g_loss: 0.76649410\n",
      "Epoch: [ 2] [1052/1093] time: 1384.4765, d_loss: 1.3055, g_loss: 0.7578\n",
      "[Sample] d_loss: 1.27083540, g_loss: 0.77653229\n",
      "Epoch: [ 2] [1062/1093] time: 1388.9610, d_loss: 1.2984, g_loss: 0.7503\n",
      "[Sample] d_loss: 1.27552664, g_loss: 0.76100338\n",
      "Epoch: [ 2] [1072/1093] time: 1393.2441, d_loss: 1.3023, g_loss: 0.7561\n",
      "[Sample] d_loss: 1.27251875, g_loss: 0.75644147\n",
      "Epoch: [ 2] [1082/1093] time: 1397.7683, d_loss: 1.3105, g_loss: 0.7544\n",
      "[Sample] d_loss: 1.26360607, g_loss: 0.77920705\n",
      "Epoch: [ 2] [1092/1093] time: 1402.1794, d_loss: 1.2727, g_loss: 0.7618\n",
      "[Sample] d_loss: 1.25999260, g_loss: 0.77905262\n",
      "Epoch: [ 3] [   9/1093] time: 1406.8994, d_loss: 1.3111, g_loss: 0.7440\n",
      "[Sample] d_loss: 1.26054382, g_loss: 0.77811408\n",
      "Epoch: [ 3] [  19/1093] time: 1411.5245, d_loss: 1.2953, g_loss: 0.7616\n",
      "[Sample] d_loss: 1.26342869, g_loss: 0.77380878\n",
      "Epoch: [ 3] [  29/1093] time: 1416.4650, d_loss: 1.2771, g_loss: 0.7528\n",
      "[Sample] d_loss: 1.27559364, g_loss: 0.76516551\n",
      "Epoch: [ 3] [  39/1093] time: 1420.8990, d_loss: 1.2998, g_loss: 0.7627\n",
      "[Sample] d_loss: 1.25484264, g_loss: 0.78278458\n",
      "Epoch: [ 3] [  49/1093] time: 1425.1739, d_loss: 1.2918, g_loss: 0.7592\n",
      "[Sample] d_loss: 1.25986373, g_loss: 0.78219068\n",
      "Epoch: [ 3] [  59/1093] time: 1429.5507, d_loss: 1.2530, g_loss: 0.7574\n",
      "[Sample] d_loss: 1.25992274, g_loss: 0.77625906\n",
      "Epoch: [ 3] [  69/1093] time: 1433.8406, d_loss: 1.2631, g_loss: 0.7584\n",
      "[Sample] d_loss: 1.25717413, g_loss: 0.77687669\n",
      "Epoch: [ 3] [  79/1093] time: 1438.1470, d_loss: 1.3044, g_loss: 0.7568\n",
      "[Sample] d_loss: 1.27904940, g_loss: 0.75718462\n",
      "Epoch: [ 3] [  89/1093] time: 1442.7237, d_loss: 1.3302, g_loss: 0.7573\n",
      "[Sample] d_loss: 1.26191032, g_loss: 0.77329350\n",
      "Epoch: [ 3] [  99/1093] time: 1447.6382, d_loss: 1.2664, g_loss: 0.7561\n",
      "[Sample] d_loss: 1.26806283, g_loss: 0.76288939\n",
      "Epoch: [ 3] [ 109/1093] time: 1452.0371, d_loss: 1.2512, g_loss: 0.7555\n",
      "[Sample] d_loss: 1.25466740, g_loss: 0.78741693\n",
      "Epoch: [ 3] [ 119/1093] time: 1456.2624, d_loss: 1.2704, g_loss: 0.7630\n",
      "[Sample] d_loss: 1.26992011, g_loss: 0.76700377\n",
      "Epoch: [ 3] [ 129/1093] time: 1460.5557, d_loss: 1.2805, g_loss: 0.7701\n",
      "[Sample] d_loss: 1.25804961, g_loss: 0.77846658\n",
      "Epoch: [ 3] [ 139/1093] time: 1464.7709, d_loss: 1.2349, g_loss: 0.7659\n",
      "[Sample] d_loss: 1.25452089, g_loss: 0.78954768\n",
      "Epoch: [ 3] [ 149/1093] time: 1469.0598, d_loss: 1.2469, g_loss: 0.7570\n",
      "[Sample] d_loss: 1.26287079, g_loss: 0.77665937\n",
      "Epoch: [ 3] [ 159/1093] time: 1473.3606, d_loss: 1.2917, g_loss: 0.7595\n",
      "[Sample] d_loss: 1.25619006, g_loss: 0.78529215\n",
      "Epoch: [ 3] [ 169/1093] time: 1477.7000, d_loss: 1.2491, g_loss: 0.7723\n",
      "[Sample] d_loss: 1.26460671, g_loss: 0.77506477\n",
      "Epoch: [ 3] [ 179/1093] time: 1481.9990, d_loss: 1.2728, g_loss: 0.7683\n",
      "[Sample] d_loss: 1.25548291, g_loss: 0.77506018\n",
      "Epoch: [ 3] [ 189/1093] time: 1486.2721, d_loss: 1.2794, g_loss: 0.7646\n",
      "[Sample] d_loss: 1.25084710, g_loss: 0.78120375\n",
      "Epoch: [ 3] [ 199/1093] time: 1490.7601, d_loss: 1.2708, g_loss: 0.7683\n",
      "[Sample] d_loss: 1.25837803, g_loss: 0.77672923\n",
      "Epoch: [ 3] [ 209/1093] time: 1495.3529, d_loss: 1.2954, g_loss: 0.7715\n",
      "[Sample] d_loss: 1.24911606, g_loss: 0.79511130\n",
      "Epoch: [ 3] [ 219/1093] time: 1499.7764, d_loss: 1.2543, g_loss: 0.7714\n",
      "[Sample] d_loss: 1.26053786, g_loss: 0.77038366\n",
      "Epoch: [ 3] [ 229/1093] time: 1504.0596, d_loss: 1.2602, g_loss: 0.7794\n",
      "[Sample] d_loss: 1.24446523, g_loss: 0.78908539\n",
      "Epoch: [ 3] [ 239/1093] time: 1508.5933, d_loss: 1.2980, g_loss: 0.7632\n",
      "[Sample] d_loss: 1.25307870, g_loss: 0.77404213\n",
      "Epoch: [ 3] [ 249/1093] time: 1512.9785, d_loss: 1.3063, g_loss: 0.7556\n",
      "[Sample] d_loss: 1.26395822, g_loss: 0.77083689\n",
      "Epoch: [ 3] [ 259/1093] time: 1517.4157, d_loss: 1.2426, g_loss: 0.7715\n",
      "[Sample] d_loss: 1.26164150, g_loss: 0.77135801\n",
      "Epoch: [ 3] [ 269/1093] time: 1521.8401, d_loss: 1.3007, g_loss: 0.7673\n",
      "[Sample] d_loss: 1.24871683, g_loss: 0.77859032\n",
      "Epoch: [ 3] [ 279/1093] time: 1526.1238, d_loss: 1.2835, g_loss: 0.7578\n",
      "[Sample] d_loss: 1.25175047, g_loss: 0.77658784\n",
      "Epoch: [ 3] [ 289/1093] time: 1530.4492, d_loss: 1.2605, g_loss: 0.7555\n",
      "[Sample] d_loss: 1.25067496, g_loss: 0.78049523\n",
      "Epoch: [ 3] [ 299/1093] time: 1534.7156, d_loss: 1.2670, g_loss: 0.7647\n",
      "[Sample] d_loss: 1.23580575, g_loss: 0.79401857\n",
      "Epoch: [ 3] [ 309/1093] time: 1539.0164, d_loss: 1.2407, g_loss: 0.7793\n",
      "[Sample] d_loss: 1.24038672, g_loss: 0.79666007\n",
      "Epoch: [ 3] [ 319/1093] time: 1543.5391, d_loss: 1.2677, g_loss: 0.7541\n",
      "[Sample] d_loss: 1.23836052, g_loss: 0.78932273\n",
      "Epoch: [ 3] [ 329/1093] time: 1547.7793, d_loss: 1.2999, g_loss: 0.7695\n",
      "[Sample] d_loss: 1.25568855, g_loss: 0.77672303\n",
      "Epoch: [ 3] [ 339/1093] time: 1552.1278, d_loss: 1.2974, g_loss: 0.7645\n",
      "[Sample] d_loss: 1.24880528, g_loss: 0.77926087\n",
      "Epoch: [ 3] [ 349/1093] time: 1556.4276, d_loss: 1.2542, g_loss: 0.7712\n",
      "[Sample] d_loss: 1.24877131, g_loss: 0.77091622\n",
      "Epoch: [ 3] [ 359/1093] time: 1560.7619, d_loss: 1.2783, g_loss: 0.7567\n",
      "[Sample] d_loss: 1.24321508, g_loss: 0.77959836\n",
      "Epoch: [ 3] [ 369/1093] time: 1565.1062, d_loss: 1.2796, g_loss: 0.7684\n",
      "[Sample] d_loss: 1.24596810, g_loss: 0.78090012\n",
      "Epoch: [ 3] [ 379/1093] time: 1569.6176, d_loss: 1.2280, g_loss: 0.7833\n",
      "[Sample] d_loss: 1.25295711, g_loss: 0.77758348\n",
      "Epoch: [ 3] [ 389/1093] time: 1574.5883, d_loss: 1.2353, g_loss: 0.7689\n",
      "[Sample] d_loss: 1.25508142, g_loss: 0.77588385\n",
      "Epoch: [ 3] [ 399/1093] time: 1579.5464, d_loss: 1.2805, g_loss: 0.7564\n",
      "[Sample] d_loss: 1.23304760, g_loss: 0.79375660\n",
      "Epoch: [ 3] [ 409/1093] time: 1584.1878, d_loss: 1.2329, g_loss: 0.7683\n",
      "[Sample] d_loss: 1.22856259, g_loss: 0.79254150\n",
      "Epoch: [ 3] [ 419/1093] time: 1588.7140, d_loss: 1.2539, g_loss: 0.7743\n",
      "[Sample] d_loss: 1.23886466, g_loss: 0.79008281\n",
      "Epoch: [ 3] [ 429/1093] time: 1593.6316, d_loss: 1.2368, g_loss: 0.7705\n",
      "[Sample] d_loss: 1.24819326, g_loss: 0.78553426\n",
      "Epoch: [ 3] [ 439/1093] time: 1598.7411, d_loss: 1.2881, g_loss: 0.7718\n",
      "[Sample] d_loss: 1.23260963, g_loss: 0.79247618\n",
      "Epoch: [ 3] [ 449/1093] time: 1604.1455, d_loss: 1.2595, g_loss: 0.7661\n",
      "[Sample] d_loss: 1.24466002, g_loss: 0.77841079\n",
      "Epoch: [ 3] [ 459/1093] time: 1609.8858, d_loss: 1.2745, g_loss: 0.7738\n",
      "[Sample] d_loss: 1.23234510, g_loss: 0.79245007\n",
      "Epoch: [ 3] [ 469/1093] time: 1614.3505, d_loss: 1.2650, g_loss: 0.7846\n",
      "[Sample] d_loss: 1.22935891, g_loss: 0.79109824\n",
      "Epoch: [ 3] [ 479/1093] time: 1619.0853, d_loss: 1.2388, g_loss: 0.7650\n",
      "[Sample] d_loss: 1.24617755, g_loss: 0.77430665\n",
      "Epoch: [ 3] [ 489/1093] time: 1623.8178, d_loss: 1.2578, g_loss: 0.7744\n",
      "[Sample] d_loss: 1.24112332, g_loss: 0.78428054\n",
      "Epoch: [ 3] [ 499/1093] time: 1628.2661, d_loss: 1.2693, g_loss: 0.7771\n",
      "[Sample] d_loss: 1.23869348, g_loss: 0.77835184\n",
      "Epoch: [ 3] [ 509/1093] time: 1632.5428, d_loss: 1.2610, g_loss: 0.7755\n",
      "[Sample] d_loss: 1.24508762, g_loss: 0.77841949\n",
      "Epoch: [ 3] [ 519/1093] time: 1637.0787, d_loss: 1.3011, g_loss: 0.7620\n",
      "[Sample] d_loss: 1.23595047, g_loss: 0.78638136\n",
      "Epoch: [ 3] [ 529/1093] time: 1641.4490, d_loss: 1.2208, g_loss: 0.7770\n",
      "[Sample] d_loss: 1.22653472, g_loss: 0.79191035\n",
      "Epoch: [ 3] [ 539/1093] time: 1645.6548, d_loss: 1.2807, g_loss: 0.7616\n",
      "[Sample] d_loss: 1.23343325, g_loss: 0.78430533\n",
      "Epoch: [ 3] [ 549/1093] time: 1649.8328, d_loss: 1.2762, g_loss: 0.7667\n",
      "[Sample] d_loss: 1.22619462, g_loss: 0.79553026\n",
      "Epoch: [ 3] [ 559/1093] time: 1654.0984, d_loss: 1.2711, g_loss: 0.7662\n",
      "[Sample] d_loss: 1.22988713, g_loss: 0.79492521\n",
      "Epoch: [ 3] [ 569/1093] time: 1658.4179, d_loss: 1.2384, g_loss: 0.7880\n",
      "[Sample] d_loss: 1.22681296, g_loss: 0.79353064\n",
      "Epoch: [ 3] [ 579/1093] time: 1662.8042, d_loss: 1.2797, g_loss: 0.7667\n",
      "[Sample] d_loss: 1.23889995, g_loss: 0.78205568\n",
      "Epoch: [ 3] [ 589/1093] time: 1667.2138, d_loss: 1.2816, g_loss: 0.7671\n",
      "[Sample] d_loss: 1.23175621, g_loss: 0.79178631\n",
      "Epoch: [ 3] [ 599/1093] time: 1671.8262, d_loss: 1.2535, g_loss: 0.7817\n",
      "[Sample] d_loss: 1.23052096, g_loss: 0.79000735\n",
      "Epoch: [ 3] [ 609/1093] time: 1676.3169, d_loss: 1.2871, g_loss: 0.7664\n",
      "[Sample] d_loss: 1.23654175, g_loss: 0.78868127\n",
      "Epoch: [ 3] [ 619/1093] time: 1680.7127, d_loss: 1.2578, g_loss: 0.7654\n",
      "[Sample] d_loss: 1.22961068, g_loss: 0.78973055\n",
      "Epoch: [ 3] [ 629/1093] time: 1685.1399, d_loss: 1.2289, g_loss: 0.7805\n",
      "[Sample] d_loss: 1.21674967, g_loss: 0.79538512\n",
      "Epoch: [ 3] [ 639/1093] time: 1689.7453, d_loss: 1.2550, g_loss: 0.7778\n",
      "[Sample] d_loss: 1.22360039, g_loss: 0.79347605\n",
      "Epoch: [ 3] [ 649/1093] time: 1694.4886, d_loss: 1.2375, g_loss: 0.7898\n",
      "[Sample] d_loss: 1.24129224, g_loss: 0.78574759\n",
      "Epoch: [ 3] [ 659/1093] time: 1699.1300, d_loss: 1.2397, g_loss: 0.7852\n",
      "[Sample] d_loss: 1.23851168, g_loss: 0.78870225\n",
      "Epoch: [ 3] [ 669/1093] time: 1703.9105, d_loss: 1.3060, g_loss: 0.7749\n",
      "[Sample] d_loss: 1.23423481, g_loss: 0.78889084\n",
      "Epoch: [ 3] [ 679/1093] time: 1708.5914, d_loss: 1.2275, g_loss: 0.7912\n",
      "[Sample] d_loss: 1.22005510, g_loss: 0.80485201\n",
      "Epoch: [ 3] [ 689/1093] time: 1712.9982, d_loss: 1.2836, g_loss: 0.7675\n",
      "[Sample] d_loss: 1.22703886, g_loss: 0.80545634\n",
      "Epoch: [ 3] [ 699/1093] time: 1717.7953, d_loss: 1.2775, g_loss: 0.7862\n",
      "[Sample] d_loss: 1.21852326, g_loss: 0.80738634\n",
      "Epoch: [ 3] [ 709/1093] time: 1722.3582, d_loss: 1.2290, g_loss: 0.7719\n",
      "[Sample] d_loss: 1.22427511, g_loss: 0.79442739\n",
      "Epoch: [ 3] [ 719/1093] time: 1726.6400, d_loss: 1.2415, g_loss: 0.7850\n",
      "[Sample] d_loss: 1.22391534, g_loss: 0.80377412\n",
      "Epoch: [ 3] [ 729/1093] time: 1731.0888, d_loss: 1.2289, g_loss: 0.7947\n",
      "[Sample] d_loss: 1.22722554, g_loss: 0.79371822\n",
      "Epoch: [ 3] [ 739/1093] time: 1735.4894, d_loss: 1.2794, g_loss: 0.8002\n",
      "[Sample] d_loss: 1.20957768, g_loss: 0.80911267\n",
      "Epoch: [ 3] [ 749/1093] time: 1739.7736, d_loss: 1.2530, g_loss: 0.7679\n",
      "[Sample] d_loss: 1.21129858, g_loss: 0.80827367\n",
      "Epoch: [ 3] [ 759/1093] time: 1744.0165, d_loss: 1.2299, g_loss: 0.7856\n",
      "[Sample] d_loss: 1.21141994, g_loss: 0.80884862\n",
      "Epoch: [ 3] [ 769/1093] time: 1748.5847, d_loss: 1.2184, g_loss: 0.7871\n",
      "[Sample] d_loss: 1.20621216, g_loss: 0.81321096\n",
      "Epoch: [ 3] [ 779/1093] time: 1752.8496, d_loss: 1.2119, g_loss: 0.7926\n",
      "[Sample] d_loss: 1.21481371, g_loss: 0.80690789\n",
      "Epoch: [ 3] [ 789/1093] time: 1757.1857, d_loss: 1.2686, g_loss: 0.7959\n",
      "[Sample] d_loss: 1.20791388, g_loss: 0.81001508\n",
      "Epoch: [ 3] [ 799/1093] time: 1761.6105, d_loss: 1.2270, g_loss: 0.7806\n",
      "[Sample] d_loss: 1.21894026, g_loss: 0.80805665\n",
      "Epoch: [ 3] [ 809/1093] time: 1765.8783, d_loss: 1.2172, g_loss: 0.7874\n",
      "[Sample] d_loss: 1.22437799, g_loss: 0.79647392\n",
      "Epoch: [ 3] [ 819/1093] time: 1770.2151, d_loss: 1.2230, g_loss: 0.7976\n",
      "[Sample] d_loss: 1.21197057, g_loss: 0.79802418\n",
      "Epoch: [ 3] [ 829/1093] time: 1774.4728, d_loss: 1.2281, g_loss: 0.7672\n",
      "[Sample] d_loss: 1.20398796, g_loss: 0.80944198\n",
      "Epoch: [ 3] [ 839/1093] time: 1778.8761, d_loss: 1.2148, g_loss: 0.7878\n",
      "[Sample] d_loss: 1.22881413, g_loss: 0.78108728\n",
      "Epoch: [ 3] [ 849/1093] time: 1783.1596, d_loss: 1.2326, g_loss: 0.7921\n",
      "[Sample] d_loss: 1.21043861, g_loss: 0.80802011\n",
      "Epoch: [ 3] [ 859/1093] time: 1787.5337, d_loss: 1.2316, g_loss: 0.7995\n",
      "[Sample] d_loss: 1.21594095, g_loss: 0.79230273\n",
      "Epoch: [ 3] [ 869/1093] time: 1791.9846, d_loss: 1.2711, g_loss: 0.7944\n",
      "[Sample] d_loss: 1.20579004, g_loss: 0.80189735\n",
      "Epoch: [ 3] [ 879/1093] time: 1796.5945, d_loss: 1.2140, g_loss: 0.7901\n",
      "[Sample] d_loss: 1.21364129, g_loss: 0.80026340\n",
      "Epoch: [ 3] [ 889/1093] time: 1800.9600, d_loss: 1.2571, g_loss: 0.7985\n",
      "[Sample] d_loss: 1.21517253, g_loss: 0.79841685\n",
      "Epoch: [ 3] [ 899/1093] time: 1805.3549, d_loss: 1.2667, g_loss: 0.7803\n",
      "[Sample] d_loss: 1.20472801, g_loss: 0.80357087\n",
      "Epoch: [ 3] [ 909/1093] time: 1809.8254, d_loss: 1.2391, g_loss: 0.7938\n",
      "[Sample] d_loss: 1.20634747, g_loss: 0.80032432\n",
      "Epoch: [ 3] [ 919/1093] time: 1814.2279, d_loss: 1.2339, g_loss: 0.7830\n",
      "[Sample] d_loss: 1.20148528, g_loss: 0.80406207\n",
      "Epoch: [ 3] [ 929/1093] time: 1818.4791, d_loss: 1.2830, g_loss: 0.7928\n",
      "[Sample] d_loss: 1.20321596, g_loss: 0.80982661\n",
      "Epoch: [ 3] [ 939/1093] time: 1822.9524, d_loss: 1.2108, g_loss: 0.7851\n",
      "[Sample] d_loss: 1.20308733, g_loss: 0.81084406\n",
      "Epoch: [ 3] [ 949/1093] time: 1827.2344, d_loss: 1.2439, g_loss: 0.7968\n",
      "[Sample] d_loss: 1.20877957, g_loss: 0.79550874\n",
      "Epoch: [ 3] [ 959/1093] time: 1831.6843, d_loss: 1.2372, g_loss: 0.7886\n",
      "[Sample] d_loss: 1.20157576, g_loss: 0.80934274\n",
      "Epoch: [ 3] [ 969/1093] time: 1836.0680, d_loss: 1.2093, g_loss: 0.7956\n",
      "[Sample] d_loss: 1.20130360, g_loss: 0.80420917\n",
      "Epoch: [ 3] [ 979/1093] time: 1840.4730, d_loss: 1.2392, g_loss: 0.7976\n",
      "[Sample] d_loss: 1.19701660, g_loss: 0.81676102\n",
      "Epoch: [ 3] [ 989/1093] time: 1844.8963, d_loss: 1.2345, g_loss: 0.7968\n",
      "[Sample] d_loss: 1.19362485, g_loss: 0.81719685\n",
      "Epoch: [ 3] [ 999/1093] time: 1849.3090, d_loss: 1.2029, g_loss: 0.7800\n",
      "[Sample] d_loss: 1.21568155, g_loss: 0.79825073\n",
      "Epoch: [ 3] [1009/1093] time: 1853.7758, d_loss: 1.2501, g_loss: 0.8001\n",
      "[Sample] d_loss: 1.20413756, g_loss: 0.81114721\n",
      "Epoch: [ 3] [1019/1093] time: 1858.1197, d_loss: 1.2429, g_loss: 0.8020\n",
      "[Sample] d_loss: 1.19999528, g_loss: 0.81633341\n",
      "Epoch: [ 3] [1029/1093] time: 1862.6736, d_loss: 1.2020, g_loss: 0.8043\n",
      "[Sample] d_loss: 1.20484555, g_loss: 0.81063795\n",
      "Epoch: [ 3] [1039/1093] time: 1867.6325, d_loss: 1.2571, g_loss: 0.7948\n",
      "[Sample] d_loss: 1.20484924, g_loss: 0.80672103\n",
      "Epoch: [ 3] [1049/1093] time: 1872.5950, d_loss: 1.1927, g_loss: 0.8047\n",
      "[Sample] d_loss: 1.18680227, g_loss: 0.82581347\n",
      "Epoch: [ 3] [1059/1093] time: 1877.4105, d_loss: 1.2096, g_loss: 0.8014\n",
      "[Sample] d_loss: 1.18993735, g_loss: 0.82194245\n",
      "Epoch: [ 3] [1069/1093] time: 1882.0064, d_loss: 1.2761, g_loss: 0.7881\n",
      "[Sample] d_loss: 1.19953477, g_loss: 0.81170481\n",
      "Epoch: [ 3] [1079/1093] time: 1886.3293, d_loss: 1.2237, g_loss: 0.8056\n",
      "[Sample] d_loss: 1.18740833, g_loss: 0.81881815\n",
      "Epoch: [ 3] [1089/1093] time: 1890.5960, d_loss: 1.2347, g_loss: 0.7945\n",
      "[Sample] d_loss: 1.19666982, g_loss: 0.81607652\n",
      "[Sample] d_loss: 1.20278335, g_loss: 0.81164122\n",
      "Epoch: [ 4] [   6/1093] time: 1895.0966, d_loss: 1.2166, g_loss: 0.7876\n",
      "[Sample] d_loss: 1.19672275, g_loss: 0.80963480\n",
      "Epoch: [ 4] [  16/1093] time: 1899.3552, d_loss: 1.2414, g_loss: 0.7862\n",
      "[Sample] d_loss: 1.18655181, g_loss: 0.81838441\n",
      "Epoch: [ 4] [  26/1093] time: 1903.8905, d_loss: 1.2084, g_loss: 0.7956\n",
      "[Sample] d_loss: 1.18836904, g_loss: 0.81430447\n",
      "Epoch: [ 4] [  36/1093] time: 1908.2501, d_loss: 1.2197, g_loss: 0.7975\n",
      "[Sample] d_loss: 1.18505609, g_loss: 0.82131612\n",
      "Epoch: [ 4] [  46/1093] time: 1912.7428, d_loss: 1.1923, g_loss: 0.7958\n",
      "[Sample] d_loss: 1.17660940, g_loss: 0.83539057\n",
      "Epoch: [ 4] [  56/1093] time: 1917.1381, d_loss: 1.2267, g_loss: 0.8044\n",
      "[Sample] d_loss: 1.18666029, g_loss: 0.82560325\n",
      "Epoch: [ 4] [  66/1093] time: 1921.4862, d_loss: 1.2027, g_loss: 0.7935\n",
      "[Sample] d_loss: 1.19426405, g_loss: 0.81043184\n",
      "Epoch: [ 4] [  76/1093] time: 1925.9258, d_loss: 1.2419, g_loss: 0.8080\n",
      "[Sample] d_loss: 1.18790960, g_loss: 0.81489748\n",
      "Epoch: [ 4] [  86/1093] time: 1930.3597, d_loss: 1.2027, g_loss: 0.8081\n",
      "[Sample] d_loss: 1.19714653, g_loss: 0.81198567\n",
      "Epoch: [ 4] [  96/1093] time: 1934.8659, d_loss: 1.2311, g_loss: 0.8048\n",
      "[Sample] d_loss: 1.17634130, g_loss: 0.82377517\n",
      "Epoch: [ 4] [ 106/1093] time: 1939.2569, d_loss: 1.1824, g_loss: 0.7975\n",
      "[Sample] d_loss: 1.18350935, g_loss: 0.82796085\n",
      "Epoch: [ 4] [ 116/1093] time: 1943.6409, d_loss: 1.2865, g_loss: 0.8024\n",
      "[Sample] d_loss: 1.18589580, g_loss: 0.82177120\n",
      "Epoch: [ 4] [ 126/1093] time: 1948.0345, d_loss: 1.2262, g_loss: 0.7956\n",
      "[Sample] d_loss: 1.19132507, g_loss: 0.80864751\n",
      "Epoch: [ 4] [ 136/1093] time: 1952.3375, d_loss: 1.1690, g_loss: 0.8181\n",
      "[Sample] d_loss: 1.19650984, g_loss: 0.81778681\n",
      "Epoch: [ 4] [ 146/1093] time: 1956.6120, d_loss: 1.2169, g_loss: 0.7986\n",
      "[Sample] d_loss: 1.19442677, g_loss: 0.81204522\n",
      "Epoch: [ 4] [ 156/1093] time: 1961.1128, d_loss: 1.2319, g_loss: 0.7941\n",
      "[Sample] d_loss: 1.19190907, g_loss: 0.81165749\n",
      "Epoch: [ 4] [ 166/1093] time: 1965.4320, d_loss: 1.2213, g_loss: 0.8164\n",
      "[Sample] d_loss: 1.18811655, g_loss: 0.80593622\n",
      "Epoch: [ 4] [ 176/1093] time: 1969.9745, d_loss: 1.1709, g_loss: 0.8211\n",
      "[Sample] d_loss: 1.17845380, g_loss: 0.82862455\n",
      "Epoch: [ 4] [ 186/1093] time: 1974.3527, d_loss: 1.2447, g_loss: 0.8096\n",
      "[Sample] d_loss: 1.17569125, g_loss: 0.83063006\n",
      "Epoch: [ 4] [ 196/1093] time: 1978.6857, d_loss: 1.2270, g_loss: 0.8076\n",
      "[Sample] d_loss: 1.18862605, g_loss: 0.82551205\n",
      "Epoch: [ 4] [ 206/1093] time: 1983.0747, d_loss: 1.2129, g_loss: 0.8172\n",
      "[Sample] d_loss: 1.19429874, g_loss: 0.80540150\n",
      "Epoch: [ 4] [ 216/1093] time: 1987.4064, d_loss: 1.1786, g_loss: 0.8174\n",
      "[Sample] d_loss: 1.18817568, g_loss: 0.81223500\n",
      "Epoch: [ 4] [ 226/1093] time: 1991.8278, d_loss: 1.1812, g_loss: 0.8049\n",
      "[Sample] d_loss: 1.18261743, g_loss: 0.81289351\n",
      "Epoch: [ 4] [ 236/1093] time: 1996.3016, d_loss: 1.2237, g_loss: 0.8218\n",
      "[Sample] d_loss: 1.17193699, g_loss: 0.83114964\n",
      "Epoch: [ 4] [ 246/1093] time: 2000.8651, d_loss: 1.2249, g_loss: 0.8273\n",
      "[Sample] d_loss: 1.17612231, g_loss: 0.82114744\n",
      "Epoch: [ 4] [ 256/1093] time: 2005.2838, d_loss: 1.1869, g_loss: 0.8208\n",
      "[Sample] d_loss: 1.17410290, g_loss: 0.82818633\n",
      "Epoch: [ 4] [ 266/1093] time: 2009.8364, d_loss: 1.1840, g_loss: 0.8114\n",
      "[Sample] d_loss: 1.17598403, g_loss: 0.82762921\n",
      "Epoch: [ 4] [ 276/1093] time: 2014.1083, d_loss: 1.2158, g_loss: 0.8147\n",
      "[Sample] d_loss: 1.17191827, g_loss: 0.83766854\n",
      "Epoch: [ 4] [ 286/1093] time: 2018.3953, d_loss: 1.2424, g_loss: 0.8016\n",
      "[Sample] d_loss: 1.18139386, g_loss: 0.82228661\n",
      "Epoch: [ 4] [ 296/1093] time: 2022.7437, d_loss: 1.2214, g_loss: 0.8063\n",
      "[Sample] d_loss: 1.16748214, g_loss: 0.83169150\n",
      "Epoch: [ 4] [ 306/1093] time: 2027.0973, d_loss: 1.2077, g_loss: 0.8208\n",
      "[Sample] d_loss: 1.18532395, g_loss: 0.82033509\n",
      "Epoch: [ 4] [ 316/1093] time: 2031.4953, d_loss: 1.1792, g_loss: 0.8068\n",
      "[Sample] d_loss: 1.17640185, g_loss: 0.81970286\n",
      "Epoch: [ 4] [ 326/1093] time: 2036.0214, d_loss: 1.2179, g_loss: 0.8070\n",
      "[Sample] d_loss: 1.17091739, g_loss: 0.82334888\n",
      "Epoch: [ 4] [ 336/1093] time: 2040.2905, d_loss: 1.1877, g_loss: 0.8128\n",
      "[Sample] d_loss: 1.16956842, g_loss: 0.82530355\n",
      "Epoch: [ 4] [ 346/1093] time: 2044.6381, d_loss: 1.2060, g_loss: 0.8094\n",
      "[Sample] d_loss: 1.17431569, g_loss: 0.82703966\n",
      "Epoch: [ 4] [ 356/1093] time: 2049.0199, d_loss: 1.1815, g_loss: 0.8294\n",
      "[Sample] d_loss: 1.17786503, g_loss: 0.81585979\n",
      "Epoch: [ 4] [ 366/1093] time: 2053.3086, d_loss: 1.1584, g_loss: 0.8110\n",
      "[Sample] d_loss: 1.16829896, g_loss: 0.83364844\n",
      "Epoch: [ 4] [ 376/1093] time: 2057.9110, d_loss: 1.2110, g_loss: 0.8000\n",
      "[Sample] d_loss: 1.18183017, g_loss: 0.81574947\n",
      "Epoch: [ 4] [ 386/1093] time: 2062.2234, d_loss: 1.2017, g_loss: 0.8059\n",
      "[Sample] d_loss: 1.15161121, g_loss: 0.83910698\n",
      "Epoch: [ 4] [ 396/1093] time: 2066.7132, d_loss: 1.2140, g_loss: 0.8106\n",
      "[Sample] d_loss: 1.15656173, g_loss: 0.83737183\n",
      "Epoch: [ 4] [ 406/1093] time: 2070.9729, d_loss: 1.2471, g_loss: 0.8057\n",
      "[Sample] d_loss: 1.15199089, g_loss: 0.84530425\n",
      "Epoch: [ 4] [ 416/1093] time: 2075.3427, d_loss: 1.2150, g_loss: 0.8136\n",
      "[Sample] d_loss: 1.17240369, g_loss: 0.81823647\n",
      "Epoch: [ 4] [ 426/1093] time: 2079.6703, d_loss: 1.2214, g_loss: 0.8157\n",
      "[Sample] d_loss: 1.16618800, g_loss: 0.82329917\n",
      "Epoch: [ 4] [ 436/1093] time: 2083.9949, d_loss: 1.1565, g_loss: 0.7930\n",
      "[Sample] d_loss: 1.16006923, g_loss: 0.83616889\n",
      "Epoch: [ 4] [ 446/1093] time: 2088.4310, d_loss: 1.2081, g_loss: 0.7955\n",
      "[Sample] d_loss: 1.17704940, g_loss: 0.82448828\n",
      "Epoch: [ 4] [ 456/1093] time: 2092.9149, d_loss: 1.2127, g_loss: 0.8086\n",
      "[Sample] d_loss: 1.16054225, g_loss: 0.83658075\n",
      "Epoch: [ 4] [ 466/1093] time: 2097.5046, d_loss: 1.1762, g_loss: 0.8156\n",
      "[Sample] d_loss: 1.16998780, g_loss: 0.82529950\n",
      "Epoch: [ 4] [ 476/1093] time: 2101.8633, d_loss: 1.2017, g_loss: 0.8129\n",
      "[Sample] d_loss: 1.16479790, g_loss: 0.83045101\n",
      "Epoch: [ 4] [ 486/1093] time: 2106.2032, d_loss: 1.2007, g_loss: 0.8244\n",
      "[Sample] d_loss: 1.16180861, g_loss: 0.83151329\n",
      "Epoch: [ 4] [ 496/1093] time: 2110.5171, d_loss: 1.1596, g_loss: 0.8326\n",
      "[Sample] d_loss: 1.15898895, g_loss: 0.83144867\n",
      "Epoch: [ 4] [ 506/1093] time: 2114.8765, d_loss: 1.1861, g_loss: 0.8168\n",
      "[Sample] d_loss: 1.16576076, g_loss: 0.82965791\n",
      "Epoch: [ 4] [ 516/1093] time: 2119.4137, d_loss: 1.2133, g_loss: 0.8220\n",
      "[Sample] d_loss: 1.15964651, g_loss: 0.84469116\n",
      "Epoch: [ 4] [ 526/1093] time: 2124.6417, d_loss: 1.1769, g_loss: 0.8229\n",
      "[Sample] d_loss: 1.16440940, g_loss: 0.83423793\n",
      "Epoch: [ 4] [ 536/1093] time: 2129.0383, d_loss: 1.2411, g_loss: 0.8061\n",
      "[Sample] d_loss: 1.16881323, g_loss: 0.82215291\n",
      "Epoch: [ 4] [ 546/1093] time: 2133.0356, d_loss: 1.1581, g_loss: 0.8014\n",
      "[Sample] d_loss: 1.16597450, g_loss: 0.83489180\n",
      "Epoch: [ 4] [ 556/1093] time: 2136.9935, d_loss: 1.2519, g_loss: 0.8129\n",
      "[Sample] d_loss: 1.16276956, g_loss: 0.82799482\n",
      "Epoch: [ 4] [ 566/1093] time: 2140.9563, d_loss: 1.1951, g_loss: 0.8213\n",
      "[Sample] d_loss: 1.17123604, g_loss: 0.82373798\n",
      "Epoch: [ 4] [ 576/1093] time: 2144.9240, d_loss: 1.1926, g_loss: 0.8185\n",
      "[Sample] d_loss: 1.17833424, g_loss: 0.82104319\n",
      "Epoch: [ 4] [ 586/1093] time: 2149.1073, d_loss: 1.1441, g_loss: 0.8280\n",
      "[Sample] d_loss: 1.15493464, g_loss: 0.83983326\n",
      "Epoch: [ 4] [ 596/1093] time: 5995.3464, d_loss: 1.1764, g_loss: 0.8370\n",
      "[Sample] d_loss: 1.15867078, g_loss: 0.84310746\n",
      "Epoch: [ 4] [ 606/1093] time: 6001.7032, d_loss: 1.2002, g_loss: 0.7982\n",
      "[Sample] d_loss: 1.17408109, g_loss: 0.81790829\n",
      "Epoch: [ 4] [ 616/1093] time: 6005.9688, d_loss: 1.1970, g_loss: 0.8172\n",
      "[Sample] d_loss: 1.17090356, g_loss: 0.82521605\n",
      "Epoch: [ 4] [ 626/1093] time: 6009.9291, d_loss: 1.2545, g_loss: 0.8129\n",
      "[Sample] d_loss: 1.15909290, g_loss: 0.82796633\n",
      "Epoch: [ 4] [ 636/1093] time: 6014.4583, d_loss: 1.1917, g_loss: 0.7941\n",
      "[Sample] d_loss: 1.16983843, g_loss: 0.82149607\n",
      "Epoch: [ 4] [ 646/1093] time: 6018.4093, d_loss: 1.2006, g_loss: 0.8195\n",
      "[Sample] d_loss: 1.16907787, g_loss: 0.82226253\n",
      "Epoch: [ 4] [ 656/1093] time: 6022.5153, d_loss: 1.1631, g_loss: 0.8187\n",
      "[Sample] d_loss: 1.17032802, g_loss: 0.81475264\n",
      "Epoch: [ 4] [ 666/1093] time: 6026.6343, d_loss: 1.2239, g_loss: 0.8011\n",
      "[Sample] d_loss: 1.16430998, g_loss: 0.82863319\n",
      "Epoch: [ 4] [ 676/1093] time: 6030.7917, d_loss: 1.2188, g_loss: 0.7862\n",
      "[Sample] d_loss: 1.17142868, g_loss: 0.81930953\n",
      "Epoch: [ 4] [ 686/1093] time: 6035.2957, d_loss: 1.1789, g_loss: 0.8153\n",
      "[Sample] d_loss: 1.16992164, g_loss: 0.82335252\n",
      "Epoch: [ 4] [ 696/1093] time: 6040.0353, d_loss: 1.2270, g_loss: 0.8171\n",
      "[Sample] d_loss: 1.18484664, g_loss: 0.80276257\n",
      "Epoch: [ 4] [ 706/1093] time: 6046.0225, d_loss: 1.1824, g_loss: 0.8113\n",
      "[Sample] d_loss: 1.16949606, g_loss: 0.81829965\n",
      "Epoch: [ 4] [ 716/1093] time: 6050.9940, d_loss: 1.1874, g_loss: 0.8202\n",
      "[Sample] d_loss: 1.16878295, g_loss: 0.82276034\n",
      "Epoch: [ 4] [ 726/1093] time: 6055.8511, d_loss: 1.1815, g_loss: 0.8239\n",
      "[Sample] d_loss: 1.18600118, g_loss: 0.80315548\n",
      "Epoch: [ 4] [ 736/1093] time: 6060.4171, d_loss: 1.2077, g_loss: 0.8145\n",
      "[Sample] d_loss: 1.17393112, g_loss: 0.81854534\n",
      "Epoch: [ 4] [ 746/1093] time: 6064.8501, d_loss: 1.2072, g_loss: 0.7835\n",
      "[Sample] d_loss: 1.17189622, g_loss: 0.82000768\n",
      "Epoch: [ 4] [ 756/1093] time: 6069.0505, d_loss: 1.2285, g_loss: 0.7832\n",
      "[Sample] d_loss: 1.17332089, g_loss: 0.81441009\n",
      "Epoch: [ 4] [ 766/1093] time: 6073.4408, d_loss: 1.1741, g_loss: 0.8116\n",
      "[Sample] d_loss: 1.17236662, g_loss: 0.82209444\n",
      "Epoch: [ 4] [ 776/1093] time: 6077.5402, d_loss: 1.1802, g_loss: 0.8180\n",
      "[Sample] d_loss: 1.17823362, g_loss: 0.81191504\n",
      "Epoch: [ 4] [ 786/1093] time: 6081.4234, d_loss: 1.2222, g_loss: 0.7880\n",
      "[Sample] d_loss: 1.18123853, g_loss: 0.81677759\n",
      "Epoch: [ 4] [ 796/1093] time: 6085.6102, d_loss: 1.2309, g_loss: 0.8144\n",
      "[Sample] d_loss: 1.17308235, g_loss: 0.81122541\n",
      "Epoch: [ 4] [ 806/1093] time: 6090.0438, d_loss: 1.1609, g_loss: 0.8039\n",
      "[Sample] d_loss: 1.17903626, g_loss: 0.81303680\n",
      "Epoch: [ 4] [ 816/1093] time: 6094.9588, d_loss: 1.2318, g_loss: 0.7661\n",
      "[Sample] d_loss: 1.18781662, g_loss: 0.80589682\n",
      "Epoch: [ 4] [ 826/1093] time: 6099.6265, d_loss: 1.1754, g_loss: 0.8281\n",
      "[Sample] d_loss: 1.19334555, g_loss: 0.80579442\n",
      "Epoch: [ 4] [ 836/1093] time: 6104.3425, d_loss: 1.2067, g_loss: 0.8211\n",
      "[Sample] d_loss: 1.18437839, g_loss: 0.80549312\n",
      "Epoch: [ 4] [ 846/1093] time: 6109.1963, d_loss: 1.1682, g_loss: 0.8051\n",
      "[Sample] d_loss: 1.18091869, g_loss: 0.80425036\n",
      "Epoch: [ 4] [ 856/1093] time: 6114.6823, d_loss: 1.1905, g_loss: 0.8220\n",
      "[Sample] d_loss: 1.17466998, g_loss: 0.81425089\n",
      "Epoch: [ 4] [ 866/1093] time: 6119.1389, d_loss: 1.1721, g_loss: 0.8216\n",
      "[Sample] d_loss: 1.17686749, g_loss: 0.81467849\n",
      "Epoch: [ 4] [ 876/1093] time: 6123.8226, d_loss: 1.2373, g_loss: 0.7702\n",
      "[Sample] d_loss: 1.17612815, g_loss: 0.81843138\n",
      "Epoch: [ 4] [ 886/1093] time: 6128.1630, d_loss: 1.2102, g_loss: 0.8049\n",
      "[Sample] d_loss: 1.18767202, g_loss: 0.81061012\n",
      "Epoch: [ 4] [ 896/1093] time: 6132.8721, d_loss: 1.1766, g_loss: 0.8146\n",
      "[Sample] d_loss: 1.18350840, g_loss: 0.81407750\n",
      "Epoch: [ 4] [ 906/1093] time: 6137.2953, d_loss: 1.2152, g_loss: 0.8060\n",
      "[Sample] d_loss: 1.18035090, g_loss: 0.81977797\n",
      "Epoch: [ 4] [ 916/1093] time: 6141.9989, d_loss: 1.1651, g_loss: 0.8313\n",
      "[Sample] d_loss: 1.16552734, g_loss: 0.83017677\n",
      "Epoch: [ 4] [ 926/1093] time: 6146.4824, d_loss: 1.1980, g_loss: 0.8461\n",
      "[Sample] d_loss: 1.16347003, g_loss: 0.83908093\n",
      "Epoch: [ 4] [ 936/1093] time: 6150.5783, d_loss: 1.1585, g_loss: 0.8281\n",
      "[Sample] d_loss: 1.16779780, g_loss: 0.82879627\n",
      "Epoch: [ 4] [ 946/1093] time: 6154.5433, d_loss: 1.1886, g_loss: 0.8222\n",
      "[Sample] d_loss: 1.15266252, g_loss: 0.84303737\n",
      "Epoch: [ 4] [ 956/1093] time: 6158.7771, d_loss: 1.1483, g_loss: 0.8334\n",
      "[Sample] d_loss: 1.17262864, g_loss: 0.82395452\n",
      "Epoch: [ 4] [ 966/1093] time: 6162.9631, d_loss: 1.2411, g_loss: 0.8023\n",
      "[Sample] d_loss: 1.18552434, g_loss: 0.81310487\n",
      "Epoch: [ 4] [ 976/1093] time: 6166.9927, d_loss: 1.2085, g_loss: 0.7946\n",
      "[Sample] d_loss: 1.17230415, g_loss: 0.83140224\n",
      "Epoch: [ 4] [ 986/1093] time: 6171.0708, d_loss: 1.1912, g_loss: 0.8183\n",
      "[Sample] d_loss: 1.17683494, g_loss: 0.81155097\n",
      "Epoch: [ 4] [ 996/1093] time: 6175.5342, d_loss: 1.2541, g_loss: 0.8021\n",
      "[Sample] d_loss: 1.19570684, g_loss: 0.79855025\n",
      "Epoch: [ 4] [1006/1093] time: 6180.1092, d_loss: 1.1753, g_loss: 0.8311\n",
      "[Sample] d_loss: 1.17857337, g_loss: 0.81100196\n",
      "Epoch: [ 4] [1016/1093] time: 6184.6414, d_loss: 1.2217, g_loss: 0.8074\n",
      "[Sample] d_loss: 1.17790103, g_loss: 0.81672287\n",
      "Epoch: [ 4] [1026/1093] time: 6188.9365, d_loss: 1.1893, g_loss: 0.8301\n",
      "[Sample] d_loss: 1.18217301, g_loss: 0.80601293\n",
      "Epoch: [ 4] [1036/1093] time: 6193.2522, d_loss: 1.2015, g_loss: 0.8105\n",
      "[Sample] d_loss: 1.17839122, g_loss: 0.80712676\n",
      "Epoch: [ 4] [1046/1093] time: 6197.4815, d_loss: 1.2377, g_loss: 0.7975\n",
      "[Sample] d_loss: 1.18234563, g_loss: 0.80706036\n",
      "Epoch: [ 4] [1056/1093] time: 6201.8881, d_loss: 1.1789, g_loss: 0.8367\n",
      "[Sample] d_loss: 1.17128038, g_loss: 0.82291478\n",
      "Epoch: [ 4] [1066/1093] time: 6206.2702, d_loss: 1.2241, g_loss: 0.8213\n",
      "[Sample] d_loss: 1.16733646, g_loss: 0.82634807\n",
      "Epoch: [ 4] [1076/1093] time: 6210.7563, d_loss: 1.2011, g_loss: 0.8211\n",
      "[Sample] d_loss: 1.17064357, g_loss: 0.82852387\n",
      "Epoch: [ 4] [1086/1093] time: 6214.7260, d_loss: 1.1691, g_loss: 0.8287\n",
      "[Sample] d_loss: 1.17889380, g_loss: 0.82335484\n",
      "[Sample] d_loss: 1.19225919, g_loss: 0.80613953\n",
      "Epoch: [ 5] [   3/1093] time: 6218.8569, d_loss: 1.2306, g_loss: 0.8222\n",
      "[Sample] d_loss: 1.17436457, g_loss: 0.82020098\n",
      "Epoch: [ 5] [  13/1093] time: 6223.5887, d_loss: 1.1815, g_loss: 0.8262\n",
      "[Sample] d_loss: 1.16923857, g_loss: 0.82355487\n",
      "Epoch: [ 5] [  23/1093] time: 6228.1846, d_loss: 1.2205, g_loss: 0.8072\n",
      "[Sample] d_loss: 1.17338085, g_loss: 0.81722814\n",
      "Epoch: [ 5] [  33/1093] time: 6232.2758, d_loss: 1.2064, g_loss: 0.8262\n",
      "[Sample] d_loss: 1.17907262, g_loss: 0.80672729\n",
      "Epoch: [ 5] [  43/1093] time: 6236.4712, d_loss: 1.1925, g_loss: 0.8310\n",
      "[Sample] d_loss: 1.18135726, g_loss: 0.81128871\n",
      "Epoch: [ 5] [  53/1093] time: 6240.6991, d_loss: 1.2338, g_loss: 0.7963\n",
      "[Sample] d_loss: 1.18525088, g_loss: 0.81048918\n",
      "Epoch: [ 5] [  63/1093] time: 6245.0487, d_loss: 1.1957, g_loss: 0.8119\n",
      "[Sample] d_loss: 1.17636657, g_loss: 0.82331705\n",
      "Epoch: [ 5] [  73/1093] time: 6248.9897, d_loss: 1.2360, g_loss: 0.8002\n",
      "[Sample] d_loss: 1.17441487, g_loss: 0.82066011\n",
      "Epoch: [ 5] [  83/1093] time: 6252.8784, d_loss: 1.1978, g_loss: 0.8040\n",
      "[Sample] d_loss: 1.17129040, g_loss: 0.83445966\n",
      "Epoch: [ 5] [  93/1093] time: 6257.3852, d_loss: 1.2057, g_loss: 0.8059\n",
      "[Sample] d_loss: 1.16038513, g_loss: 0.83646739\n",
      "Epoch: [ 5] [ 103/1093] time: 6261.6902, d_loss: 1.1834, g_loss: 0.8149\n",
      "[Sample] d_loss: 1.16271281, g_loss: 0.82655108\n",
      "Epoch: [ 5] [ 113/1093] time: 6265.7034, d_loss: 1.2388, g_loss: 0.7798\n",
      "[Sample] d_loss: 1.17804027, g_loss: 0.81227964\n",
      "Epoch: [ 5] [ 123/1093] time: 6270.2501, d_loss: 1.2162, g_loss: 0.7945\n",
      "[Sample] d_loss: 1.17047167, g_loss: 0.82814646\n",
      "Epoch: [ 5] [ 133/1093] time: 6274.7097, d_loss: 1.2284, g_loss: 0.7978\n",
      "[Sample] d_loss: 1.15934765, g_loss: 0.83059162\n",
      "Epoch: [ 5] [ 143/1093] time: 6278.9554, d_loss: 1.2142, g_loss: 0.7953\n",
      "[Sample] d_loss: 1.18299234, g_loss: 0.80690515\n",
      "Epoch: [ 5] [ 153/1093] time: 6282.9329, d_loss: 1.2394, g_loss: 0.7994\n",
      "[Sample] d_loss: 1.17315650, g_loss: 0.82730281\n",
      "Epoch: [ 5] [ 163/1093] time: 6286.8863, d_loss: 1.1735, g_loss: 0.8091\n",
      "[Sample] d_loss: 1.17251027, g_loss: 0.82291591\n",
      "Epoch: [ 5] [ 173/1093] time: 6290.8599, d_loss: 1.1680, g_loss: 0.8091\n",
      "[Sample] d_loss: 1.18766046, g_loss: 0.79792601\n",
      "Epoch: [ 5] [ 183/1093] time: 6294.9541, d_loss: 1.2277, g_loss: 0.7918\n",
      "[Sample] d_loss: 1.17589462, g_loss: 0.81648815\n",
      "Epoch: [ 5] [ 193/1093] time: 6298.8278, d_loss: 1.2237, g_loss: 0.7874\n",
      "[Sample] d_loss: 1.17445767, g_loss: 0.82254368\n",
      "Epoch: [ 5] [ 203/1093] time: 6302.6988, d_loss: 1.1945, g_loss: 0.7963\n",
      "[Sample] d_loss: 1.15737677, g_loss: 0.84122896\n",
      "Epoch: [ 5] [ 213/1093] time: 6306.5613, d_loss: 1.2068, g_loss: 0.7914\n",
      "[Sample] d_loss: 1.17129469, g_loss: 0.83142114\n",
      "Epoch: [ 5] [ 223/1093] time: 6310.4205, d_loss: 1.2235, g_loss: 0.7836\n",
      "[Sample] d_loss: 1.18537450, g_loss: 0.81596386\n",
      "Epoch: [ 5] [ 233/1093] time: 6314.5769, d_loss: 1.2114, g_loss: 0.8065\n",
      "[Sample] d_loss: 1.16678250, g_loss: 0.82571435\n",
      "Epoch: [ 5] [ 243/1093] time: 6319.7476, d_loss: 1.2148, g_loss: 0.8279\n",
      "[Sample] d_loss: 1.17301655, g_loss: 0.82349956\n",
      "Epoch: [ 5] [ 253/1093] time: 6323.9204, d_loss: 1.1920, g_loss: 0.8033\n",
      "[Sample] d_loss: 1.15678108, g_loss: 0.84169245\n",
      "Epoch: [ 5] [ 263/1093] time: 6327.9488, d_loss: 1.2324, g_loss: 0.8329\n",
      "[Sample] d_loss: 1.16874290, g_loss: 0.82819200\n",
      "Epoch: [ 5] [ 273/1093] time: 6331.8731, d_loss: 1.1926, g_loss: 0.8122\n",
      "[Sample] d_loss: 1.17101312, g_loss: 0.82966822\n",
      "Epoch: [ 5] [ 283/1093] time: 6335.8803, d_loss: 1.2438, g_loss: 0.8044\n",
      "[Sample] d_loss: 1.17303514, g_loss: 0.81717533\n",
      "Epoch: [ 5] [ 293/1093] time: 6340.1104, d_loss: 1.2775, g_loss: 0.7998\n",
      "[Sample] d_loss: 1.17777896, g_loss: 0.81759787\n",
      "Epoch: [ 5] [ 303/1093] time: 6344.9323, d_loss: 1.2164, g_loss: 0.8160\n",
      "[Sample] d_loss: 1.17321873, g_loss: 0.82039738\n",
      "Epoch: [ 5] [ 313/1093] time: 6349.4761, d_loss: 1.2384, g_loss: 0.8071\n",
      "[Sample] d_loss: 1.17811012, g_loss: 0.81284249\n",
      "Epoch: [ 5] [ 323/1093] time: 6353.5481, d_loss: 1.2381, g_loss: 0.7966\n",
      "[Sample] d_loss: 1.16728497, g_loss: 0.83236355\n",
      "Epoch: [ 5] [ 333/1093] time: 6357.4480, d_loss: 1.2629, g_loss: 0.7557\n",
      "[Sample] d_loss: 1.17352748, g_loss: 0.82916832\n",
      "Epoch: [ 5] [ 343/1093] time: 6361.3054, d_loss: 1.1711, g_loss: 0.7942\n",
      "[Sample] d_loss: 1.17912138, g_loss: 0.81923646\n",
      "Epoch: [ 5] [ 353/1093] time: 6365.4481, d_loss: 1.2187, g_loss: 0.7955\n",
      "[Sample] d_loss: 1.16479635, g_loss: 0.83787549\n",
      "Epoch: [ 5] [ 363/1093] time: 6369.6733, d_loss: 1.2920, g_loss: 0.7964\n",
      "[Sample] d_loss: 1.17109394, g_loss: 0.83512759\n",
      "Epoch: [ 5] [ 373/1093] time: 6373.7580, d_loss: 1.2589, g_loss: 0.7925\n",
      "[Sample] d_loss: 1.18343520, g_loss: 0.81928116\n",
      "Epoch: [ 5] [ 383/1093] time: 6377.6549, d_loss: 1.2195, g_loss: 0.8057\n",
      "[Sample] d_loss: 1.17744696, g_loss: 0.83271956\n",
      "Epoch: [ 5] [ 393/1093] time: 6381.5585, d_loss: 1.2356, g_loss: 0.8190\n",
      "[Sample] d_loss: 1.16365290, g_loss: 0.83803976\n",
      "Epoch: [ 5] [ 403/1093] time: 6385.4197, d_loss: 1.1795, g_loss: 0.8186\n",
      "[Sample] d_loss: 1.16800368, g_loss: 0.84047306\n",
      "Epoch: [ 5] [ 413/1093] time: 6389.2644, d_loss: 1.2102, g_loss: 0.7866\n",
      "[Sample] d_loss: 1.16525745, g_loss: 0.83862692\n",
      "Epoch: [ 5] [ 423/1093] time: 6393.1382, d_loss: 1.2152, g_loss: 0.8167\n",
      "[Sample] d_loss: 1.16290712, g_loss: 0.84390354\n",
      "Epoch: [ 5] [ 433/1093] time: 6397.0512, d_loss: 1.1592, g_loss: 0.8174\n",
      "[Sample] d_loss: 1.16489553, g_loss: 0.83937657\n",
      "Epoch: [ 5] [ 443/1093] time: 6400.9150, d_loss: 1.2209, g_loss: 0.8163\n",
      "[Sample] d_loss: 1.16961098, g_loss: 0.82780027\n",
      "Epoch: [ 5] [ 453/1093] time: 6404.7455, d_loss: 1.2249, g_loss: 0.8023\n",
      "[Sample] d_loss: 1.17199349, g_loss: 0.82502252\n",
      "Epoch: [ 5] [ 463/1093] time: 6408.6221, d_loss: 1.1480, g_loss: 0.8332\n",
      "[Sample] d_loss: 1.16921163, g_loss: 0.82566488\n",
      "Epoch: [ 5] [ 473/1093] time: 6412.4876, d_loss: 1.1698, g_loss: 0.8219\n",
      "[Sample] d_loss: 1.17381048, g_loss: 0.82871175\n",
      "Epoch: [ 5] [ 483/1093] time: 6416.3307, d_loss: 1.1853, g_loss: 0.8184\n",
      "[Sample] d_loss: 1.18306017, g_loss: 0.81940567\n",
      "Epoch: [ 5] [ 493/1093] time: 6420.3824, d_loss: 1.1760, g_loss: 0.8471\n",
      "[Sample] d_loss: 1.16487479, g_loss: 0.83375794\n",
      "Epoch: [ 5] [ 503/1093] time: 6424.4456, d_loss: 1.2375, g_loss: 0.8021\n",
      "[Sample] d_loss: 1.17896521, g_loss: 0.82461369\n",
      "Epoch: [ 5] [ 513/1093] time: 6428.5349, d_loss: 1.2662, g_loss: 0.8149\n",
      "[Sample] d_loss: 1.16429031, g_loss: 0.83281338\n",
      "Epoch: [ 5] [ 523/1093] time: 6432.4950, d_loss: 1.1636, g_loss: 0.8219\n",
      "[Sample] d_loss: 1.16354060, g_loss: 0.83629239\n",
      "Epoch: [ 5] [ 533/1093] time: 6436.5941, d_loss: 1.1848, g_loss: 0.8348\n",
      "[Sample] d_loss: 1.16438520, g_loss: 0.83669472\n",
      "Epoch: [ 5] [ 543/1093] time: 6440.5749, d_loss: 1.1824, g_loss: 0.8058\n",
      "[Sample] d_loss: 1.18568683, g_loss: 0.81256914\n",
      "Epoch: [ 5] [ 553/1093] time: 6444.5241, d_loss: 1.2364, g_loss: 0.7946\n",
      "[Sample] d_loss: 1.17658508, g_loss: 0.82248020\n",
      "Epoch: [ 5] [ 563/1093] time: 6448.4374, d_loss: 1.1809, g_loss: 0.8207\n",
      "[Sample] d_loss: 1.16419125, g_loss: 0.84683156\n",
      "Epoch: [ 5] [ 573/1093] time: 6452.3318, d_loss: 1.1890, g_loss: 0.8142\n",
      "[Sample] d_loss: 1.16768336, g_loss: 0.83591390\n",
      "Epoch: [ 5] [ 583/1093] time: 6456.2259, d_loss: 1.2500, g_loss: 0.8048\n",
      "[Sample] d_loss: 1.15944362, g_loss: 0.85304379\n",
      "Epoch: [ 5] [ 593/1093] time: 6460.1192, d_loss: 1.1997, g_loss: 0.8300\n",
      "[Sample] d_loss: 1.16127276, g_loss: 0.84689915\n",
      "Epoch: [ 5] [ 603/1093] time: 6463.9858, d_loss: 1.1959, g_loss: 0.8365\n",
      "[Sample] d_loss: 1.18840301, g_loss: 0.80894649\n",
      "Epoch: [ 5] [ 613/1093] time: 6467.9153, d_loss: 1.2345, g_loss: 0.8240\n",
      "[Sample] d_loss: 1.17945385, g_loss: 0.81819594\n",
      "Epoch: [ 5] [ 623/1093] time: 6471.8030, d_loss: 1.2087, g_loss: 0.8018\n",
      "[Sample] d_loss: 1.16525090, g_loss: 0.83535939\n",
      "Epoch: [ 5] [ 633/1093] time: 6475.7619, d_loss: 1.1955, g_loss: 0.8076\n",
      "[Sample] d_loss: 1.17581904, g_loss: 0.82088172\n",
      "Epoch: [ 5] [ 643/1093] time: 6479.8941, d_loss: 1.1829, g_loss: 0.8002\n",
      "[Sample] d_loss: 1.18156815, g_loss: 0.81828082\n",
      "Epoch: [ 5] [ 653/1093] time: 6483.9769, d_loss: 1.1883, g_loss: 0.7999\n",
      "[Sample] d_loss: 1.15862417, g_loss: 0.83817315\n",
      "Epoch: [ 5] [ 663/1093] time: 6488.0375, d_loss: 1.2051, g_loss: 0.8026\n",
      "[Sample] d_loss: 1.16401947, g_loss: 0.83041912\n",
      "Epoch: [ 5] [ 673/1093] time: 6492.1345, d_loss: 1.1881, g_loss: 0.7937\n",
      "[Sample] d_loss: 1.17130303, g_loss: 0.82067943\n",
      "Epoch: [ 5] [ 683/1093] time: 6496.3603, d_loss: 1.1689, g_loss: 0.8063\n",
      "[Sample] d_loss: 1.17106545, g_loss: 0.81288767\n",
      "Epoch: [ 5] [ 693/1093] time: 6500.6844, d_loss: 1.1557, g_loss: 0.8241\n",
      "[Sample] d_loss: 1.16599441, g_loss: 0.83269441\n",
      "Epoch: [ 5] [ 703/1093] time: 6505.1065, d_loss: 1.1897, g_loss: 0.8158\n",
      "[Sample] d_loss: 1.16119075, g_loss: 0.84295464\n",
      "Epoch: [ 5] [ 713/1093] time: 6509.5752, d_loss: 1.1657, g_loss: 0.8362\n",
      "[Sample] d_loss: 1.16591656, g_loss: 0.82890517\n",
      "Epoch: [ 5] [ 723/1093] time: 6513.7701, d_loss: 1.2684, g_loss: 0.8319\n",
      "[Sample] d_loss: 1.16899586, g_loss: 0.82744986\n",
      "Epoch: [ 5] [ 733/1093] time: 6517.9460, d_loss: 1.2204, g_loss: 0.7958\n",
      "[Sample] d_loss: 1.15576053, g_loss: 0.84194446\n",
      "Epoch: [ 5] [ 743/1093] time: 6521.9441, d_loss: 1.2415, g_loss: 0.8208\n",
      "[Sample] d_loss: 1.17451954, g_loss: 0.82488084\n",
      "Epoch: [ 5] [ 753/1093] time: 6525.9223, d_loss: 1.2021, g_loss: 0.7945\n",
      "[Sample] d_loss: 1.17637420, g_loss: 0.81855559\n",
      "Epoch: [ 5] [ 763/1093] time: 6529.8638, d_loss: 1.2047, g_loss: 0.8250\n",
      "[Sample] d_loss: 1.17355180, g_loss: 0.82800555\n",
      "Epoch: [ 5] [ 773/1093] time: 6533.8895, d_loss: 1.2025, g_loss: 0.8065\n",
      "[Sample] d_loss: 1.15166032, g_loss: 0.85358655\n",
      "Epoch: [ 5] [ 783/1093] time: 6537.8900, d_loss: 1.1793, g_loss: 0.8191\n",
      "[Sample] d_loss: 1.16045594, g_loss: 0.84055722\n",
      "Epoch: [ 5] [ 793/1093] time: 6541.7470, d_loss: 1.1939, g_loss: 0.8265\n",
      "[Sample] d_loss: 1.16286528, g_loss: 0.83955413\n",
      "Epoch: [ 5] [ 803/1093] time: 6545.6343, d_loss: 1.2232, g_loss: 0.8284\n",
      "[Sample] d_loss: 1.14771485, g_loss: 0.85568607\n",
      "Epoch: [ 5] [ 813/1093] time: 6549.5231, d_loss: 1.2017, g_loss: 0.8129\n",
      "[Sample] d_loss: 1.15145850, g_loss: 0.84686631\n",
      "Epoch: [ 5] [ 823/1093] time: 6553.4027, d_loss: 1.2199, g_loss: 0.8152\n",
      "[Sample] d_loss: 1.14540434, g_loss: 0.84977835\n",
      "Epoch: [ 5] [ 833/1093] time: 6557.2949, d_loss: 1.2241, g_loss: 0.8208\n",
      "[Sample] d_loss: 1.15028584, g_loss: 0.85117567\n",
      "Epoch: [ 5] [ 843/1093] time: 6561.1988, d_loss: 1.1677, g_loss: 0.8340\n",
      "[Sample] d_loss: 1.14477777, g_loss: 0.85761684\n",
      "Epoch: [ 5] [ 853/1093] time: 6565.0747, d_loss: 1.2047, g_loss: 0.8310\n",
      "[Sample] d_loss: 1.15313327, g_loss: 0.85454518\n",
      "Epoch: [ 5] [ 863/1093] time: 6568.9928, d_loss: 1.1419, g_loss: 0.8320\n",
      "[Sample] d_loss: 1.14950955, g_loss: 0.84434330\n",
      "Epoch: [ 5] [ 873/1093] time: 6572.8923, d_loss: 1.1494, g_loss: 0.8341\n",
      "[Sample] d_loss: 1.15852582, g_loss: 0.83400917\n",
      "Epoch: [ 5] [ 883/1093] time: 6576.8570, d_loss: 1.1352, g_loss: 0.8139\n",
      "[Sample] d_loss: 1.14665842, g_loss: 0.85032892\n",
      "Epoch: [ 5] [ 893/1093] time: 6580.9795, d_loss: 1.1661, g_loss: 0.8331\n",
      "[Sample] d_loss: 1.15712690, g_loss: 0.83045280\n",
      "Epoch: [ 5] [ 903/1093] time: 6585.0029, d_loss: 1.1329, g_loss: 0.8490\n",
      "[Sample] d_loss: 1.15646434, g_loss: 0.83154738\n",
      "Epoch: [ 5] [ 913/1093] time: 6589.0175, d_loss: 1.2461, g_loss: 0.8300\n",
      "[Sample] d_loss: 1.15038288, g_loss: 0.83690947\n",
      "Epoch: [ 5] [ 923/1093] time: 6593.0862, d_loss: 1.1804, g_loss: 0.8359\n",
      "[Sample] d_loss: 1.14791393, g_loss: 0.84618711\n",
      "Epoch: [ 5] [ 933/1093] time: 6597.2446, d_loss: 1.1970, g_loss: 0.8125\n",
      "[Sample] d_loss: 1.15272582, g_loss: 0.83689600\n",
      "Epoch: [ 5] [ 943/1093] time: 6601.2651, d_loss: 1.2022, g_loss: 0.8020\n",
      "[Sample] d_loss: 1.15494657, g_loss: 0.83681464\n",
      "Epoch: [ 5] [ 953/1093] time: 6605.3941, d_loss: 1.1954, g_loss: 0.8155\n",
      "[Sample] d_loss: 1.14867628, g_loss: 0.84246612\n",
      "Epoch: [ 5] [ 963/1093] time: 6609.5151, d_loss: 1.1518, g_loss: 0.8073\n",
      "[Sample] d_loss: 1.14412093, g_loss: 0.84817994\n",
      "Epoch: [ 5] [ 973/1093] time: 6613.5185, d_loss: 1.2091, g_loss: 0.8525\n",
      "[Sample] d_loss: 1.16506147, g_loss: 0.83131510\n",
      "Epoch: [ 5] [ 983/1093] time: 6617.9337, d_loss: 1.1511, g_loss: 0.8082\n",
      "[Sample] d_loss: 1.15802515, g_loss: 0.83378649\n",
      "Epoch: [ 5] [ 993/1093] time: 6622.3075, d_loss: 1.2297, g_loss: 0.8207\n",
      "[Sample] d_loss: 1.17235100, g_loss: 0.80775803\n",
      "Epoch: [ 5] [1003/1093] time: 6627.0684, d_loss: 1.1353, g_loss: 0.8274\n",
      "[Sample] d_loss: 1.16925490, g_loss: 0.82028884\n",
      "Epoch: [ 5] [1013/1093] time: 6631.4096, d_loss: 1.2160, g_loss: 0.7853\n",
      "[Sample] d_loss: 1.16187251, g_loss: 0.82498658\n",
      "Epoch: [ 5] [1023/1093] time: 6635.8720, d_loss: 1.1960, g_loss: 0.8225\n",
      "[Sample] d_loss: 1.17013526, g_loss: 0.82033420\n",
      "Epoch: [ 5] [1033/1093] time: 6639.9436, d_loss: 1.2155, g_loss: 0.7978\n",
      "[Sample] d_loss: 1.17163420, g_loss: 0.82096589\n",
      "Epoch: [ 5] [1043/1093] time: 6644.8863, d_loss: 1.1859, g_loss: 0.8233\n",
      "[Sample] d_loss: 1.16926289, g_loss: 0.81356096\n",
      "Epoch: [ 5] [1053/1093] time: 6650.1230, d_loss: 1.2337, g_loss: 0.8060\n",
      "[Sample] d_loss: 1.16669059, g_loss: 0.82249737\n",
      "Epoch: [ 5] [1063/1093] time: 6654.4291, d_loss: 1.2187, g_loss: 0.8066\n",
      "[Sample] d_loss: 1.15869915, g_loss: 0.82830131\n",
      "Epoch: [ 5] [1073/1093] time: 6658.8883, d_loss: 1.2416, g_loss: 0.7869\n",
      "[Sample] d_loss: 1.16404653, g_loss: 0.81714499\n",
      "Epoch: [ 5] [1083/1093] time: 6663.0975, d_loss: 1.1606, g_loss: 0.8384\n",
      "[Sample] d_loss: 1.17920423, g_loss: 0.81693423\n",
      "Epoch: [ 6] [   0/1093] time: 6667.7227, d_loss: 1.2388, g_loss: 0.7819\n",
      "[Sample] d_loss: 1.17763352, g_loss: 0.82268000\n",
      "Epoch: [ 6] [  10/1093] time: 6673.2025, d_loss: 1.1655, g_loss: 0.8226\n",
      "[Sample] d_loss: 1.17746782, g_loss: 0.81301945\n",
      "Epoch: [ 6] [  20/1093] time: 6678.3927, d_loss: 1.2962, g_loss: 0.8050\n",
      "[Sample] d_loss: 1.16720581, g_loss: 0.82001436\n",
      "Epoch: [ 6] [  30/1093] time: 6682.9714, d_loss: 1.2203, g_loss: 0.8176\n",
      "[Sample] d_loss: 1.16525745, g_loss: 0.82142353\n",
      "Epoch: [ 6] [  40/1093] time: 6687.2498, d_loss: 1.1563, g_loss: 0.8262\n",
      "[Sample] d_loss: 1.17690825, g_loss: 0.80716836\n",
      "Epoch: [ 6] [  50/1093] time: 6691.4136, d_loss: 1.1785, g_loss: 0.8206\n",
      "[Sample] d_loss: 1.18185902, g_loss: 0.80437112\n",
      "Epoch: [ 6] [  60/1093] time: 6695.6419, d_loss: 1.1639, g_loss: 0.8307\n",
      "[Sample] d_loss: 1.16342235, g_loss: 0.83129489\n",
      "Epoch: [ 6] [  70/1093] time: 6700.3254, d_loss: 1.1907, g_loss: 0.8131\n",
      "[Sample] d_loss: 1.17340708, g_loss: 0.82739794\n",
      "Epoch: [ 6] [  80/1093] time: 6704.9322, d_loss: 1.2198, g_loss: 0.8188\n",
      "[Sample] d_loss: 1.16679621, g_loss: 0.82283735\n",
      "Epoch: [ 6] [  90/1093] time: 6709.1496, d_loss: 1.1999, g_loss: 0.8082\n",
      "[Sample] d_loss: 1.16160679, g_loss: 0.83335972\n",
      "Epoch: [ 6] [ 100/1093] time: 6713.2222, d_loss: 1.1948, g_loss: 0.8109\n",
      "[Sample] d_loss: 1.16601408, g_loss: 0.82845485\n",
      "Epoch: [ 6] [ 110/1093] time: 6717.2153, d_loss: 1.1912, g_loss: 0.8051\n",
      "[Sample] d_loss: 1.16835880, g_loss: 0.82238477\n",
      "Epoch: [ 6] [ 120/1093] time: 6721.2035, d_loss: 1.1668, g_loss: 0.8282\n",
      "[Sample] d_loss: 1.17193604, g_loss: 0.82441151\n",
      "Epoch: [ 6] [ 130/1093] time: 6725.2105, d_loss: 1.2158, g_loss: 0.8179\n",
      "[Sample] d_loss: 1.16903090, g_loss: 0.82737935\n",
      "Epoch: [ 6] [ 140/1093] time: 6729.2119, d_loss: 1.2108, g_loss: 0.8098\n",
      "[Sample] d_loss: 1.17041695, g_loss: 0.82646286\n",
      "Epoch: [ 6] [ 150/1093] time: 6733.4902, d_loss: 1.1641, g_loss: 0.8268\n",
      "[Sample] d_loss: 1.16273141, g_loss: 0.82703048\n",
      "Epoch: [ 6] [ 160/1093] time: 6737.5915, d_loss: 1.2303, g_loss: 0.8339\n",
      "[Sample] d_loss: 1.14824605, g_loss: 0.85950863\n",
      "Epoch: [ 6] [ 170/1093] time: 6742.2003, d_loss: 1.2605, g_loss: 0.8131\n",
      "[Sample] d_loss: 1.15596020, g_loss: 0.83478904\n",
      "Epoch: [ 6] [ 180/1093] time: 6747.2395, d_loss: 1.1516, g_loss: 0.8323\n",
      "[Sample] d_loss: 1.16211343, g_loss: 0.83480597\n",
      "Epoch: [ 6] [ 190/1093] time: 6751.7456, d_loss: 1.2161, g_loss: 0.8026\n",
      "[Sample] d_loss: 1.14702344, g_loss: 0.84644067\n",
      "Epoch: [ 6] [ 200/1093] time: 6759.4244, d_loss: 1.1402, g_loss: 0.8308\n",
      "[Sample] d_loss: 1.17229295, g_loss: 0.81575704\n",
      "Epoch: [ 6] [ 210/1093] time: 6763.3608, d_loss: 1.1805, g_loss: 0.8435\n",
      "[Sample] d_loss: 1.16780198, g_loss: 0.82781255\n",
      "Epoch: [ 6] [ 220/1093] time: 6767.3461, d_loss: 1.1617, g_loss: 0.8491\n",
      "[Sample] d_loss: 1.15378892, g_loss: 0.84139520\n",
      "Epoch: [ 6] [ 230/1093] time: 6771.2898, d_loss: 1.1815, g_loss: 0.8245\n",
      "[Sample] d_loss: 1.17598426, g_loss: 0.82007384\n",
      "Epoch: [ 6] [ 240/1093] time: 6775.7799, d_loss: 1.2130, g_loss: 0.8214\n",
      "[Sample] d_loss: 1.15125382, g_loss: 0.84366417\n",
      "Epoch: [ 6] [ 250/1093] time: 6780.5673, d_loss: 1.2275, g_loss: 0.8079\n",
      "[Sample] d_loss: 1.15787685, g_loss: 0.83690321\n",
      "Epoch: [ 6] [ 260/1093] time: 6784.7554, d_loss: 1.2258, g_loss: 0.7998\n",
      "[Sample] d_loss: 1.14953971, g_loss: 0.85069484\n",
      "Epoch: [ 6] [ 270/1093] time: 6789.2632, d_loss: 1.1747, g_loss: 0.7945\n",
      "[Sample] d_loss: 1.15279794, g_loss: 0.84202087\n",
      "Epoch: [ 6] [ 280/1093] time: 6794.2906, d_loss: 1.1861, g_loss: 0.8239\n",
      "[Sample] d_loss: 1.15797055, g_loss: 0.84023201\n",
      "Epoch: [ 6] [ 290/1093] time: 6798.9469, d_loss: 1.2283, g_loss: 0.8172\n",
      "[Sample] d_loss: 1.15971804, g_loss: 0.83040953\n",
      "Epoch: [ 6] [ 300/1093] time: 6802.8883, d_loss: 1.1600, g_loss: 0.8179\n",
      "[Sample] d_loss: 1.15875971, g_loss: 0.84278804\n",
      "Epoch: [ 6] [ 310/1093] time: 6806.8474, d_loss: 1.1520, g_loss: 0.8226\n",
      "[Sample] d_loss: 1.17772639, g_loss: 0.81854880\n",
      "Epoch: [ 6] [ 320/1093] time: 6810.7984, d_loss: 1.1878, g_loss: 0.8034\n",
      "[Sample] d_loss: 1.16365671, g_loss: 0.83031976\n",
      "Epoch: [ 6] [ 330/1093] time: 6814.7497, d_loss: 1.2254, g_loss: 0.7976\n",
      "[Sample] d_loss: 1.16397536, g_loss: 0.84748435\n",
      "Epoch: [ 6] [ 340/1093] time: 6818.7884, d_loss: 1.2183, g_loss: 0.8041\n",
      "[Sample] d_loss: 1.16577506, g_loss: 0.83204257\n",
      "Epoch: [ 6] [ 350/1093] time: 6822.7702, d_loss: 1.2109, g_loss: 0.8183\n",
      "[Sample] d_loss: 1.16918731, g_loss: 0.83359993\n",
      "Epoch: [ 6] [ 360/1093] time: 6826.6978, d_loss: 1.1793, g_loss: 0.8040\n",
      "[Sample] d_loss: 1.17767227, g_loss: 0.81741357\n",
      "Epoch: [ 6] [ 370/1093] time: 6830.7337, d_loss: 1.1666, g_loss: 0.8341\n",
      "[Sample] d_loss: 1.17117286, g_loss: 0.82222581\n",
      "Epoch: [ 6] [ 380/1093] time: 6834.9076, d_loss: 1.1836, g_loss: 0.8292\n",
      "[Sample] d_loss: 1.16175401, g_loss: 0.83223379\n",
      "Epoch: [ 6] [ 390/1093] time: 6839.0376, d_loss: 1.2017, g_loss: 0.8264\n",
      "[Sample] d_loss: 1.17705107, g_loss: 0.81731552\n",
      "Epoch: [ 6] [ 400/1093] time: 6843.1482, d_loss: 1.2202, g_loss: 0.8090\n",
      "[Sample] d_loss: 1.17031622, g_loss: 0.82287252\n",
      "Epoch: [ 6] [ 410/1093] time: 6847.2640, d_loss: 1.2087, g_loss: 0.8421\n",
      "[Sample] d_loss: 1.17394745, g_loss: 0.82030505\n",
      "Epoch: [ 6] [ 420/1093] time: 6851.2726, d_loss: 1.2249, g_loss: 0.8069\n",
      "[Sample] d_loss: 1.17081785, g_loss: 0.81769884\n",
      "Epoch: [ 6] [ 430/1093] time: 6855.2485, d_loss: 1.2161, g_loss: 0.8373\n",
      "[Sample] d_loss: 1.17355752, g_loss: 0.81431806\n",
      "Epoch: [ 6] [ 440/1093] time: 6859.2441, d_loss: 1.1644, g_loss: 0.8197\n",
      "[Sample] d_loss: 1.18239808, g_loss: 0.81093061\n",
      "Epoch: [ 6] [ 450/1093] time: 6863.2924, d_loss: 1.2035, g_loss: 0.8205\n",
      "[Sample] d_loss: 1.18260157, g_loss: 0.80847919\n",
      "Epoch: [ 6] [ 460/1093] time: 6867.3975, d_loss: 1.1685, g_loss: 0.8269\n",
      "[Sample] d_loss: 1.17539871, g_loss: 0.81589401\n",
      "Epoch: [ 6] [ 470/1093] time: 6871.4441, d_loss: 1.1922, g_loss: 0.8394\n",
      "[Sample] d_loss: 1.17541957, g_loss: 0.81255925\n",
      "Epoch: [ 6] [ 480/1093] time: 6875.3966, d_loss: 1.2488, g_loss: 0.8162\n",
      "[Sample] d_loss: 1.18093777, g_loss: 0.80992717\n",
      "Epoch: [ 6] [ 490/1093] time: 6879.4146, d_loss: 1.2330, g_loss: 0.8079\n",
      "[Sample] d_loss: 1.16816163, g_loss: 0.82720160\n",
      "Epoch: [ 6] [ 500/1093] time: 6883.4400, d_loss: 1.2126, g_loss: 0.7960\n",
      "[Sample] d_loss: 1.17136884, g_loss: 0.81504679\n",
      "Epoch: [ 6] [ 510/1093] time: 6887.3527, d_loss: 1.2159, g_loss: 0.8053\n",
      "[Sample] d_loss: 1.17868066, g_loss: 0.81465137\n",
      "Epoch: [ 6] [ 520/1093] time: 6891.4260, d_loss: 1.1682, g_loss: 0.8245\n",
      "[Sample] d_loss: 1.18127227, g_loss: 0.81142122\n",
      "Epoch: [ 6] [ 530/1093] time: 6895.6010, d_loss: 1.1248, g_loss: 0.8253\n",
      "[Sample] d_loss: 1.18463564, g_loss: 0.80364019\n",
      "Epoch: [ 6] [ 540/1093] time: 6899.6419, d_loss: 1.1558, g_loss: 0.8274\n",
      "[Sample] d_loss: 1.18641341, g_loss: 0.80623579\n",
      "Epoch: [ 6] [ 550/1093] time: 6903.5953, d_loss: 1.1936, g_loss: 0.8165\n",
      "[Sample] d_loss: 1.15729260, g_loss: 0.84010792\n",
      "Epoch: [ 6] [ 560/1093] time: 6907.5652, d_loss: 1.1739, g_loss: 0.8150\n",
      "[Sample] d_loss: 1.17814207, g_loss: 0.81332552\n",
      "Epoch: [ 6] [ 570/1093] time: 6912.0245, d_loss: 1.2325, g_loss: 0.8073\n",
      "[Sample] d_loss: 1.17303753, g_loss: 0.81663036\n",
      "Epoch: [ 6] [ 580/1093] time: 6916.1069, d_loss: 1.1672, g_loss: 0.8361\n",
      "[Sample] d_loss: 1.16650558, g_loss: 0.82889014\n",
      "Epoch: [ 6] [ 590/1093] time: 6920.1074, d_loss: 1.1683, g_loss: 0.8187\n",
      "[Sample] d_loss: 1.18362808, g_loss: 0.80808693\n",
      "Epoch: [ 6] [ 600/1093] time: 6924.8133, d_loss: 1.1944, g_loss: 0.8280\n",
      "[Sample] d_loss: 1.18710446, g_loss: 0.79952949\n",
      "Epoch: [ 6] [ 610/1093] time: 6928.8011, d_loss: 1.1802, g_loss: 0.8283\n",
      "[Sample] d_loss: 1.17720246, g_loss: 0.81129479\n",
      "Epoch: [ 6] [ 620/1093] time: 6932.7389, d_loss: 1.2314, g_loss: 0.7969\n",
      "[Sample] d_loss: 1.16866446, g_loss: 0.82240808\n",
      "Epoch: [ 6] [ 630/1093] time: 6936.8121, d_loss: 1.1966, g_loss: 0.8389\n",
      "[Sample] d_loss: 1.16559339, g_loss: 0.82377589\n",
      "Epoch: [ 6] [ 640/1093] time: 6940.9409, d_loss: 1.1962, g_loss: 0.8305\n",
      "[Sample] d_loss: 1.17454672, g_loss: 0.81009293\n",
      "Epoch: [ 6] [ 650/1093] time: 6945.0626, d_loss: 1.2486, g_loss: 0.7722\n",
      "[Sample] d_loss: 1.16897094, g_loss: 0.81973511\n",
      "Epoch: [ 6] [ 660/1093] time: 6949.2725, d_loss: 1.1769, g_loss: 0.7902\n",
      "[Sample] d_loss: 1.15725923, g_loss: 0.83196563\n",
      "Epoch: [ 6] [ 670/1093] time: 6953.3481, d_loss: 1.2348, g_loss: 0.8168\n",
      "[Sample] d_loss: 1.16807294, g_loss: 0.82303643\n",
      "Epoch: [ 6] [ 680/1093] time: 6957.4393, d_loss: 1.1795, g_loss: 0.7935\n",
      "[Sample] d_loss: 1.20102501, g_loss: 0.78032774\n",
      "Epoch: [ 6] [ 690/1093] time: 6961.6690, d_loss: 1.2254, g_loss: 0.8192\n",
      "[Sample] d_loss: 1.18463349, g_loss: 0.81070507\n",
      "Epoch: [ 6] [ 700/1093] time: 6966.0415, d_loss: 1.2483, g_loss: 0.8156\n",
      "[Sample] d_loss: 1.15920782, g_loss: 0.83669758\n",
      "Epoch: [ 6] [ 710/1093] time: 6970.4544, d_loss: 1.2500, g_loss: 0.7862\n",
      "[Sample] d_loss: 1.17392063, g_loss: 0.82197559\n",
      "Epoch: [ 6] [ 720/1093] time: 6974.6479, d_loss: 1.2621, g_loss: 0.8101\n",
      "[Sample] d_loss: 1.17562187, g_loss: 0.81668210\n",
      "Epoch: [ 6] [ 730/1093] time: 6978.8716, d_loss: 1.2573, g_loss: 0.8127\n",
      "[Sample] d_loss: 1.17767477, g_loss: 0.81127870\n",
      "Epoch: [ 6] [ 740/1093] time: 6983.0415, d_loss: 1.2474, g_loss: 0.8057\n",
      "[Sample] d_loss: 1.17420197, g_loss: 0.82080132\n",
      "Epoch: [ 6] [ 750/1093] time: 6987.6655, d_loss: 1.2438, g_loss: 0.7870\n",
      "[Sample] d_loss: 1.18881464, g_loss: 0.80038965\n",
      "Epoch: [ 6] [ 760/1093] time: 6992.0869, d_loss: 1.1932, g_loss: 0.7948\n",
      "[Sample] d_loss: 1.17241943, g_loss: 0.82398498\n",
      "Epoch: [ 6] [ 770/1093] time: 6996.5487, d_loss: 1.2016, g_loss: 0.7905\n",
      "[Sample] d_loss: 1.17803013, g_loss: 0.82448840\n",
      "Epoch: [ 6] [ 780/1093] time: 7000.7215, d_loss: 1.2598, g_loss: 0.7765\n",
      "[Sample] d_loss: 1.17819953, g_loss: 0.81316006\n",
      "Epoch: [ 6] [ 790/1093] time: 7006.1399, d_loss: 1.1988, g_loss: 0.8114\n",
      "[Sample] d_loss: 1.17687297, g_loss: 0.81634837\n",
      "Epoch: [ 6] [ 800/1093] time: 7010.7888, d_loss: 1.1792, g_loss: 0.8273\n",
      "[Sample] d_loss: 1.16017485, g_loss: 0.83767772\n",
      "Epoch: [ 6] [ 810/1093] time: 7016.1069, d_loss: 1.1659, g_loss: 0.8375\n",
      "[Sample] d_loss: 1.16920161, g_loss: 0.83172160\n",
      "Epoch: [ 6] [ 820/1093] time: 7020.3972, d_loss: 1.1951, g_loss: 0.8075\n",
      "[Sample] d_loss: 1.17557609, g_loss: 0.82215780\n",
      "Epoch: [ 6] [ 830/1093] time: 7024.4985, d_loss: 1.2091, g_loss: 0.7970\n",
      "[Sample] d_loss: 1.18279028, g_loss: 0.82277727\n",
      "Epoch: [ 6] [ 840/1093] time: 7029.1952, d_loss: 1.1779, g_loss: 0.8104\n",
      "[Sample] d_loss: 1.19803894, g_loss: 0.80000627\n",
      "Epoch: [ 6] [ 850/1093] time: 7033.5216, d_loss: 1.1872, g_loss: 0.8405\n",
      "[Sample] d_loss: 1.18009591, g_loss: 0.81424832\n",
      "Epoch: [ 6] [ 860/1093] time: 7037.7359, d_loss: 1.1528, g_loss: 0.8202\n",
      "[Sample] d_loss: 1.18131244, g_loss: 0.82246542\n",
      "Epoch: [ 6] [ 870/1093] time: 7042.0860, d_loss: 1.1890, g_loss: 0.8532\n",
      "[Sample] d_loss: 1.16858184, g_loss: 0.83745372\n",
      "Epoch: [ 6] [ 880/1093] time: 7046.3267, d_loss: 1.2226, g_loss: 0.8063\n",
      "[Sample] d_loss: 1.17779946, g_loss: 0.81946242\n",
      "Epoch: [ 6] [ 890/1093] time: 7050.3703, d_loss: 1.1792, g_loss: 0.8089\n",
      "[Sample] d_loss: 1.16486645, g_loss: 0.83820117\n",
      "Epoch: [ 6] [ 900/1093] time: 7054.6171, d_loss: 1.2014, g_loss: 0.7795\n",
      "[Sample] d_loss: 1.17977154, g_loss: 0.81490684\n",
      "Epoch: [ 6] [ 910/1093] time: 7059.2046, d_loss: 1.2054, g_loss: 0.8234\n",
      "[Sample] d_loss: 1.15755546, g_loss: 0.84374923\n",
      "Epoch: [ 6] [ 920/1093] time: 7063.3873, d_loss: 1.2629, g_loss: 0.8166\n",
      "[Sample] d_loss: 1.13718319, g_loss: 0.86764181\n",
      "Epoch: [ 6] [ 930/1093] time: 7067.6809, d_loss: 1.1745, g_loss: 0.8011\n",
      "[Sample] d_loss: 1.14409137, g_loss: 0.85583967\n",
      "Epoch: [ 6] [ 940/1093] time: 7071.8509, d_loss: 1.1787, g_loss: 0.8180\n",
      "[Sample] d_loss: 1.14612627, g_loss: 0.84969699\n",
      "Epoch: [ 6] [ 950/1093] time: 7076.2896, d_loss: 1.1946, g_loss: 0.7963\n",
      "[Sample] d_loss: 1.17091036, g_loss: 0.82100457\n",
      "Epoch: [ 6] [ 960/1093] time: 7080.5469, d_loss: 1.2142, g_loss: 0.8158\n",
      "[Sample] d_loss: 1.17038226, g_loss: 0.81993568\n",
      "Epoch: [ 6] [ 970/1093] time: 7085.1523, d_loss: 1.1795, g_loss: 0.8108\n",
      "[Sample] d_loss: 1.17502308, g_loss: 0.81799185\n",
      "Epoch: [ 6] [ 980/1093] time: 7089.6081, d_loss: 1.2448, g_loss: 0.7952\n",
      "[Sample] d_loss: 1.17567086, g_loss: 0.81581545\n",
      "Epoch: [ 6] [ 990/1093] time: 7093.9717, d_loss: 1.1940, g_loss: 0.8133\n",
      "[Sample] d_loss: 1.17848063, g_loss: 0.80906022\n",
      "Epoch: [ 6] [1000/1093] time: 7098.2746, d_loss: 1.1932, g_loss: 0.7967\n",
      "[Sample] d_loss: 1.18378305, g_loss: 0.80908042\n",
      "Epoch: [ 6] [1010/1093] time: 7102.9472, d_loss: 1.2383, g_loss: 0.8043\n",
      "[Sample] d_loss: 1.17420197, g_loss: 0.82380486\n",
      "Epoch: [ 6] [1020/1093] time: 7107.5540, d_loss: 1.1413, g_loss: 0.8357\n",
      "[Sample] d_loss: 1.16946149, g_loss: 0.82872593\n",
      "Epoch: [ 6] [1030/1093] time: 7112.2547, d_loss: 1.1876, g_loss: 0.8156\n",
      "[Sample] d_loss: 1.16064441, g_loss: 0.83408237\n",
      "Epoch: [ 6] [1040/1093] time: 7116.6068, d_loss: 1.1610, g_loss: 0.8286\n",
      "[Sample] d_loss: 1.16988635, g_loss: 0.82199776\n",
      "Epoch: [ 6] [1050/1093] time: 7122.7131, d_loss: 1.2243, g_loss: 0.8076\n",
      "[Sample] d_loss: 1.15826833, g_loss: 0.83780164\n",
      "Epoch: [ 6] [1060/1093] time: 7127.1881, d_loss: 1.2110, g_loss: 0.8176\n",
      "[Sample] d_loss: 1.17065334, g_loss: 0.82320726\n",
      "Epoch: [ 6] [1070/1093] time: 7131.2083, d_loss: 1.1924, g_loss: 0.8239\n",
      "[Sample] d_loss: 1.17176521, g_loss: 0.82032895\n",
      "Epoch: [ 6] [1080/1093] time: 7135.3783, d_loss: 1.2102, g_loss: 0.8117\n",
      "[Sample] d_loss: 1.17858744, g_loss: 0.81437361\n",
      "Epoch: [ 6] [1090/1093] time: 7140.0261, d_loss: 1.1778, g_loss: 0.7941\n",
      "[Sample] d_loss: 1.15934289, g_loss: 0.83635849\n",
      "[Sample] d_loss: 1.15659380, g_loss: 0.83926433\n",
      "Epoch: [ 7] [   7/1093] time: 7144.5615, d_loss: 1.1811, g_loss: 0.8372\n",
      "[Sample] d_loss: 1.16411114, g_loss: 0.83047003\n",
      "Epoch: [ 7] [  17/1093] time: 7148.9542, d_loss: 1.2260, g_loss: 0.8009\n",
      "[Sample] d_loss: 1.17895961, g_loss: 0.82068181\n",
      "Epoch: [ 7] [  27/1093] time: 7153.2237, d_loss: 1.1822, g_loss: 0.7865\n",
      "[Sample] d_loss: 1.19033325, g_loss: 0.80418760\n",
      "Epoch: [ 7] [  37/1093] time: 7157.5550, d_loss: 1.1877, g_loss: 0.7980\n",
      "[Sample] d_loss: 1.19338107, g_loss: 0.80324543\n",
      "Epoch: [ 7] [  47/1093] time: 7162.5943, d_loss: 1.1872, g_loss: 0.7975\n",
      "[Sample] d_loss: 1.16169691, g_loss: 0.83476919\n",
      "Epoch: [ 7] [  57/1093] time: 7168.0707, d_loss: 1.2441, g_loss: 0.7941\n",
      "[Sample] d_loss: 1.17204738, g_loss: 0.81766844\n",
      "Epoch: [ 7] [  67/1093] time: 7172.4479, d_loss: 1.1960, g_loss: 0.8353\n",
      "[Sample] d_loss: 1.18291092, g_loss: 0.81157565\n",
      "Epoch: [ 7] [  77/1093] time: 7176.8061, d_loss: 1.2172, g_loss: 0.8245\n",
      "[Sample] d_loss: 1.17274880, g_loss: 0.83277172\n",
      "Epoch: [ 7] [  87/1093] time: 7181.1568, d_loss: 1.1881, g_loss: 0.8630\n",
      "[Sample] d_loss: 1.19022560, g_loss: 0.81100082\n",
      "Epoch: [ 7] [  97/1093] time: 7185.2858, d_loss: 1.2007, g_loss: 0.7781\n",
      "[Sample] d_loss: 1.18623734, g_loss: 0.81446570\n",
      "Epoch: [ 7] [ 107/1093] time: 7189.3519, d_loss: 1.2102, g_loss: 0.7928\n",
      "[Sample] d_loss: 1.20641494, g_loss: 0.79605913\n",
      "Epoch: [ 7] [ 117/1093] time: 7193.3677, d_loss: 1.2387, g_loss: 0.7936\n",
      "[Sample] d_loss: 1.17858028, g_loss: 0.81232560\n",
      "Epoch: [ 7] [ 127/1093] time: 7197.9356, d_loss: 1.1765, g_loss: 0.8162\n",
      "[Sample] d_loss: 1.18257082, g_loss: 0.81282461\n",
      "Epoch: [ 7] [ 137/1093] time: 7202.5626, d_loss: 1.2343, g_loss: 0.8134\n",
      "[Sample] d_loss: 1.17630255, g_loss: 0.82184792\n",
      "Epoch: [ 7] [ 147/1093] time: 7206.8157, d_loss: 1.2049, g_loss: 0.7913\n",
      "[Sample] d_loss: 1.19133806, g_loss: 0.80975765\n",
      "Epoch: [ 7] [ 157/1093] time: 7211.3333, d_loss: 1.2009, g_loss: 0.8131\n",
      "[Sample] d_loss: 1.17786479, g_loss: 0.80936956\n",
      "Epoch: [ 7] [ 167/1093] time: 7215.8641, d_loss: 1.1664, g_loss: 0.8393\n",
      "[Sample] d_loss: 1.17511606, g_loss: 0.82366645\n",
      "Epoch: [ 7] [ 177/1093] time: 7220.2684, d_loss: 1.2384, g_loss: 0.8586\n",
      "[Sample] d_loss: 1.14620638, g_loss: 0.85994202\n",
      "Epoch: [ 7] [ 187/1093] time: 7224.4777, d_loss: 1.2244, g_loss: 0.8078\n",
      "[Sample] d_loss: 1.15575695, g_loss: 0.84221977\n",
      "Epoch: [ 7] [ 197/1093] time: 7228.6365, d_loss: 1.2010, g_loss: 0.8120\n",
      "[Sample] d_loss: 1.17663205, g_loss: 0.81484503\n",
      "Epoch: [ 7] [ 207/1093] time: 7233.5280, d_loss: 1.2168, g_loss: 0.8366\n",
      "[Sample] d_loss: 1.19989765, g_loss: 0.78800541\n",
      "Epoch: [ 7] [ 217/1093] time: 7237.8648, d_loss: 1.1987, g_loss: 0.8209\n",
      "[Sample] d_loss: 1.19594359, g_loss: 0.80317569\n",
      "Epoch: [ 7] [ 227/1093] time: 7242.0474, d_loss: 1.1755, g_loss: 0.8180\n",
      "[Sample] d_loss: 1.18717289, g_loss: 0.80716372\n",
      "Epoch: [ 7] [ 237/1093] time: 7246.2724, d_loss: 1.1581, g_loss: 0.8379\n",
      "[Sample] d_loss: 1.19243479, g_loss: 0.80155087\n",
      "Epoch: [ 7] [ 247/1093] time: 7250.5055, d_loss: 1.1990, g_loss: 0.7919\n",
      "[Sample] d_loss: 1.19443512, g_loss: 0.79573166\n",
      "Epoch: [ 7] [ 257/1093] time: 7255.1046, d_loss: 1.2218, g_loss: 0.8010\n",
      "[Sample] d_loss: 1.17999959, g_loss: 0.81612182\n",
      "Epoch: [ 7] [ 267/1093] time: 7260.2788, d_loss: 1.1470, g_loss: 0.8291\n",
      "[Sample] d_loss: 1.17860579, g_loss: 0.81823051\n",
      "Epoch: [ 7] [ 277/1093] time: 7265.4233, d_loss: 1.2048, g_loss: 0.8323\n",
      "[Sample] d_loss: 1.17503679, g_loss: 0.82280535\n",
      "Epoch: [ 7] [ 287/1093] time: 7270.5301, d_loss: 1.2317, g_loss: 0.7742\n",
      "[Sample] d_loss: 1.18889630, g_loss: 0.79776442\n",
      "Epoch: [ 7] [ 297/1093] time: 7274.6560, d_loss: 1.2027, g_loss: 0.7860\n",
      "[Sample] d_loss: 1.18728590, g_loss: 0.80448806\n",
      "Epoch: [ 7] [ 307/1093] time: 7278.6948, d_loss: 1.1559, g_loss: 0.8433\n",
      "[Sample] d_loss: 1.18456078, g_loss: 0.80497277\n",
      "Epoch: [ 7] [ 317/1093] time: 7282.7573, d_loss: 1.1346, g_loss: 0.8303\n",
      "[Sample] d_loss: 1.17010379, g_loss: 0.82870829\n",
      "Epoch: [ 7] [ 327/1093] time: 7286.8175, d_loss: 1.2367, g_loss: 0.8112\n",
      "[Sample] d_loss: 1.17667246, g_loss: 0.81948298\n",
      "Epoch: [ 7] [ 337/1093] time: 7290.8621, d_loss: 1.1594, g_loss: 0.8424\n",
      "[Sample] d_loss: 1.17619789, g_loss: 0.81908798\n",
      "Epoch: [ 7] [ 347/1093] time: 7295.4164, d_loss: 1.1579, g_loss: 0.8125\n",
      "[Sample] d_loss: 1.18223548, g_loss: 0.81537646\n",
      "Epoch: [ 7] [ 357/1093] time: 7300.3739, d_loss: 1.2067, g_loss: 0.8081\n",
      "[Sample] d_loss: 1.15381575, g_loss: 0.84546357\n",
      "Epoch: [ 7] [ 367/1093] time: 7304.8110, d_loss: 1.1830, g_loss: 0.8337\n",
      "[Sample] d_loss: 1.16132438, g_loss: 0.84134263\n",
      "Epoch: [ 7] [ 377/1093] time: 7309.6497, d_loss: 1.1736, g_loss: 0.8273\n",
      "[Sample] d_loss: 1.18192482, g_loss: 0.80954409\n",
      "Epoch: [ 7] [ 387/1093] time: 7313.7818, d_loss: 1.2190, g_loss: 0.7847\n",
      "[Sample] d_loss: 1.17745328, g_loss: 0.81964481\n",
      "Epoch: [ 7] [ 397/1093] time: 7317.8987, d_loss: 1.1761, g_loss: 0.8094\n",
      "[Sample] d_loss: 1.18869829, g_loss: 0.80515933\n",
      "Epoch: [ 7] [ 407/1093] time: 7321.9794, d_loss: 1.2549, g_loss: 0.8023\n",
      "[Sample] d_loss: 1.18146110, g_loss: 0.81219989\n",
      "Epoch: [ 7] [ 417/1093] time: 7326.1166, d_loss: 1.2190, g_loss: 0.8127\n",
      "[Sample] d_loss: 1.17736542, g_loss: 0.81665856\n",
      "Epoch: [ 7] [ 427/1093] time: 7330.2804, d_loss: 1.2558, g_loss: 0.8321\n",
      "[Sample] d_loss: 1.16911793, g_loss: 0.82578194\n",
      "Epoch: [ 7] [ 437/1093] time: 7335.0681, d_loss: 1.1842, g_loss: 0.8336\n",
      "[Sample] d_loss: 1.17211175, g_loss: 0.82886714\n",
      "Epoch: [ 7] [ 447/1093] time: 7339.3566, d_loss: 1.2373, g_loss: 0.7965\n",
      "[Sample] d_loss: 1.19036925, g_loss: 0.79990411\n",
      "Epoch: [ 7] [ 457/1093] time: 7343.5630, d_loss: 1.2367, g_loss: 0.8034\n",
      "[Sample] d_loss: 1.19576287, g_loss: 0.79744083\n",
      "Epoch: [ 7] [ 467/1093] time: 7347.6788, d_loss: 1.2087, g_loss: 0.8116\n",
      "[Sample] d_loss: 1.19424701, g_loss: 0.80424941\n",
      "Epoch: [ 7] [ 477/1093] time: 7351.9809, d_loss: 1.2017, g_loss: 0.8217\n",
      "[Sample] d_loss: 1.18462396, g_loss: 0.80926335\n",
      "Epoch: [ 7] [ 487/1093] time: 7356.7369, d_loss: 1.2377, g_loss: 0.7909\n",
      "[Sample] d_loss: 1.19268477, g_loss: 0.79787195\n",
      "Epoch: [ 7] [ 497/1093] time: 7361.1114, d_loss: 1.2177, g_loss: 0.8209\n",
      "[Sample] d_loss: 1.18138266, g_loss: 0.81365722\n",
      "Epoch: [ 7] [ 507/1093] time: 7365.3586, d_loss: 1.2249, g_loss: 0.8067\n",
      "[Sample] d_loss: 1.19212413, g_loss: 0.79907632\n",
      "Epoch: [ 7] [ 517/1093] time: 7370.1666, d_loss: 1.2007, g_loss: 0.7841\n",
      "[Sample] d_loss: 1.18948710, g_loss: 0.81040883\n",
      "Epoch: [ 7] [ 527/1093] time: 7374.8462, d_loss: 1.1593, g_loss: 0.8411\n",
      "[Sample] d_loss: 1.19754863, g_loss: 0.78997576\n",
      "Epoch: [ 7] [ 537/1093] time: 7379.9790, d_loss: 1.1804, g_loss: 0.7856\n",
      "[Sample] d_loss: 1.18026185, g_loss: 0.81184757\n",
      "Epoch: [ 7] [ 547/1093] time: 7384.2208, d_loss: 1.2522, g_loss: 0.7950\n",
      "[Sample] d_loss: 1.18913293, g_loss: 0.81004721\n",
      "Epoch: [ 7] [ 557/1093] time: 7388.1874, d_loss: 1.1943, g_loss: 0.8059\n",
      "[Sample] d_loss: 1.18440175, g_loss: 0.81475544\n",
      "Epoch: [ 7] [ 567/1093] time: 7392.0953, d_loss: 1.2257, g_loss: 0.8151\n",
      "[Sample] d_loss: 1.19515657, g_loss: 0.79630929\n",
      "Epoch: [ 7] [ 577/1093] time: 7396.0154, d_loss: 1.2218, g_loss: 0.8386\n",
      "[Sample] d_loss: 1.17133641, g_loss: 0.84166789\n",
      "Epoch: [ 7] [ 587/1093] time: 7399.9897, d_loss: 1.2118, g_loss: 0.8051\n",
      "[Sample] d_loss: 1.16322851, g_loss: 0.84813380\n",
      "Epoch: [ 7] [ 597/1093] time: 7404.0948, d_loss: 1.1746, g_loss: 0.8341\n",
      "[Sample] d_loss: 1.16616952, g_loss: 0.83850950\n",
      "Epoch: [ 7] [ 607/1093] time: 7408.9575, d_loss: 1.1886, g_loss: 0.8025\n",
      "[Sample] d_loss: 1.14239478, g_loss: 0.88588285\n",
      "Epoch: [ 7] [ 617/1093] time: 7413.3404, d_loss: 1.2033, g_loss: 0.8205\n",
      "[Sample] d_loss: 1.15831566, g_loss: 0.84078133\n",
      "Epoch: [ 7] [ 627/1093] time: 7417.5759, d_loss: 1.2337, g_loss: 0.8128\n",
      "[Sample] d_loss: 1.15612388, g_loss: 0.85214728\n",
      "Epoch: [ 7] [ 637/1093] time: 7422.0096, d_loss: 1.1961, g_loss: 0.8086\n",
      "[Sample] d_loss: 1.15489936, g_loss: 0.85210860\n",
      "Epoch: [ 7] [ 647/1093] time: 7426.0640, d_loss: 1.2240, g_loss: 0.7845\n",
      "[Sample] d_loss: 1.15431297, g_loss: 0.85199797\n",
      "Epoch: [ 7] [ 657/1093] time: 7430.4655, d_loss: 1.2422, g_loss: 0.7956\n",
      "[Sample] d_loss: 1.15222621, g_loss: 0.85553390\n",
      "Epoch: [ 7] [ 667/1093] time: 7434.7882, d_loss: 1.2461, g_loss: 0.7769\n",
      "[Sample] d_loss: 1.18501091, g_loss: 0.81458700\n",
      "Epoch: [ 7] [ 677/1093] time: 7439.0564, d_loss: 1.1438, g_loss: 0.8205\n",
      "[Sample] d_loss: 1.17547917, g_loss: 0.82356048\n",
      "Epoch: [ 7] [ 687/1093] time: 7444.1624, d_loss: 1.2170, g_loss: 0.8162\n",
      "[Sample] d_loss: 1.17468584, g_loss: 0.82781529\n",
      "Epoch: [ 7] [ 697/1093] time: 7448.7099, d_loss: 1.1974, g_loss: 0.8231\n",
      "[Sample] d_loss: 1.19294965, g_loss: 0.80719054\n",
      "Epoch: [ 7] [ 707/1093] time: 7453.0932, d_loss: 1.2286, g_loss: 0.8164\n",
      "[Sample] d_loss: 1.17124057, g_loss: 0.82950783\n",
      "Epoch: [ 7] [ 717/1093] time: 7457.4125, d_loss: 1.2577, g_loss: 0.7987\n",
      "[Sample] d_loss: 1.18036079, g_loss: 0.81731564\n",
      "Epoch: [ 7] [ 727/1093] time: 7461.7034, d_loss: 1.1676, g_loss: 0.8079\n",
      "[Sample] d_loss: 1.19037759, g_loss: 0.80205715\n",
      "Epoch: [ 7] [ 737/1093] time: 7465.7746, d_loss: 1.1794, g_loss: 0.8165\n",
      "[Sample] d_loss: 1.19154763, g_loss: 0.81260312\n",
      "Epoch: [ 7] [ 747/1093] time: 7470.2829, d_loss: 1.2128, g_loss: 0.8234\n",
      "[Sample] d_loss: 1.18885899, g_loss: 0.80945158\n",
      "Epoch: [ 7] [ 757/1093] time: 7474.3929, d_loss: 1.2564, g_loss: 0.7779\n",
      "[Sample] d_loss: 1.19201875, g_loss: 0.80161560\n",
      "Epoch: [ 7] [ 767/1093] time: 7478.9716, d_loss: 1.2048, g_loss: 0.7952\n",
      "[Sample] d_loss: 1.19866955, g_loss: 0.79134411\n",
      "Epoch: [ 7] [ 777/1093] time: 7483.0276, d_loss: 1.2276, g_loss: 0.8315\n",
      "[Sample] d_loss: 1.19991183, g_loss: 0.80359697\n",
      "Epoch: [ 7] [ 787/1093] time: 7487.4904, d_loss: 1.2051, g_loss: 0.8205\n",
      "[Sample] d_loss: 1.20363212, g_loss: 0.79603034\n",
      "Epoch: [ 7] [ 797/1093] time: 7491.7057, d_loss: 1.1780, g_loss: 0.8195\n",
      "[Sample] d_loss: 1.19058239, g_loss: 0.80764604\n",
      "Epoch: [ 7] [ 807/1093] time: 7496.1193, d_loss: 1.2189, g_loss: 0.7896\n",
      "[Sample] d_loss: 1.19957983, g_loss: 0.80503237\n",
      "Epoch: [ 7] [ 817/1093] time: 7500.5434, d_loss: 1.2177, g_loss: 0.7845\n",
      "[Sample] d_loss: 1.20357037, g_loss: 0.79686034\n",
      "Epoch: [ 7] [ 827/1093] time: 7504.7854, d_loss: 1.2311, g_loss: 0.7750\n",
      "[Sample] d_loss: 1.21133685, g_loss: 0.78842562\n",
      "Epoch: [ 7] [ 837/1093] time: 7509.0974, d_loss: 1.2102, g_loss: 0.7788\n",
      "[Sample] d_loss: 1.19573939, g_loss: 0.81363440\n",
      "Epoch: [ 7] [ 847/1093] time: 7513.3756, d_loss: 1.2052, g_loss: 0.8071\n",
      "[Sample] d_loss: 1.18486285, g_loss: 0.83035576\n",
      "Epoch: [ 7] [ 857/1093] time: 7517.4010, d_loss: 1.2515, g_loss: 0.8076\n",
      "[Sample] d_loss: 1.20550275, g_loss: 0.80423379\n",
      "Epoch: [ 7] [ 867/1093] time: 7521.5958, d_loss: 1.3050, g_loss: 0.7916\n",
      "[Sample] d_loss: 1.19604731, g_loss: 0.81343400\n",
      "Epoch: [ 7] [ 877/1093] time: 7526.0749, d_loss: 1.2281, g_loss: 0.8107\n",
      "[Sample] d_loss: 1.20858526, g_loss: 0.80442524\n",
      "Epoch: [ 7] [ 887/1093] time: 7530.2651, d_loss: 1.2303, g_loss: 0.7982\n",
      "[Sample] d_loss: 1.17307127, g_loss: 0.83274209\n",
      "Epoch: [ 7] [ 897/1093] time: 7534.3712, d_loss: 1.2613, g_loss: 0.8021\n",
      "[Sample] d_loss: 1.19038796, g_loss: 0.81398863\n",
      "Epoch: [ 7] [ 907/1093] time: 7539.0938, d_loss: 1.2167, g_loss: 0.8118\n",
      "[Sample] d_loss: 1.19733381, g_loss: 0.80880839\n",
      "Epoch: [ 7] [ 917/1093] time: 7543.2261, d_loss: 1.1640, g_loss: 0.8441\n",
      "[Sample] d_loss: 1.20435452, g_loss: 0.79832357\n",
      "Epoch: [ 7] [ 927/1093] time: 7547.5085, d_loss: 1.2416, g_loss: 0.7764\n",
      "[Sample] d_loss: 1.20210862, g_loss: 0.79775178\n",
      "Epoch: [ 7] [ 937/1093] time: 7551.5457, d_loss: 1.2082, g_loss: 0.7989\n",
      "[Sample] d_loss: 1.20665145, g_loss: 0.79689598\n",
      "Epoch: [ 7] [ 947/1093] time: 7555.8676, d_loss: 1.1679, g_loss: 0.8202\n",
      "[Sample] d_loss: 1.19181156, g_loss: 0.81380820\n",
      "Epoch: [ 7] [ 957/1093] time: 7560.7362, d_loss: 1.2452, g_loss: 0.7832\n",
      "[Sample] d_loss: 1.20062566, g_loss: 0.81157327\n",
      "Epoch: [ 7] [ 967/1093] time: 7564.8900, d_loss: 1.2476, g_loss: 0.7849\n",
      "[Sample] d_loss: 1.22325444, g_loss: 0.78717935\n",
      "Epoch: [ 7] [ 977/1093] time: 7568.9596, d_loss: 1.2091, g_loss: 0.8323\n",
      "[Sample] d_loss: 1.21102321, g_loss: 0.79775536\n",
      "Epoch: [ 7] [ 987/1093] time: 7573.2062, d_loss: 1.1968, g_loss: 0.7858\n",
      "[Sample] d_loss: 1.21094275, g_loss: 0.80266738\n",
      "Epoch: [ 7] [ 997/1093] time: 7577.5343, d_loss: 1.2181, g_loss: 0.7964\n",
      "[Sample] d_loss: 1.19117641, g_loss: 0.81636161\n",
      "Epoch: [ 7] [1007/1093] time: 7581.6818, d_loss: 1.2408, g_loss: 0.7816\n",
      "[Sample] d_loss: 1.19936776, g_loss: 0.80922395\n",
      "Epoch: [ 7] [1017/1093] time: 7585.7024, d_loss: 1.2343, g_loss: 0.7870\n",
      "[Sample] d_loss: 1.19995415, g_loss: 0.80524397\n",
      "Epoch: [ 7] [1027/1093] time: 7589.7421, d_loss: 1.2949, g_loss: 0.7688\n",
      "[Sample] d_loss: 1.21174216, g_loss: 0.79742146\n",
      "Epoch: [ 7] [1037/1093] time: 7593.7784, d_loss: 1.2038, g_loss: 0.8398\n",
      "[Sample] d_loss: 1.20139742, g_loss: 0.80890012\n",
      "Epoch: [ 7] [1047/1093] time: 7597.7502, d_loss: 1.1493, g_loss: 0.8313\n",
      "[Sample] d_loss: 1.18753266, g_loss: 0.82198316\n",
      "Epoch: [ 7] [1057/1093] time: 7601.7906, d_loss: 1.2133, g_loss: 0.8099\n",
      "[Sample] d_loss: 1.18498349, g_loss: 0.82308304\n",
      "Epoch: [ 7] [1067/1093] time: 7605.7711, d_loss: 1.2321, g_loss: 0.8218\n",
      "[Sample] d_loss: 1.19744039, g_loss: 0.80733150\n",
      "Epoch: [ 7] [1077/1093] time: 7609.7354, d_loss: 1.1738, g_loss: 0.8128\n",
      "[Sample] d_loss: 1.20795512, g_loss: 0.79487032\n",
      "Epoch: [ 7] [1087/1093] time: 7613.6819, d_loss: 1.2582, g_loss: 0.7824\n",
      "[Sample] d_loss: 1.20002878, g_loss: 0.81069183\n",
      "[Sample] d_loss: 1.19985485, g_loss: 0.81200057\n",
      "Epoch: [ 8] [   4/1093] time: 7617.7381, d_loss: 1.1592, g_loss: 0.8119\n",
      "[Sample] d_loss: 1.20526803, g_loss: 0.79743981\n",
      "Epoch: [ 8] [  14/1093] time: 7621.6459, d_loss: 1.1895, g_loss: 0.8274\n",
      "[Sample] d_loss: 1.20068455, g_loss: 0.81029326\n",
      "Epoch: [ 8] [  24/1093] time: 7625.5471, d_loss: 1.1306, g_loss: 0.8368\n",
      "[Sample] d_loss: 1.19395685, g_loss: 0.81709206\n",
      "Epoch: [ 8] [  34/1093] time: 7629.4920, d_loss: 1.2223, g_loss: 0.8018\n",
      "[Sample] d_loss: 1.19288659, g_loss: 0.81512928\n",
      "Epoch: [ 8] [  44/1093] time: 7633.7551, d_loss: 1.2258, g_loss: 0.8045\n",
      "[Sample] d_loss: 1.17889178, g_loss: 0.82424551\n",
      "Epoch: [ 8] [  54/1093] time: 7637.9122, d_loss: 1.2276, g_loss: 0.7882\n",
      "[Sample] d_loss: 1.19544506, g_loss: 0.81049621\n",
      "Epoch: [ 8] [  64/1093] time: 7641.9950, d_loss: 1.2437, g_loss: 0.8242\n",
      "[Sample] d_loss: 1.18888295, g_loss: 0.81935441\n",
      "Epoch: [ 8] [  74/1093] time: 7646.7841, d_loss: 1.2160, g_loss: 0.8161\n",
      "[Sample] d_loss: 1.17550087, g_loss: 0.83410341\n",
      "Epoch: [ 8] [  84/1093] time: 7651.3386, d_loss: 1.1996, g_loss: 0.8049\n",
      "[Sample] d_loss: 1.20319593, g_loss: 0.80873638\n",
      "Epoch: [ 8] [  94/1093] time: 7655.5618, d_loss: 1.2298, g_loss: 0.7928\n",
      "[Sample] d_loss: 1.19693184, g_loss: 0.80875850\n",
      "Epoch: [ 8] [ 104/1093] time: 7659.7319, d_loss: 1.2198, g_loss: 0.8114\n",
      "[Sample] d_loss: 1.19480526, g_loss: 0.81167346\n",
      "Epoch: [ 8] [ 114/1093] time: 7664.0471, d_loss: 1.1806, g_loss: 0.8179\n",
      "[Sample] d_loss: 1.20736039, g_loss: 0.79202366\n",
      "Epoch: [ 8] [ 124/1093] time: 7668.3670, d_loss: 1.1735, g_loss: 0.7877\n",
      "[Sample] d_loss: 1.20652401, g_loss: 0.79619616\n",
      "Epoch: [ 8] [ 134/1093] time: 7672.7640, d_loss: 1.2588, g_loss: 0.8223\n",
      "[Sample] d_loss: 1.20303786, g_loss: 0.80249918\n",
      "Epoch: [ 8] [ 144/1093] time: 7677.1664, d_loss: 1.1356, g_loss: 0.8010\n",
      "[Sample] d_loss: 1.19110596, g_loss: 0.81446010\n",
      "Epoch: [ 8] [ 154/1093] time: 7681.3715, d_loss: 1.1472, g_loss: 0.8447\n",
      "[Sample] d_loss: 1.19437575, g_loss: 0.80940723\n",
      "Epoch: [ 8] [ 164/1093] time: 7685.4540, d_loss: 1.2114, g_loss: 0.7873\n",
      "[Sample] d_loss: 1.20624733, g_loss: 0.79184449\n",
      "Epoch: [ 8] [ 174/1093] time: 7689.4010, d_loss: 1.2052, g_loss: 0.8093\n",
      "[Sample] d_loss: 1.19676638, g_loss: 0.80993581\n",
      "Epoch: [ 8] [ 184/1093] time: 7693.3375, d_loss: 1.1733, g_loss: 0.8386\n",
      "[Sample] d_loss: 1.20378494, g_loss: 0.79080760\n",
      "Epoch: [ 8] [ 194/1093] time: 7697.6354, d_loss: 1.2133, g_loss: 0.8111\n",
      "[Sample] d_loss: 1.19403744, g_loss: 0.80963838\n",
      "Epoch: [ 8] [ 204/1093] time: 7702.0811, d_loss: 1.2151, g_loss: 0.7942\n",
      "[Sample] d_loss: 1.21331704, g_loss: 0.79207826\n",
      "Epoch: [ 8] [ 214/1093] time: 7706.8115, d_loss: 1.2742, g_loss: 0.7894\n",
      "[Sample] d_loss: 1.20096540, g_loss: 0.80696732\n",
      "Epoch: [ 8] [ 224/1093] time: 7711.8906, d_loss: 1.2144, g_loss: 0.8046\n",
      "[Sample] d_loss: 1.21669817, g_loss: 0.78792471\n",
      "Epoch: [ 8] [ 234/1093] time: 7716.6697, d_loss: 1.2468, g_loss: 0.8033\n",
      "[Sample] d_loss: 1.21226716, g_loss: 0.79162776\n",
      "Epoch: [ 8] [ 244/1093] time: 7720.8897, d_loss: 1.1698, g_loss: 0.8380\n",
      "[Sample] d_loss: 1.19756651, g_loss: 0.81607604\n",
      "Epoch: [ 8] [ 254/1093] time: 7725.0941, d_loss: 1.2228, g_loss: 0.8766\n",
      "[Sample] d_loss: 1.21412814, g_loss: 0.79541504\n",
      "Epoch: [ 8] [ 264/1093] time: 7729.1377, d_loss: 1.1920, g_loss: 0.8086\n",
      "[Sample] d_loss: 1.20285606, g_loss: 0.80390036\n",
      "Epoch: [ 8] [ 274/1093] time: 7733.2968, d_loss: 1.1882, g_loss: 0.8206\n",
      "[Sample] d_loss: 1.20768785, g_loss: 0.79792726\n",
      "Epoch: [ 8] [ 284/1093] time: 7737.5498, d_loss: 1.2018, g_loss: 0.7969\n",
      "[Sample] d_loss: 1.21385026, g_loss: 0.79099274\n",
      "Epoch: [ 8] [ 294/1093] time: 7741.9156, d_loss: 1.1546, g_loss: 0.8365\n",
      "[Sample] d_loss: 1.20985341, g_loss: 0.79549503\n",
      "Epoch: [ 8] [ 304/1093] time: 7746.2005, d_loss: 1.2138, g_loss: 0.7996\n",
      "[Sample] d_loss: 1.22356915, g_loss: 0.78124571\n",
      "Epoch: [ 8] [ 314/1093] time: 7750.2190, d_loss: 1.1694, g_loss: 0.8008\n",
      "[Sample] d_loss: 1.21219754, g_loss: 0.78850234\n",
      "Epoch: [ 8] [ 324/1093] time: 7754.4326, d_loss: 1.1808, g_loss: 0.8327\n",
      "[Sample] d_loss: 1.20685983, g_loss: 0.79522455\n",
      "Epoch: [ 8] [ 334/1093] time: 7758.4943, d_loss: 1.2585, g_loss: 0.7840\n",
      "[Sample] d_loss: 1.19287086, g_loss: 0.82542604\n",
      "Epoch: [ 8] [ 344/1093] time: 7762.5318, d_loss: 1.1912, g_loss: 0.7910\n",
      "[Sample] d_loss: 1.17971170, g_loss: 0.82465214\n",
      "Epoch: [ 8] [ 354/1093] time: 7767.0805, d_loss: 1.1814, g_loss: 0.8235\n",
      "[Sample] d_loss: 1.18921125, g_loss: 0.82174015\n",
      "Epoch: [ 8] [ 364/1093] time: 7771.1243, d_loss: 1.2232, g_loss: 0.8220\n",
      "[Sample] d_loss: 1.19273913, g_loss: 0.80661523\n",
      "Epoch: [ 8] [ 374/1093] time: 7775.3540, d_loss: 1.2083, g_loss: 0.8231\n",
      "[Sample] d_loss: 1.18004274, g_loss: 0.82520533\n",
      "Epoch: [ 8] [ 384/1093] time: 7779.5551, d_loss: 1.1788, g_loss: 0.8169\n",
      "[Sample] d_loss: 1.21941674, g_loss: 0.78992236\n",
      "Epoch: [ 8] [ 394/1093] time: 7783.7096, d_loss: 1.2299, g_loss: 0.7586\n",
      "[Sample] d_loss: 1.19893742, g_loss: 0.80270118\n",
      "Epoch: [ 8] [ 404/1093] time: 7787.8431, d_loss: 1.2102, g_loss: 0.8231\n",
      "[Sample] d_loss: 1.21843219, g_loss: 0.78152502\n",
      "Epoch: [ 8] [ 414/1093] time: 7791.9511, d_loss: 1.2523, g_loss: 0.7981\n",
      "[Sample] d_loss: 1.20714974, g_loss: 0.79087555\n",
      "Epoch: [ 8] [ 424/1093] time: 7796.1435, d_loss: 1.2628, g_loss: 0.7491\n",
      "[Sample] d_loss: 1.21148586, g_loss: 0.78752506\n",
      "Epoch: [ 8] [ 434/1093] time: 7800.2824, d_loss: 1.2290, g_loss: 0.7996\n",
      "[Sample] d_loss: 1.21707356, g_loss: 0.78855443\n",
      "Epoch: [ 8] [ 444/1093] time: 7804.3245, d_loss: 1.2616, g_loss: 0.7918\n",
      "[Sample] d_loss: 1.20233154, g_loss: 0.80217832\n",
      "Epoch: [ 8] [ 454/1093] time: 7808.3477, d_loss: 1.2222, g_loss: 0.8073\n",
      "[Sample] d_loss: 1.19930840, g_loss: 0.80751342\n",
      "Epoch: [ 8] [ 464/1093] time: 7812.4081, d_loss: 1.2485, g_loss: 0.8001\n",
      "[Sample] d_loss: 1.19661939, g_loss: 0.80995834\n",
      "Epoch: [ 8] [ 474/1093] time: 7816.5176, d_loss: 1.1978, g_loss: 0.8260\n",
      "[Sample] d_loss: 1.22732210, g_loss: 0.77321088\n",
      "Epoch: [ 8] [ 484/1093] time: 7820.7830, d_loss: 1.2252, g_loss: 0.7788\n",
      "[Sample] d_loss: 1.21670747, g_loss: 0.79036438\n",
      "Epoch: [ 8] [ 494/1093] time: 7825.1847, d_loss: 1.2691, g_loss: 0.7717\n",
      "[Sample] d_loss: 1.22097421, g_loss: 0.78122497\n",
      "Epoch: [ 8] [ 504/1093] time: 7829.3681, d_loss: 1.1852, g_loss: 0.8154\n",
      "[Sample] d_loss: 1.20541608, g_loss: 0.79538906\n",
      "Epoch: [ 8] [ 514/1093] time: 7833.7405, d_loss: 1.1923, g_loss: 0.8045\n",
      "[Sample] d_loss: 1.21046424, g_loss: 0.79725045\n",
      "Epoch: [ 8] [ 524/1093] time: 7837.8772, d_loss: 1.2544, g_loss: 0.7979\n",
      "[Sample] d_loss: 1.20938468, g_loss: 0.79847717\n",
      "Epoch: [ 8] [ 534/1093] time: 7841.9316, d_loss: 1.2407, g_loss: 0.7983\n",
      "[Sample] d_loss: 1.21056747, g_loss: 0.79916030\n",
      "Epoch: [ 8] [ 544/1093] time: 7846.2033, d_loss: 1.2455, g_loss: 0.7817\n",
      "[Sample] d_loss: 1.19320536, g_loss: 0.82151878\n",
      "Epoch: [ 8] [ 554/1093] time: 7850.1648, d_loss: 1.1948, g_loss: 0.8593\n",
      "[Sample] d_loss: 1.20015860, g_loss: 0.80834556\n",
      "Epoch: [ 8] [ 564/1093] time: 7854.4208, d_loss: 1.2344, g_loss: 0.8027\n",
      "[Sample] d_loss: 1.19955850, g_loss: 0.81484729\n",
      "Epoch: [ 8] [ 574/1093] time: 7858.6804, d_loss: 1.2223, g_loss: 0.8054\n",
      "[Sample] d_loss: 1.20322978, g_loss: 0.80661571\n",
      "Epoch: [ 8] [ 584/1093] time: 7862.7773, d_loss: 1.2011, g_loss: 0.8146\n",
      "[Sample] d_loss: 1.19397330, g_loss: 0.82654136\n",
      "Epoch: [ 8] [ 594/1093] time: 7866.8502, d_loss: 1.2484, g_loss: 0.7883\n",
      "[Sample] d_loss: 1.20598757, g_loss: 0.81762320\n",
      "Epoch: [ 8] [ 604/1093] time: 7870.8366, d_loss: 1.2146, g_loss: 0.8018\n",
      "[Sample] d_loss: 1.21560776, g_loss: 0.80120116\n",
      "Epoch: [ 8] [ 614/1093] time: 7874.8304, d_loss: 1.2335, g_loss: 0.8202\n",
      "[Sample] d_loss: 1.20177460, g_loss: 0.81118667\n",
      "Epoch: [ 8] [ 624/1093] time: 7878.7470, d_loss: 1.1716, g_loss: 0.8296\n",
      "[Sample] d_loss: 1.19646120, g_loss: 0.82637703\n",
      "Epoch: [ 8] [ 634/1093] time: 7882.7159, d_loss: 1.2166, g_loss: 0.7841\n",
      "[Sample] d_loss: 1.19165456, g_loss: 0.82256711\n",
      "Epoch: [ 8] [ 644/1093] time: 7886.7142, d_loss: 1.2535, g_loss: 0.8271\n",
      "[Sample] d_loss: 1.20415366, g_loss: 0.80569261\n",
      "Epoch: [ 8] [ 654/1093] time: 7890.7967, d_loss: 1.2250, g_loss: 0.8236\n",
      "[Sample] d_loss: 1.21993268, g_loss: 0.79355723\n",
      "Epoch: [ 8] [ 664/1093] time: 7894.9933, d_loss: 1.2106, g_loss: 0.8003\n",
      "[Sample] d_loss: 1.21006930, g_loss: 0.81078398\n",
      "Epoch: [ 8] [ 674/1093] time: 7899.5243, d_loss: 1.2426, g_loss: 0.7895\n",
      "[Sample] d_loss: 1.19608033, g_loss: 0.81582713\n",
      "Epoch: [ 8] [ 684/1093] time: 7904.0807, d_loss: 1.2284, g_loss: 0.7871\n",
      "[Sample] d_loss: 1.20193267, g_loss: 0.80817664\n",
      "Epoch: [ 8] [ 694/1093] time: 7908.3135, d_loss: 1.2300, g_loss: 0.7509\n",
      "[Sample] d_loss: 1.19442689, g_loss: 0.82070220\n",
      "Epoch: [ 8] [ 704/1093] time: 7912.5090, d_loss: 1.1984, g_loss: 0.8265\n",
      "[Sample] d_loss: 1.20224786, g_loss: 0.80826080\n",
      "Epoch: [ 8] [ 714/1093] time: 7916.7953, d_loss: 1.2291, g_loss: 0.8037\n",
      "[Sample] d_loss: 1.20977521, g_loss: 0.80323333\n",
      "Epoch: [ 8] [ 724/1093] time: 7921.0458, d_loss: 1.2399, g_loss: 0.7670\n",
      "[Sample] d_loss: 1.21619916, g_loss: 0.80215526\n",
      "Epoch: [ 8] [ 734/1093] time: 7925.2846, d_loss: 1.2194, g_loss: 0.7957\n",
      "[Sample] d_loss: 1.19448137, g_loss: 0.83918566\n",
      "Epoch: [ 8] [ 744/1093] time: 7929.6625, d_loss: 1.2497, g_loss: 0.8198\n",
      "[Sample] d_loss: 1.19309843, g_loss: 0.82331467\n",
      "Epoch: [ 8] [ 754/1093] time: 7934.2433, d_loss: 1.2575, g_loss: 0.7693\n",
      "[Sample] d_loss: 1.19436610, g_loss: 0.81850708\n",
      "Epoch: [ 8] [ 764/1093] time: 7938.4632, d_loss: 1.2683, g_loss: 0.7767\n",
      "[Sample] d_loss: 1.20095158, g_loss: 0.81485498\n",
      "Epoch: [ 8] [ 774/1093] time: 7942.6881, d_loss: 1.1788, g_loss: 0.8261\n",
      "[Sample] d_loss: 1.21366203, g_loss: 0.79667699\n",
      "Epoch: [ 8] [ 784/1093] time: 7946.8091, d_loss: 1.2131, g_loss: 0.8444\n",
      "[Sample] d_loss: 1.22914600, g_loss: 0.78328043\n",
      "Epoch: [ 8] [ 794/1093] time: 7950.9026, d_loss: 1.2343, g_loss: 0.7945\n",
      "[Sample] d_loss: 1.19853640, g_loss: 0.80521691\n",
      "Epoch: [ 8] [ 804/1093] time: 7955.3951, d_loss: 1.2560, g_loss: 0.7613\n",
      "[Sample] d_loss: 1.18539715, g_loss: 0.82837981\n",
      "Epoch: [ 8] [ 814/1093] time: 7959.4172, d_loss: 1.2213, g_loss: 0.8076\n",
      "[Sample] d_loss: 1.20178366, g_loss: 0.80900776\n",
      "Epoch: [ 8] [ 824/1093] time: 7963.3907, d_loss: 1.2906, g_loss: 0.8038\n",
      "[Sample] d_loss: 1.19671142, g_loss: 0.81777537\n",
      "Epoch: [ 8] [ 834/1093] time: 7967.3986, d_loss: 1.2019, g_loss: 0.7844\n",
      "[Sample] d_loss: 1.19871211, g_loss: 0.81949049\n",
      "Epoch: [ 8] [ 844/1093] time: 7971.5208, d_loss: 1.2437, g_loss: 0.7861\n",
      "[Sample] d_loss: 1.19549990, g_loss: 0.82350427\n",
      "Epoch: [ 8] [ 854/1093] time: 7975.6419, d_loss: 1.1893, g_loss: 0.8085\n",
      "[Sample] d_loss: 1.19376814, g_loss: 0.83183533\n",
      "Epoch: [ 8] [ 864/1093] time: 7979.7382, d_loss: 1.2127, g_loss: 0.8084\n",
      "[Sample] d_loss: 1.21608281, g_loss: 0.81079304\n",
      "Epoch: [ 8] [ 874/1093] time: 7984.1229, d_loss: 1.1983, g_loss: 0.8068\n",
      "[Sample] d_loss: 1.20902371, g_loss: 0.80521297\n",
      "Epoch: [ 8] [ 884/1093] time: 7988.6449, d_loss: 1.1887, g_loss: 0.8336\n",
      "[Sample] d_loss: 1.20477045, g_loss: 0.81810701\n",
      "Epoch: [ 8] [ 894/1093] time: 7994.3311, d_loss: 1.2717, g_loss: 0.7537\n",
      "[Sample] d_loss: 1.18688476, g_loss: 0.83407968\n",
      "Epoch: [ 8] [ 904/1093] time: 7999.1426, d_loss: 1.2551, g_loss: 0.7594\n",
      "[Sample] d_loss: 1.20431614, g_loss: 0.81158209\n",
      "Epoch: [ 8] [ 914/1093] time: 8003.7345, d_loss: 1.2776, g_loss: 0.7768\n",
      "[Sample] d_loss: 1.19749403, g_loss: 0.81675428\n",
      "Epoch: [ 8] [ 924/1093] time: 8007.7223, d_loss: 1.1928, g_loss: 0.7970\n",
      "[Sample] d_loss: 1.19849944, g_loss: 0.82458067\n",
      "Epoch: [ 8] [ 934/1093] time: 8011.7611, d_loss: 1.2452, g_loss: 0.8123\n",
      "[Sample] d_loss: 1.21730757, g_loss: 0.81114328\n",
      "Epoch: [ 8] [ 944/1093] time: 8015.9009, d_loss: 1.2057, g_loss: 0.7660\n",
      "[Sample] d_loss: 1.18287027, g_loss: 0.83444858\n",
      "Epoch: [ 8] [ 954/1093] time: 8019.9537, d_loss: 1.2447, g_loss: 0.8178\n",
      "[Sample] d_loss: 1.20409000, g_loss: 0.80782330\n",
      "Epoch: [ 8] [ 964/1093] time: 8023.9733, d_loss: 1.1933, g_loss: 0.7917\n",
      "[Sample] d_loss: 1.20991075, g_loss: 0.80208486\n",
      "Epoch: [ 8] [ 974/1093] time: 8027.9341, d_loss: 1.2140, g_loss: 0.8120\n",
      "[Sample] d_loss: 1.21024024, g_loss: 0.80842692\n",
      "Epoch: [ 8] [ 984/1093] time: 8031.9049, d_loss: 1.2329, g_loss: 0.8072\n",
      "[Sample] d_loss: 1.18103254, g_loss: 0.84364831\n",
      "Epoch: [ 8] [ 994/1093] time: 8035.9249, d_loss: 1.2394, g_loss: 0.7861\n",
      "[Sample] d_loss: 1.21552944, g_loss: 0.80395454\n",
      "Epoch: [ 8] [1004/1093] time: 8040.0140, d_loss: 1.1916, g_loss: 0.8012\n",
      "[Sample] d_loss: 1.19433951, g_loss: 0.82256281\n",
      "Epoch: [ 8] [1014/1093] time: 8044.0795, d_loss: 1.2261, g_loss: 0.8299\n",
      "[Sample] d_loss: 1.19849575, g_loss: 0.82190824\n",
      "Epoch: [ 8] [1024/1093] time: 8048.0886, d_loss: 1.1822, g_loss: 0.8602\n",
      "[Sample] d_loss: 1.18347251, g_loss: 0.84197640\n",
      "Epoch: [ 8] [1034/1093] time: 8052.1519, d_loss: 1.2255, g_loss: 0.8106\n",
      "[Sample] d_loss: 1.19108748, g_loss: 0.83719826\n",
      "Epoch: [ 8] [1044/1093] time: 8056.1600, d_loss: 1.2563, g_loss: 0.7863\n",
      "[Sample] d_loss: 1.19633901, g_loss: 0.83544999\n",
      "Epoch: [ 8] [1054/1093] time: 8060.1025, d_loss: 1.1887, g_loss: 0.8461\n",
      "[Sample] d_loss: 1.19521499, g_loss: 0.82865334\n",
      "Epoch: [ 8] [1064/1093] time: 8064.0823, d_loss: 1.2702, g_loss: 0.8444\n",
      "[Sample] d_loss: 1.18172169, g_loss: 0.83411074\n",
      "Epoch: [ 8] [1074/1093] time: 8068.2091, d_loss: 1.1920, g_loss: 0.8182\n",
      "[Sample] d_loss: 1.20194304, g_loss: 0.81240004\n",
      "Epoch: [ 8] [1084/1093] time: 8072.6308, d_loss: 1.2330, g_loss: 0.7922\n",
      "[Sample] d_loss: 1.21378684, g_loss: 0.79102802\n",
      "[Sample] d_loss: 1.20444787, g_loss: 0.80707431\n",
      "Epoch: [ 9] [   1/1093] time: 8076.9231, d_loss: 1.2113, g_loss: 0.8000\n",
      "[Sample] d_loss: 1.21670294, g_loss: 0.80033356\n",
      "Epoch: [ 9] [  11/1093] time: 8081.0250, d_loss: 1.2141, g_loss: 0.7849\n",
      "[Sample] d_loss: 1.22069049, g_loss: 0.79442835\n",
      "Epoch: [ 9] [  21/1093] time: 8085.0602, d_loss: 1.2222, g_loss: 0.8018\n",
      "[Sample] d_loss: 1.20955014, g_loss: 0.81485403\n",
      "Epoch: [ 9] [  31/1093] time: 8089.1374, d_loss: 1.2647, g_loss: 0.7515\n",
      "[Sample] d_loss: 1.19943666, g_loss: 0.82647139\n",
      "Epoch: [ 9] [  41/1093] time: 8093.4013, d_loss: 1.1864, g_loss: 0.8201\n",
      "[Sample] d_loss: 1.20892835, g_loss: 0.81500888\n",
      "Epoch: [ 9] [  51/1093] time: 8097.5933, d_loss: 1.2137, g_loss: 0.8287\n",
      "[Sample] d_loss: 1.21886146, g_loss: 0.80209184\n",
      "Epoch: [ 9] [  61/1093] time: 8101.7141, d_loss: 1.2279, g_loss: 0.8080\n",
      "[Sample] d_loss: 1.22256899, g_loss: 0.79500043\n",
      "Epoch: [ 9] [  71/1093] time: 8105.8694, d_loss: 1.2410, g_loss: 0.7927\n",
      "[Sample] d_loss: 1.20250773, g_loss: 0.82328933\n",
      "Epoch: [ 9] [  81/1093] time: 8110.2815, d_loss: 1.1738, g_loss: 0.8511\n",
      "[Sample] d_loss: 1.20448256, g_loss: 0.82407808\n",
      "Epoch: [ 9] [  91/1093] time: 8116.2620, d_loss: 1.2593, g_loss: 0.7669\n",
      "[Sample] d_loss: 1.19430470, g_loss: 0.83414721\n",
      "Epoch: [ 9] [ 101/1093] time: 8120.6673, d_loss: 1.1705, g_loss: 0.8359\n",
      "[Sample] d_loss: 1.20474482, g_loss: 0.82821143\n",
      "Epoch: [ 9] [ 111/1093] time: 8124.7257, d_loss: 1.2141, g_loss: 0.8308\n",
      "[Sample] d_loss: 1.20414150, g_loss: 0.81242490\n",
      "Epoch: [ 9] [ 121/1093] time: 8128.7918, d_loss: 1.2048, g_loss: 0.8196\n",
      "[Sample] d_loss: 1.20780659, g_loss: 0.81294245\n",
      "Epoch: [ 9] [ 131/1093] time: 8132.9305, d_loss: 1.2448, g_loss: 0.8063\n",
      "[Sample] d_loss: 1.19631028, g_loss: 0.83465230\n",
      "Epoch: [ 9] [ 141/1093] time: 8137.2180, d_loss: 1.2187, g_loss: 0.8114\n",
      "[Sample] d_loss: 1.20666087, g_loss: 0.81573588\n",
      "Epoch: [ 9] [ 151/1093] time: 8141.3866, d_loss: 1.1963, g_loss: 0.8119\n",
      "[Sample] d_loss: 1.21287346, g_loss: 0.80732608\n",
      "Epoch: [ 9] [ 161/1093] time: 8145.4471, d_loss: 1.2276, g_loss: 0.8131\n",
      "[Sample] d_loss: 1.20944118, g_loss: 0.81633669\n",
      "Epoch: [ 9] [ 171/1093] time: 8149.6812, d_loss: 1.1904, g_loss: 0.8008\n",
      "[Sample] d_loss: 1.20339823, g_loss: 0.82424533\n",
      "Epoch: [ 9] [ 181/1093] time: 8153.8259, d_loss: 1.1812, g_loss: 0.8373\n",
      "[Sample] d_loss: 1.20279300, g_loss: 0.82305539\n",
      "Epoch: [ 9] [ 191/1093] time: 8158.1771, d_loss: 1.2159, g_loss: 0.8212\n",
      "[Sample] d_loss: 1.19387007, g_loss: 0.83205843\n",
      "Epoch: [ 9] [ 201/1093] time: 8162.4105, d_loss: 1.2232, g_loss: 0.7928\n",
      "[Sample] d_loss: 1.20540333, g_loss: 0.81942594\n",
      "Epoch: [ 9] [ 211/1093] time: 8166.7813, d_loss: 1.2394, g_loss: 0.8069\n",
      "[Sample] d_loss: 1.20221150, g_loss: 0.82226992\n",
      "Epoch: [ 9] [ 221/1093] time: 8171.5841, d_loss: 1.2414, g_loss: 0.8220\n",
      "[Sample] d_loss: 1.18844628, g_loss: 0.83298522\n",
      "Epoch: [ 9] [ 231/1093] time: 8175.9870, d_loss: 1.2033, g_loss: 0.8294\n",
      "[Sample] d_loss: 1.19960880, g_loss: 0.82316875\n",
      "Epoch: [ 9] [ 241/1093] time: 8180.2098, d_loss: 1.2298, g_loss: 0.8279\n",
      "[Sample] d_loss: 1.19699430, g_loss: 0.82828057\n",
      "Epoch: [ 9] [ 251/1093] time: 8184.3030, d_loss: 1.1925, g_loss: 0.8072\n",
      "[Sample] d_loss: 1.20822787, g_loss: 0.82345092\n",
      "Epoch: [ 9] [ 261/1093] time: 8188.3959, d_loss: 1.2406, g_loss: 0.8003\n",
      "[Sample] d_loss: 1.20502114, g_loss: 0.81806040\n",
      "Epoch: [ 9] [ 271/1093] time: 8192.4748, d_loss: 1.2560, g_loss: 0.7915\n",
      "[Sample] d_loss: 1.20684230, g_loss: 0.81137842\n",
      "Epoch: [ 9] [ 281/1093] time: 8196.7600, d_loss: 1.2245, g_loss: 0.7721\n",
      "[Sample] d_loss: 1.20671856, g_loss: 0.81604826\n",
      "Epoch: [ 9] [ 291/1093] time: 8201.0357, d_loss: 1.2384, g_loss: 0.7866\n",
      "[Sample] d_loss: 1.21421814, g_loss: 0.80020082\n",
      "Epoch: [ 9] [ 301/1093] time: 8205.1361, d_loss: 1.1522, g_loss: 0.8390\n",
      "[Sample] d_loss: 1.21561122, g_loss: 0.79956275\n",
      "Epoch: [ 9] [ 311/1093] time: 8209.0984, d_loss: 1.1387, g_loss: 0.8245\n",
      "[Sample] d_loss: 1.20059395, g_loss: 0.82742673\n",
      "Epoch: [ 9] [ 321/1093] time: 8213.1394, d_loss: 1.1788, g_loss: 0.7915\n",
      "[Sample] d_loss: 1.21571660, g_loss: 0.79625392\n",
      "Epoch: [ 9] [ 331/1093] time: 8217.0811, d_loss: 1.2485, g_loss: 0.7906\n",
      "[Sample] d_loss: 1.20101857, g_loss: 0.81298232\n",
      "Epoch: [ 9] [ 341/1093] time: 8221.0234, d_loss: 1.2350, g_loss: 0.7965\n",
      "[Sample] d_loss: 1.19338381, g_loss: 0.83053577\n",
      "Epoch: [ 9] [ 351/1093] time: 8225.0470, d_loss: 1.2374, g_loss: 0.7898\n",
      "[Sample] d_loss: 1.19132781, g_loss: 0.83661568\n",
      "Epoch: [ 9] [ 361/1093] time: 8229.3309, d_loss: 1.1808, g_loss: 0.8396\n",
      "[Sample] d_loss: 1.21354866, g_loss: 0.81084830\n",
      "Epoch: [ 9] [ 371/1093] time: 8233.6888, d_loss: 1.2073, g_loss: 0.8211\n",
      "[Sample] d_loss: 1.19594288, g_loss: 0.82322770\n",
      "Epoch: [ 9] [ 381/1093] time: 8238.1975, d_loss: 1.2377, g_loss: 0.7945\n",
      "[Sample] d_loss: 1.18878293, g_loss: 0.82896596\n",
      "Epoch: [ 9] [ 391/1093] time: 8243.1875, d_loss: 1.2257, g_loss: 0.8174\n",
      "[Sample] d_loss: 1.18962646, g_loss: 0.82584560\n",
      "Epoch: [ 9] [ 401/1093] time: 8247.7535, d_loss: 1.2501, g_loss: 0.7899\n",
      "[Sample] d_loss: 1.19906497, g_loss: 0.82192373\n",
      "Epoch: [ 9] [ 411/1093] time: 8252.2630, d_loss: 1.1919, g_loss: 0.8186\n",
      "[Sample] d_loss: 1.19895315, g_loss: 0.81463593\n",
      "Epoch: [ 9] [ 421/1093] time: 8256.3469, d_loss: 1.2241, g_loss: 0.7857\n",
      "[Sample] d_loss: 1.19590223, g_loss: 0.81454682\n",
      "Epoch: [ 9] [ 431/1093] time: 8260.4912, d_loss: 1.2547, g_loss: 0.7795\n",
      "[Sample] d_loss: 1.18788469, g_loss: 0.83540523\n",
      "Epoch: [ 9] [ 441/1093] time: 8264.5331, d_loss: 1.1935, g_loss: 0.7745\n",
      "[Sample] d_loss: 1.20036709, g_loss: 0.82026714\n",
      "Epoch: [ 9] [ 451/1093] time: 8268.5729, d_loss: 1.1552, g_loss: 0.8432\n",
      "[Sample] d_loss: 1.20074534, g_loss: 0.81280589\n",
      "Epoch: [ 9] [ 461/1093] time: 8272.7006, d_loss: 1.1690, g_loss: 0.8192\n",
      "[Sample] d_loss: 1.21742213, g_loss: 0.79000354\n",
      "Epoch: [ 9] [ 471/1093] time: 8277.5744, d_loss: 1.2254, g_loss: 0.8323\n",
      "[Sample] d_loss: 1.18796945, g_loss: 0.82487130\n",
      "Epoch: [ 9] [ 481/1093] time: 8281.9842, d_loss: 1.1897, g_loss: 0.8157\n",
      "[Sample] d_loss: 1.20172501, g_loss: 0.81316072\n",
      "Epoch: [ 9] [ 491/1093] time: 8286.3954, d_loss: 1.2022, g_loss: 0.7895\n",
      "[Sample] d_loss: 1.20603371, g_loss: 0.80862367\n",
      "Epoch: [ 9] [ 501/1093] time: 8290.7462, d_loss: 1.2555, g_loss: 0.7921\n",
      "[Sample] d_loss: 1.20565760, g_loss: 0.80882370\n",
      "Epoch: [ 9] [ 511/1093] time: 8294.7827, d_loss: 1.1664, g_loss: 0.8568\n",
      "[Sample] d_loss: 1.20963621, g_loss: 0.80512345\n",
      "Epoch: [ 9] [ 521/1093] time: 8299.9599, d_loss: 1.1963, g_loss: 0.7816\n",
      "[Sample] d_loss: 1.21881247, g_loss: 0.79314178\n",
      "Epoch: [ 9] [ 531/1093] time: 8304.4992, d_loss: 1.2255, g_loss: 0.7926\n",
      "[Sample] d_loss: 1.23396206, g_loss: 0.77899510\n",
      "Epoch: [ 9] [ 541/1093] time: 8308.9436, d_loss: 1.2230, g_loss: 0.7724\n",
      "[Sample] d_loss: 1.21262908, g_loss: 0.80406785\n",
      "Epoch: [ 9] [ 551/1093] time: 8313.0493, d_loss: 1.3001, g_loss: 0.7843\n",
      "[Sample] d_loss: 1.21283078, g_loss: 0.79949510\n",
      "Epoch: [ 9] [ 561/1093] time: 8317.2159, d_loss: 1.2053, g_loss: 0.8141\n",
      "[Sample] d_loss: 1.22603846, g_loss: 0.78265083\n",
      "Epoch: [ 9] [ 571/1093] time: 8321.3108, d_loss: 1.2639, g_loss: 0.7728\n",
      "[Sample] d_loss: 1.20382953, g_loss: 0.80991495\n",
      "Epoch: [ 9] [ 581/1093] time: 8325.3662, d_loss: 1.1791, g_loss: 0.8156\n",
      "[Sample] d_loss: 1.22189116, g_loss: 0.80016869\n",
      "Epoch: [ 9] [ 591/1093] time: 8329.9377, d_loss: 1.2284, g_loss: 0.8070\n",
      "[Sample] d_loss: 1.22099543, g_loss: 0.80196822\n",
      "Epoch: [ 9] [ 601/1093] time: 8334.1406, d_loss: 1.1608, g_loss: 0.8315\n",
      "[Sample] d_loss: 1.18720245, g_loss: 0.82714003\n",
      "Epoch: [ 9] [ 611/1093] time: 8338.2337, d_loss: 1.2400, g_loss: 0.8052\n",
      "[Sample] d_loss: 1.18787944, g_loss: 0.83874208\n",
      "Epoch: [ 9] [ 621/1093] time: 8343.7458, d_loss: 1.1793, g_loss: 0.8262\n",
      "[Sample] d_loss: 1.20131755, g_loss: 0.82081604\n",
      "Epoch: [ 9] [ 631/1093] time: 8348.6902, d_loss: 1.1723, g_loss: 0.8240\n",
      "[Sample] d_loss: 1.18859494, g_loss: 0.83199370\n",
      "Epoch: [ 9] [ 641/1093] time: 8352.9190, d_loss: 1.1799, g_loss: 0.8158\n",
      "[Sample] d_loss: 1.20626831, g_loss: 0.81482160\n",
      "Epoch: [ 9] [ 651/1093] time: 8357.4299, d_loss: 1.2142, g_loss: 0.8248\n",
      "[Sample] d_loss: 1.19727349, g_loss: 0.82073224\n",
      "Epoch: [ 9] [ 661/1093] time: 8361.7840, d_loss: 1.2422, g_loss: 0.7646\n",
      "[Sample] d_loss: 1.21133792, g_loss: 0.80515969\n",
      "Epoch: [ 9] [ 671/1093] time: 8367.8269, d_loss: 1.2803, g_loss: 0.7881\n",
      "[Sample] d_loss: 1.21859026, g_loss: 0.79474056\n",
      "Epoch: [ 9] [ 681/1093] time: 8376.8803, d_loss: 1.2655, g_loss: 0.7975\n",
      "[Sample] d_loss: 1.20598578, g_loss: 0.81551600\n",
      "Epoch: [ 9] [ 691/1093] time: 8383.5156, d_loss: 1.2063, g_loss: 0.7865\n",
      "[Sample] d_loss: 1.19110918, g_loss: 0.83264923\n",
      "Epoch: [ 9] [ 701/1093] time: 8388.3227, d_loss: 1.2426, g_loss: 0.7945\n",
      "[Sample] d_loss: 1.18563676, g_loss: 0.83901823\n",
      "Epoch: [ 9] [ 711/1093] time: 8393.2709, d_loss: 1.1943, g_loss: 0.8104\n",
      "[Sample] d_loss: 1.19673061, g_loss: 0.82696080\n",
      "Epoch: [ 9] [ 721/1093] time: 8405.7093, d_loss: 1.2220, g_loss: 0.7908\n",
      "[Sample] d_loss: 1.20667017, g_loss: 0.81101173\n",
      "Epoch: [ 9] [ 731/1093] time: 8411.8906, d_loss: 1.2059, g_loss: 0.7946\n",
      "[Sample] d_loss: 1.20214272, g_loss: 0.81204784\n",
      "Epoch: [ 9] [ 741/1093] time: 8417.3648, d_loss: 1.1990, g_loss: 0.8234\n",
      "[Sample] d_loss: 1.20836544, g_loss: 0.80866325\n",
      "Epoch: [ 9] [ 751/1093] time: 8423.1278, d_loss: 1.2115, g_loss: 0.8106\n",
      "[Sample] d_loss: 1.19636381, g_loss: 0.83021319\n",
      "Epoch: [ 9] [ 761/1093] time: 8429.9379, d_loss: 1.2916, g_loss: 0.7962\n",
      "[Sample] d_loss: 1.20546556, g_loss: 0.81495774\n",
      "Epoch: [ 9] [ 771/1093] time: 8436.2512, d_loss: 1.2342, g_loss: 0.7797\n",
      "[Sample] d_loss: 1.18645334, g_loss: 0.83730257\n",
      "Epoch: [ 9] [ 781/1093] time: 8441.8559, d_loss: 1.2732, g_loss: 0.7958\n",
      "[Sample] d_loss: 1.20775437, g_loss: 0.80713600\n",
      "Epoch: [ 9] [ 791/1093] time: 8446.6019, d_loss: 1.2641, g_loss: 0.8137\n",
      "[Sample] d_loss: 1.21563399, g_loss: 0.79524219\n",
      "Epoch: [ 9] [ 801/1093] time: 8451.0221, d_loss: 1.2297, g_loss: 0.7898\n",
      "[Sample] d_loss: 1.22532487, g_loss: 0.78549480\n",
      "Epoch: [ 9] [ 811/1093] time: 8455.2087, d_loss: 1.1960, g_loss: 0.7779\n",
      "[Sample] d_loss: 1.20863914, g_loss: 0.80246270\n",
      "Epoch: [ 9] [ 821/1093] time: 8461.4568, d_loss: 1.1824, g_loss: 0.8234\n",
      "[Sample] d_loss: 1.21122456, g_loss: 0.80391681\n",
      "Epoch: [ 9] [ 831/1093] time: 8474.8219, d_loss: 1.2276, g_loss: 0.7841\n",
      "[Sample] d_loss: 1.21605051, g_loss: 0.79608911\n",
      "Epoch: [ 9] [ 841/1093] time: 8483.2255, d_loss: 1.2416, g_loss: 0.7912\n",
      "[Sample] d_loss: 1.19356513, g_loss: 0.83103061\n",
      "Epoch: [ 9] [ 851/1093] time: 8494.6241, d_loss: 1.2036, g_loss: 0.7969\n",
      "[Sample] d_loss: 1.19644451, g_loss: 0.82090449\n",
      "Epoch: [ 9] [ 861/1093] time: 8502.6771, d_loss: 1.1836, g_loss: 0.8177\n",
      "[Sample] d_loss: 1.17974567, g_loss: 0.84806418\n",
      "Epoch: [ 9] [ 871/1093] time: 8510.5697, d_loss: 1.2274, g_loss: 0.7885\n",
      "[Sample] d_loss: 1.20002413, g_loss: 0.81548339\n",
      "Epoch: [ 9] [ 881/1093] time: 8516.5828, d_loss: 1.2330, g_loss: 0.8213\n",
      "[Sample] d_loss: 1.19918525, g_loss: 0.81264275\n",
      "Epoch: [ 9] [ 891/1093] time: 8521.9393, d_loss: 1.2524, g_loss: 0.7773\n",
      "[Sample] d_loss: 1.20659947, g_loss: 0.81049597\n",
      "Epoch: [ 9] [ 901/1093] time: 8528.2116, d_loss: 1.2349, g_loss: 0.7749\n",
      "[Sample] d_loss: 1.21574616, g_loss: 0.79752910\n",
      "Epoch: [ 9] [ 911/1093] time: 8534.0557, d_loss: 1.1780, g_loss: 0.8104\n",
      "[Sample] d_loss: 1.19732714, g_loss: 0.81927156\n",
      "Epoch: [ 9] [ 921/1093] time: 8539.0161, d_loss: 1.2350, g_loss: 0.8123\n",
      "[Sample] d_loss: 1.22427750, g_loss: 0.78313053\n",
      "Epoch: [ 9] [ 931/1093] time: 8544.0485, d_loss: 1.2112, g_loss: 0.8265\n",
      "[Sample] d_loss: 1.22918010, g_loss: 0.78184944\n",
      "Epoch: [ 9] [ 941/1093] time: 8552.1584, d_loss: 1.1948, g_loss: 0.7901\n",
      "[Sample] d_loss: 1.22460246, g_loss: 0.78100812\n",
      "Epoch: [ 9] [ 951/1093] time: 8556.5361, d_loss: 1.2222, g_loss: 0.7882\n",
      "[Sample] d_loss: 1.23455286, g_loss: 0.77265656\n",
      "Epoch: [ 9] [ 961/1093] time: 8560.6842, d_loss: 1.2093, g_loss: 0.7695\n",
      "[Sample] d_loss: 1.21886349, g_loss: 0.79083890\n",
      "Epoch: [ 9] [ 971/1093] time: 8565.1801, d_loss: 1.1952, g_loss: 0.8321\n",
      "[Sample] d_loss: 1.20896482, g_loss: 0.81787694\n",
      "Epoch: [ 9] [ 981/1093] time: 8569.2463, d_loss: 1.2809, g_loss: 0.7731\n",
      "[Sample] d_loss: 1.21447635, g_loss: 0.80020267\n",
      "Epoch: [ 9] [ 991/1093] time: 8573.6789, d_loss: 1.1931, g_loss: 0.7712\n",
      "[Sample] d_loss: 1.22360432, g_loss: 0.78892046\n",
      "Epoch: [ 9] [1001/1093] time: 8578.1469, d_loss: 1.2116, g_loss: 0.7868\n",
      "[Sample] d_loss: 1.22338033, g_loss: 0.79516643\n",
      "Epoch: [ 9] [1011/1093] time: 8582.2223, d_loss: 1.1751, g_loss: 0.8379\n",
      "[Sample] d_loss: 1.20818162, g_loss: 0.80831277\n",
      "Epoch: [ 9] [1021/1093] time: 8586.5413, d_loss: 1.1980, g_loss: 0.8315\n",
      "[Sample] d_loss: 1.20034039, g_loss: 0.81826931\n",
      "Epoch: [ 9] [1031/1093] time: 8591.4502, d_loss: 1.2379, g_loss: 0.8083\n",
      "[Sample] d_loss: 1.20442939, g_loss: 0.81463391\n",
      "Epoch: [ 9] [1041/1093] time: 8595.7907, d_loss: 1.2008, g_loss: 0.8189\n",
      "[Sample] d_loss: 1.20194089, g_loss: 0.82136691\n",
      "Epoch: [ 9] [1051/1093] time: 8600.1612, d_loss: 1.2569, g_loss: 0.8014\n",
      "[Sample] d_loss: 1.22333801, g_loss: 0.80017877\n",
      "Epoch: [ 9] [1061/1093] time: 8605.0392, d_loss: 1.2048, g_loss: 0.8286\n",
      "[Sample] d_loss: 1.23758125, g_loss: 0.77695543\n",
      "Epoch: [ 9] [1071/1093] time: 8609.8170, d_loss: 1.1851, g_loss: 0.8288\n",
      "[Sample] d_loss: 1.21646094, g_loss: 0.79500115\n",
      "Epoch: [ 9] [1081/1093] time: 8614.1436, d_loss: 1.2013, g_loss: 0.8082\n",
      "[Sample] d_loss: 1.21274030, g_loss: 0.80346954\n",
      "Epoch: [ 9] [1091/1093] time: 8618.7310, d_loss: 1.2214, g_loss: 0.8356\n",
      "[Sample] d_loss: 1.22014070, g_loss: 0.79787648\n",
      "Epoch: [10] [   8/1093] time: 8623.0497, d_loss: 1.1647, g_loss: 0.8314\n",
      "[Sample] d_loss: 1.20895338, g_loss: 0.80879498\n",
      "Epoch: [10] [  18/1093] time: 8627.1543, d_loss: 1.2191, g_loss: 0.8096\n",
      "[Sample] d_loss: 1.19640708, g_loss: 0.82182956\n",
      "Epoch: [10] [  28/1093] time: 8631.3526, d_loss: 1.2234, g_loss: 0.8496\n",
      "[Sample] d_loss: 1.19895709, g_loss: 0.81723976\n",
      "Epoch: [10] [  38/1093] time: 8635.5053, d_loss: 1.2004, g_loss: 0.8165\n",
      "[Sample] d_loss: 1.19961989, g_loss: 0.81868565\n",
      "Epoch: [10] [  48/1093] time: 8639.5907, d_loss: 1.2126, g_loss: 0.8240\n",
      "[Sample] d_loss: 1.18578863, g_loss: 0.82919002\n",
      "Epoch: [10] [  58/1093] time: 8643.8118, d_loss: 1.2084, g_loss: 0.8065\n",
      "[Sample] d_loss: 1.21089029, g_loss: 0.81048143\n",
      "Epoch: [10] [  68/1093] time: 8647.8752, d_loss: 1.2252, g_loss: 0.8087\n",
      "[Sample] d_loss: 1.19785309, g_loss: 0.81692189\n",
      "Epoch: [10] [  78/1093] time: 8652.1051, d_loss: 1.2209, g_loss: 0.8332\n",
      "[Sample] d_loss: 1.21000719, g_loss: 0.80902445\n",
      "Epoch: [10] [  88/1093] time: 8657.5946, d_loss: 1.2356, g_loss: 0.7965\n",
      "[Sample] d_loss: 1.20634496, g_loss: 0.81315440\n",
      "Epoch: [10] [  98/1093] time: 8662.6006, d_loss: 1.2198, g_loss: 0.7704\n",
      "[Sample] d_loss: 1.22315955, g_loss: 0.78924811\n",
      "Epoch: [10] [ 108/1093] time: 8666.8848, d_loss: 1.2492, g_loss: 0.8027\n",
      "[Sample] d_loss: 1.22978830, g_loss: 0.78148627\n",
      "Epoch: [10] [ 118/1093] time: 8670.9082, d_loss: 1.2259, g_loss: 0.8295\n",
      "[Sample] d_loss: 1.25293565, g_loss: 0.76568449\n",
      "Epoch: [10] [ 128/1093] time: 8674.8760, d_loss: 1.1762, g_loss: 0.8169\n",
      "[Sample] d_loss: 1.23439908, g_loss: 0.79502219\n",
      "Epoch: [10] [ 138/1093] time: 8678.8583, d_loss: 1.2782, g_loss: 0.7929\n",
      "[Sample] d_loss: 1.21209383, g_loss: 0.80818927\n",
      "Epoch: [10] [ 148/1093] time: 8682.8204, d_loss: 1.2875, g_loss: 0.8168\n",
      "[Sample] d_loss: 1.22235346, g_loss: 0.79576790\n",
      "Epoch: [10] [ 158/1093] time: 8686.8471, d_loss: 1.2057, g_loss: 0.8103\n",
      "[Sample] d_loss: 1.21598697, g_loss: 0.80455297\n",
      "Epoch: [10] [ 168/1093] time: 8690.8780, d_loss: 1.1821, g_loss: 0.8091\n",
      "[Sample] d_loss: 1.21488750, g_loss: 0.80754864\n",
      "Epoch: [10] [ 178/1093] time: 8694.9007, d_loss: 1.2758, g_loss: 0.8046\n",
      "[Sample] d_loss: 1.20759296, g_loss: 0.81764686\n",
      "Epoch: [10] [ 188/1093] time: 8698.9012, d_loss: 1.1826, g_loss: 0.8167\n",
      "[Sample] d_loss: 1.21078682, g_loss: 0.80407560\n",
      "Epoch: [10] [ 198/1093] time: 8702.8748, d_loss: 1.2155, g_loss: 0.8215\n",
      "[Sample] d_loss: 1.21238494, g_loss: 0.80530274\n",
      "Epoch: [10] [ 208/1093] time: 8706.9474, d_loss: 1.2352, g_loss: 0.7827\n",
      "[Sample] d_loss: 1.19975626, g_loss: 0.81914091\n",
      "Epoch: [10] [ 218/1093] time: 8711.0252, d_loss: 1.1996, g_loss: 0.8098\n",
      "[Sample] d_loss: 1.19600046, g_loss: 0.82128507\n",
      "Epoch: [10] [ 228/1093] time: 8714.9769, d_loss: 1.2333, g_loss: 0.7952\n",
      "[Sample] d_loss: 1.17297733, g_loss: 0.84995997\n",
      "Epoch: [10] [ 238/1093] time: 8719.0370, d_loss: 1.2131, g_loss: 0.8035\n",
      "[Sample] d_loss: 1.19216394, g_loss: 0.82553101\n",
      "Epoch: [10] [ 248/1093] time: 8722.9967, d_loss: 1.1993, g_loss: 0.8044\n",
      "[Sample] d_loss: 1.18892896, g_loss: 0.82664126\n",
      "Epoch: [10] [ 258/1093] time: 8726.9601, d_loss: 1.1727, g_loss: 0.8143\n",
      "[Sample] d_loss: 1.19351006, g_loss: 0.82341927\n",
      "Epoch: [10] [ 268/1093] time: 8730.9138, d_loss: 1.1437, g_loss: 0.8338\n",
      "[Sample] d_loss: 1.18509531, g_loss: 0.84556556\n",
      "Epoch: [10] [ 278/1093] time: 8734.8773, d_loss: 1.2216, g_loss: 0.7850\n",
      "[Sample] d_loss: 1.18857443, g_loss: 0.83401167\n",
      "Epoch: [10] [ 288/1093] time: 8738.8627, d_loss: 1.2315, g_loss: 0.7929\n",
      "[Sample] d_loss: 1.18630886, g_loss: 0.83485198\n",
      "Epoch: [10] [ 298/1093] time: 8742.8465, d_loss: 1.1847, g_loss: 0.8234\n",
      "[Sample] d_loss: 1.19580388, g_loss: 0.82860947\n",
      "Epoch: [10] [ 308/1093] time: 8746.9321, d_loss: 1.2352, g_loss: 0.7977\n",
      "[Sample] d_loss: 1.19204009, g_loss: 0.82925445\n",
      "Epoch: [10] [ 318/1093] time: 8751.0126, d_loss: 1.2410, g_loss: 0.8177\n",
      "[Sample] d_loss: 1.17498934, g_loss: 0.84573811\n",
      "Epoch: [10] [ 328/1093] time: 8754.9635, d_loss: 1.1835, g_loss: 0.8221\n",
      "[Sample] d_loss: 1.20982099, g_loss: 0.80670989\n",
      "Epoch: [10] [ 338/1093] time: 8758.9078, d_loss: 1.1809, g_loss: 0.8285\n",
      "[Sample] d_loss: 1.20412600, g_loss: 0.81597906\n",
      "Epoch: [10] [ 348/1093] time: 8762.9016, d_loss: 1.1912, g_loss: 0.8343\n",
      "[Sample] d_loss: 1.19155288, g_loss: 0.82392514\n",
      "Epoch: [10] [ 358/1093] time: 8766.8673, d_loss: 1.1900, g_loss: 0.7943\n",
      "[Sample] d_loss: 1.18866634, g_loss: 0.82840198\n",
      "Epoch: [10] [ 368/1093] time: 8770.8495, d_loss: 1.2067, g_loss: 0.8217\n",
      "[Sample] d_loss: 1.19218695, g_loss: 0.82734692\n",
      "Epoch: [10] [ 378/1093] time: 8774.7823, d_loss: 1.2189, g_loss: 0.8283\n",
      "[Sample] d_loss: 1.21366155, g_loss: 0.80411696\n",
      "Epoch: [10] [ 388/1093] time: 8778.7369, d_loss: 1.1897, g_loss: 0.8301\n",
      "[Sample] d_loss: 1.20934463, g_loss: 0.81138092\n",
      "Epoch: [10] [ 398/1093] time: 8782.7766, d_loss: 1.2270, g_loss: 0.8336\n",
      "[Sample] d_loss: 1.21886086, g_loss: 0.78944039\n",
      "Epoch: [10] [ 408/1093] time: 8786.7869, d_loss: 1.2203, g_loss: 0.8130\n",
      "[Sample] d_loss: 1.18777931, g_loss: 0.83036202\n",
      "Epoch: [10] [ 418/1093] time: 8790.8486, d_loss: 1.1832, g_loss: 0.8299\n",
      "[Sample] d_loss: 1.20121193, g_loss: 0.80927277\n",
      "Epoch: [10] [ 428/1093] time: 8795.0708, d_loss: 1.1864, g_loss: 0.8247\n",
      "[Sample] d_loss: 1.21318424, g_loss: 0.79297960\n",
      "Epoch: [10] [ 438/1093] time: 8800.0189, d_loss: 1.2293, g_loss: 0.7829\n",
      "[Sample] d_loss: 1.20971310, g_loss: 0.80299175\n",
      "Epoch: [10] [ 448/1093] time: 8805.0819, d_loss: 1.2084, g_loss: 0.8622\n",
      "[Sample] d_loss: 1.20915699, g_loss: 0.81254756\n",
      "Epoch: [10] [ 458/1093] time: 8809.0895, d_loss: 1.2068, g_loss: 0.8099\n",
      "[Sample] d_loss: 1.19585371, g_loss: 0.81846690\n",
      "Epoch: [10] [ 468/1093] time: 8813.1324, d_loss: 1.2409, g_loss: 0.7662\n",
      "[Sample] d_loss: 1.20918548, g_loss: 0.80359435\n",
      "Epoch: [10] [ 478/1093] time: 8817.2119, d_loss: 1.1887, g_loss: 0.7944\n",
      "[Sample] d_loss: 1.20583117, g_loss: 0.81443930\n",
      "Epoch: [10] [ 488/1093] time: 8821.2139, d_loss: 1.2703, g_loss: 0.7973\n",
      "[Sample] d_loss: 1.19852364, g_loss: 0.81801128\n",
      "Epoch: [10] [ 498/1093] time: 8825.4020, d_loss: 1.1470, g_loss: 0.8235\n",
      "[Sample] d_loss: 1.20717776, g_loss: 0.81002808\n",
      "Epoch: [10] [ 508/1093] time: 8829.4775, d_loss: 1.2141, g_loss: 0.7961\n",
      "[Sample] d_loss: 1.21225059, g_loss: 0.80631411\n",
      "Epoch: [10] [ 518/1093] time: 8833.6390, d_loss: 1.2135, g_loss: 0.8206\n",
      "[Sample] d_loss: 1.19288278, g_loss: 0.83177125\n",
      "Epoch: [10] [ 528/1093] time: 8837.8042, d_loss: 1.1670, g_loss: 0.7968\n",
      "[Sample] d_loss: 1.22443843, g_loss: 0.79860395\n",
      "Epoch: [10] [ 538/1093] time: 8841.9684, d_loss: 1.2154, g_loss: 0.8113\n",
      "[Sample] d_loss: 1.19314694, g_loss: 0.83145243\n",
      "Epoch: [10] [ 548/1093] time: 8846.3058, d_loss: 1.1916, g_loss: 0.8463\n",
      "[Sample] d_loss: 1.20516717, g_loss: 0.82139111\n",
      "Epoch: [10] [ 558/1093] time: 8850.4097, d_loss: 1.2011, g_loss: 0.8017\n",
      "[Sample] d_loss: 1.20610452, g_loss: 0.81904238\n",
      "Epoch: [10] [ 568/1093] time: 8854.5692, d_loss: 1.2161, g_loss: 0.8161\n",
      "[Sample] d_loss: 1.18059826, g_loss: 0.84784573\n",
      "Epoch: [10] [ 578/1093] time: 8858.8690, d_loss: 1.1613, g_loss: 0.8284\n",
      "[Sample] d_loss: 1.19518328, g_loss: 0.82313621\n",
      "Epoch: [10] [ 588/1093] time: 8863.1732, d_loss: 1.2208, g_loss: 0.8382\n",
      "[Sample] d_loss: 1.17928910, g_loss: 0.84251970\n",
      "Epoch: [10] [ 598/1093] time: 8867.3356, d_loss: 1.1856, g_loss: 0.8274\n",
      "[Sample] d_loss: 1.18839264, g_loss: 0.83702546\n",
      "Epoch: [10] [ 608/1093] time: 8871.7870, d_loss: 1.2153, g_loss: 0.8138\n",
      "[Sample] d_loss: 1.19010067, g_loss: 0.83240092\n",
      "Epoch: [10] [ 618/1093] time: 8875.9508, d_loss: 1.1915, g_loss: 0.8101\n",
      "[Sample] d_loss: 1.17317629, g_loss: 0.85355151\n",
      "Epoch: [10] [ 628/1093] time: 8880.5585, d_loss: 1.2060, g_loss: 0.8318\n",
      "[Sample] d_loss: 1.17842877, g_loss: 0.84412515\n",
      "Epoch: [10] [ 638/1093] time: 8884.8205, d_loss: 1.2163, g_loss: 0.8100\n",
      "[Sample] d_loss: 1.17772925, g_loss: 0.85107851\n",
      "Epoch: [10] [ 648/1093] time: 8888.8063, d_loss: 1.1926, g_loss: 0.7969\n",
      "[Sample] d_loss: 1.18190587, g_loss: 0.84263420\n",
      "Epoch: [10] [ 658/1093] time: 8892.8816, d_loss: 1.1838, g_loss: 0.8378\n",
      "[Sample] d_loss: 1.19021773, g_loss: 0.83270508\n",
      "Epoch: [10] [ 668/1093] time: 8896.8806, d_loss: 1.1790, g_loss: 0.8114\n",
      "[Sample] d_loss: 1.18107712, g_loss: 0.84362876\n",
      "Epoch: [10] [ 678/1093] time: 8900.8605, d_loss: 1.2064, g_loss: 0.7737\n",
      "[Sample] d_loss: 1.17190313, g_loss: 0.86517656\n",
      "Epoch: [10] [ 688/1093] time: 8905.0862, d_loss: 1.2104, g_loss: 0.8179\n",
      "[Sample] d_loss: 1.18532252, g_loss: 0.83824825\n",
      "Epoch: [10] [ 698/1093] time: 8909.0697, d_loss: 1.2211, g_loss: 0.8160\n",
      "[Sample] d_loss: 1.19134045, g_loss: 0.83320540\n",
      "Epoch: [10] [ 708/1093] time: 8913.0773, d_loss: 1.2003, g_loss: 0.8365\n",
      "[Sample] d_loss: 1.18940187, g_loss: 0.82925403\n",
      "Epoch: [10] [ 718/1093] time: 8917.0536, d_loss: 1.1502, g_loss: 0.8417\n",
      "[Sample] d_loss: 1.17832375, g_loss: 0.84901130\n",
      "Epoch: [10] [ 728/1093] time: 8921.0849, d_loss: 1.2084, g_loss: 0.8068\n",
      "[Sample] d_loss: 1.18336582, g_loss: 0.84311175\n",
      "Epoch: [10] [ 738/1093] time: 8925.0395, d_loss: 1.1837, g_loss: 0.8331\n",
      "[Sample] d_loss: 1.17144620, g_loss: 0.85369813\n",
      "Epoch: [10] [ 748/1093] time: 8929.0176, d_loss: 1.1578, g_loss: 0.8377\n",
      "[Sample] d_loss: 1.17814994, g_loss: 0.83505660\n",
      "Epoch: [10] [ 758/1093] time: 8933.1251, d_loss: 1.2069, g_loss: 0.7872\n",
      "[Sample] d_loss: 1.18354249, g_loss: 0.83013451\n",
      "Epoch: [10] [ 768/1093] time: 8937.3707, d_loss: 1.1919, g_loss: 0.8177\n",
      "[Sample] d_loss: 1.17507648, g_loss: 0.84473097\n",
      "Epoch: [10] [ 778/1093] time: 8941.7035, d_loss: 1.2014, g_loss: 0.8205\n",
      "[Sample] d_loss: 1.17961109, g_loss: 0.84822750\n",
      "Epoch: [10] [ 788/1093] time: 8945.7532, d_loss: 1.2087, g_loss: 0.8017\n",
      "[Sample] d_loss: 1.17648304, g_loss: 0.83795452\n",
      "Epoch: [10] [ 798/1093] time: 8949.7504, d_loss: 1.2624, g_loss: 0.8032\n",
      "[Sample] d_loss: 1.18357849, g_loss: 0.82645243\n",
      "Epoch: [10] [ 808/1093] time: 8953.7574, d_loss: 1.1915, g_loss: 0.8074\n",
      "[Sample] d_loss: 1.18508029, g_loss: 0.83141422\n",
      "Epoch: [10] [ 818/1093] time: 8957.8113, d_loss: 1.1954, g_loss: 0.8052\n",
      "[Sample] d_loss: 1.17982352, g_loss: 0.84060824\n",
      "Epoch: [10] [ 828/1093] time: 8961.7994, d_loss: 1.2414, g_loss: 0.8128\n",
      "[Sample] d_loss: 1.19285131, g_loss: 0.83925110\n",
      "Epoch: [10] [ 838/1093] time: 8965.7869, d_loss: 1.1995, g_loss: 0.8354\n",
      "[Sample] d_loss: 1.17361498, g_loss: 0.85360199\n",
      "Epoch: [10] [ 848/1093] time: 8969.7510, d_loss: 1.2100, g_loss: 0.7829\n",
      "[Sample] d_loss: 1.18013179, g_loss: 0.84074950\n",
      "Epoch: [10] [ 858/1093] time: 8973.8673, d_loss: 1.2807, g_loss: 0.7615\n",
      "[Sample] d_loss: 1.18995035, g_loss: 0.82815939\n",
      "Epoch: [10] [ 868/1093] time: 8978.1541, d_loss: 1.2727, g_loss: 0.7996\n",
      "[Sample] d_loss: 1.18112445, g_loss: 0.85246229\n",
      "Epoch: [10] [ 878/1093] time: 8982.2782, d_loss: 1.2505, g_loss: 0.7669\n",
      "[Sample] d_loss: 1.17902839, g_loss: 0.84099782\n",
      "Epoch: [10] [ 888/1093] time: 8986.3997, d_loss: 1.1872, g_loss: 0.8227\n",
      "[Sample] d_loss: 1.19535732, g_loss: 0.83095264\n",
      "Epoch: [10] [ 898/1093] time: 8990.5816, d_loss: 1.2312, g_loss: 0.7892\n",
      "[Sample] d_loss: 1.19341862, g_loss: 0.83338571\n",
      "Epoch: [10] [ 908/1093] time: 8994.7089, d_loss: 1.2268, g_loss: 0.8207\n",
      "[Sample] d_loss: 1.18357754, g_loss: 0.83445054\n",
      "Epoch: [10] [ 918/1093] time: 8998.9304, d_loss: 1.1754, g_loss: 0.8171\n",
      "[Sample] d_loss: 1.19752526, g_loss: 0.83192670\n",
      "Epoch: [10] [ 928/1093] time: 9003.7757, d_loss: 1.1879, g_loss: 0.8273\n",
      "[Sample] d_loss: 1.19775045, g_loss: 0.82494509\n",
      "Epoch: [10] [ 938/1093] time: 9008.5654, d_loss: 1.2029, g_loss: 0.8292\n",
      "[Sample] d_loss: 1.21563148, g_loss: 0.80219698\n",
      "Epoch: [10] [ 948/1093] time: 9012.5794, d_loss: 1.1829, g_loss: 0.7996\n",
      "[Sample] d_loss: 1.19820845, g_loss: 0.82258719\n",
      "Epoch: [10] [ 958/1093] time: 9016.6499, d_loss: 1.2025, g_loss: 0.8114\n",
      "[Sample] d_loss: 1.20265782, g_loss: 0.81969458\n",
      "Epoch: [10] [ 968/1093] time: 9020.6647, d_loss: 1.2270, g_loss: 0.8117\n",
      "[Sample] d_loss: 1.19998097, g_loss: 0.82929772\n",
      "Epoch: [10] [ 978/1093] time: 9024.8649, d_loss: 1.2049, g_loss: 0.8125\n",
      "[Sample] d_loss: 1.18452859, g_loss: 0.83515668\n",
      "Epoch: [10] [ 988/1093] time: 9029.6565, d_loss: 1.2357, g_loss: 0.8329\n",
      "[Sample] d_loss: 1.19769657, g_loss: 0.81934613\n",
      "Epoch: [10] [ 998/1093] time: 9034.3336, d_loss: 1.1954, g_loss: 0.8190\n",
      "[Sample] d_loss: 1.18540239, g_loss: 0.82553303\n",
      "Epoch: [10] [1008/1093] time: 9038.3789, d_loss: 1.2387, g_loss: 0.7724\n",
      "[Sample] d_loss: 1.19706023, g_loss: 0.81687182\n",
      "Epoch: [10] [1018/1093] time: 9042.6754, d_loss: 1.1824, g_loss: 0.8230\n",
      "[Sample] d_loss: 1.21094894, g_loss: 0.81033713\n",
      "Epoch: [10] [1028/1093] time: 9047.0708, d_loss: 1.1959, g_loss: 0.8175\n",
      "[Sample] d_loss: 1.20304537, g_loss: 0.82340574\n",
      "Epoch: [10] [1038/1093] time: 9051.1860, d_loss: 1.2132, g_loss: 0.8103\n",
      "[Sample] d_loss: 1.19417393, g_loss: 0.82832879\n",
      "Epoch: [10] [1048/1093] time: 9055.2349, d_loss: 1.2102, g_loss: 0.8097\n",
      "[Sample] d_loss: 1.19700551, g_loss: 0.82607907\n",
      "Epoch: [10] [1058/1093] time: 9059.3962, d_loss: 1.2165, g_loss: 0.8046\n",
      "[Sample] d_loss: 1.19307160, g_loss: 0.83442712\n",
      "Epoch: [10] [1068/1093] time: 9064.0589, d_loss: 1.1785, g_loss: 0.8122\n",
      "[Sample] d_loss: 1.19405723, g_loss: 0.82245898\n",
      "Epoch: [10] [1078/1093] time: 9069.3161, d_loss: 1.1901, g_loss: 0.8041\n",
      "[Sample] d_loss: 1.17879140, g_loss: 0.83826411\n",
      "Epoch: [10] [1088/1093] time: 9076.6273, d_loss: 1.2266, g_loss: 0.8223\n",
      "[Sample] d_loss: 1.19318962, g_loss: 0.82691216\n",
      "[Sample] d_loss: 1.18933523, g_loss: 0.83142424\n",
      "Epoch: [11] [   5/1093] time: 9090.4423, d_loss: 1.2101, g_loss: 0.8293\n",
      "[Sample] d_loss: 1.17178237, g_loss: 0.85295832\n",
      "Epoch: [11] [  15/1093] time: 9094.7535, d_loss: 1.1468, g_loss: 0.8868\n",
      "[Sample] d_loss: 1.18384743, g_loss: 0.83536267\n",
      "Epoch: [11] [  25/1093] time: 9099.5518, d_loss: 1.1835, g_loss: 0.8489\n",
      "[Sample] d_loss: 1.15836799, g_loss: 0.86643165\n",
      "Epoch: [11] [  35/1093] time: 9104.0924, d_loss: 1.1769, g_loss: 0.8305\n",
      "[Sample] d_loss: 1.16236353, g_loss: 0.86137980\n",
      "Epoch: [11] [  45/1093] time: 9109.0793, d_loss: 1.2131, g_loss: 0.8019\n",
      "[Sample] d_loss: 1.17766976, g_loss: 0.83450276\n",
      "Epoch: [11] [  55/1093] time: 9114.9221, d_loss: 1.0999, g_loss: 0.8706\n",
      "[Sample] d_loss: 1.18421435, g_loss: 0.83971643\n",
      "Epoch: [11] [  65/1093] time: 9120.6394, d_loss: 1.1812, g_loss: 0.8215\n",
      "[Sample] d_loss: 1.17294347, g_loss: 0.84282792\n",
      "Epoch: [11] [  75/1093] time: 9124.9685, d_loss: 1.1917, g_loss: 0.8361\n",
      "[Sample] d_loss: 1.17540324, g_loss: 0.83689260\n",
      "Epoch: [11] [  85/1093] time: 9128.9946, d_loss: 1.1932, g_loss: 0.8075\n",
      "[Sample] d_loss: 1.17605615, g_loss: 0.83702171\n",
      "Epoch: [11] [  95/1093] time: 9133.2324, d_loss: 1.1610, g_loss: 0.8236\n",
      "[Sample] d_loss: 1.17515039, g_loss: 0.83909899\n",
      "Epoch: [11] [ 105/1093] time: 9137.3463, d_loss: 1.1860, g_loss: 0.8059\n",
      "[Sample] d_loss: 1.17714703, g_loss: 0.83324093\n",
      "Epoch: [11] [ 115/1093] time: 9141.6043, d_loss: 1.1838, g_loss: 0.7981\n",
      "[Sample] d_loss: 1.18246031, g_loss: 0.83545613\n",
      "Epoch: [11] [ 125/1093] time: 9146.0375, d_loss: 1.2024, g_loss: 0.8213\n",
      "[Sample] d_loss: 1.14688945, g_loss: 0.87683880\n",
      "Epoch: [11] [ 135/1093] time: 9150.9488, d_loss: 1.2127, g_loss: 0.7952\n",
      "[Sample] d_loss: 1.17564392, g_loss: 0.84229660\n",
      "Epoch: [11] [ 145/1093] time: 9155.6351, d_loss: 1.1788, g_loss: 0.8218\n",
      "[Sample] d_loss: 1.17613494, g_loss: 0.84475744\n",
      "Epoch: [11] [ 155/1093] time: 9160.3095, d_loss: 1.1921, g_loss: 0.8073\n",
      "[Sample] d_loss: 1.16586089, g_loss: 0.85023379\n",
      "Epoch: [11] [ 165/1093] time: 9164.4600, d_loss: 1.1906, g_loss: 0.8145\n",
      "[Sample] d_loss: 1.18947554, g_loss: 0.82967842\n",
      "Epoch: [11] [ 175/1093] time: 9168.6433, d_loss: 1.2136, g_loss: 0.8177\n",
      "[Sample] d_loss: 1.19831359, g_loss: 0.81879026\n",
      "Epoch: [11] [ 185/1093] time: 9173.2974, d_loss: 1.2032, g_loss: 0.7861\n",
      "[Sample] d_loss: 1.18798351, g_loss: 0.82733309\n",
      "Epoch: [11] [ 195/1093] time: 9177.5536, d_loss: 1.1379, g_loss: 0.8143\n",
      "[Sample] d_loss: 1.19176400, g_loss: 0.82890135\n",
      "Epoch: [11] [ 205/1093] time: 9181.8993, d_loss: 1.1912, g_loss: 0.8297\n",
      "[Sample] d_loss: 1.18894553, g_loss: 0.83000708\n",
      "Epoch: [11] [ 215/1093] time: 9186.1595, d_loss: 1.2237, g_loss: 0.8033\n",
      "[Sample] d_loss: 1.18609679, g_loss: 0.82515943\n",
      "Epoch: [11] [ 225/1093] time: 9190.7494, d_loss: 1.2438, g_loss: 0.8044\n",
      "[Sample] d_loss: 1.18851686, g_loss: 0.83002794\n",
      "Epoch: [11] [ 235/1093] time: 9195.5765, d_loss: 1.2365, g_loss: 0.7910\n",
      "[Sample] d_loss: 1.18386388, g_loss: 0.84316117\n",
      "Epoch: [11] [ 245/1093] time: 9200.3921, d_loss: 1.2244, g_loss: 0.8211\n",
      "[Sample] d_loss: 1.15589547, g_loss: 0.86571950\n",
      "Epoch: [11] [ 255/1093] time: 9204.5550, d_loss: 1.1903, g_loss: 0.8329\n",
      "[Sample] d_loss: 1.17102146, g_loss: 0.85840678\n",
      "Epoch: [11] [ 265/1093] time: 9208.9881, d_loss: 1.1748, g_loss: 0.8211\n",
      "[Sample] d_loss: 1.15748346, g_loss: 0.87451231\n",
      "Epoch: [11] [ 275/1093] time: 9213.5847, d_loss: 1.2615, g_loss: 0.7655\n",
      "[Sample] d_loss: 1.14802873, g_loss: 0.87762594\n",
      "Epoch: [11] [ 285/1093] time: 9218.3249, d_loss: 1.1748, g_loss: 0.8157\n",
      "[Sample] d_loss: 1.17396426, g_loss: 0.84035045\n",
      "Epoch: [11] [ 295/1093] time: 9222.5978, d_loss: 1.2370, g_loss: 0.7886\n",
      "[Sample] d_loss: 1.17892218, g_loss: 0.83410877\n",
      "Epoch: [11] [ 305/1093] time: 9226.9510, d_loss: 1.1680, g_loss: 0.8075\n",
      "[Sample] d_loss: 1.19580340, g_loss: 0.81991154\n",
      "Epoch: [11] [ 315/1093] time: 9230.9844, d_loss: 1.2074, g_loss: 0.8294\n",
      "[Sample] d_loss: 1.17621958, g_loss: 0.84632969\n",
      "Epoch: [11] [ 325/1093] time: 9234.9067, d_loss: 1.1749, g_loss: 0.8374\n",
      "[Sample] d_loss: 1.19045401, g_loss: 0.82490349\n",
      "Epoch: [11] [ 335/1093] time: 9239.1150, d_loss: 1.1790, g_loss: 0.8065\n",
      "[Sample] d_loss: 1.18497407, g_loss: 0.84069222\n",
      "Epoch: [11] [ 345/1093] time: 9243.3547, d_loss: 1.2113, g_loss: 0.8119\n",
      "[Sample] d_loss: 1.16756272, g_loss: 0.86706424\n",
      "Epoch: [11] [ 355/1093] time: 9247.4413, d_loss: 1.2102, g_loss: 0.8133\n",
      "[Sample] d_loss: 1.16074920, g_loss: 0.87214482\n",
      "Epoch: [11] [ 365/1093] time: 9251.3930, d_loss: 1.2017, g_loss: 0.8394\n",
      "[Sample] d_loss: 1.14978218, g_loss: 0.87741899\n",
      "Epoch: [11] [ 375/1093] time: 9255.3266, d_loss: 1.2112, g_loss: 0.8344\n",
      "[Sample] d_loss: 1.16616178, g_loss: 0.85845685\n",
      "Epoch: [11] [ 385/1093] time: 9259.3027, d_loss: 1.2038, g_loss: 0.8320\n",
      "[Sample] d_loss: 1.17414689, g_loss: 0.85090148\n",
      "Epoch: [11] [ 395/1093] time: 9263.3000, d_loss: 1.2144, g_loss: 0.7736\n",
      "[Sample] d_loss: 1.16930580, g_loss: 0.85323107\n",
      "Epoch: [11] [ 405/1093] time: 9267.5931, d_loss: 1.2220, g_loss: 0.8443\n",
      "[Sample] d_loss: 1.17603040, g_loss: 0.83922368\n",
      "Epoch: [11] [ 415/1093] time: 9271.6427, d_loss: 1.2415, g_loss: 0.8054\n",
      "[Sample] d_loss: 1.16552997, g_loss: 0.85543084\n",
      "Epoch: [11] [ 425/1093] time: 9275.7739, d_loss: 1.2153, g_loss: 0.8105\n",
      "[Sample] d_loss: 1.17485213, g_loss: 0.83655167\n",
      "Epoch: [11] [ 435/1093] time: 9279.9287, d_loss: 1.2021, g_loss: 0.8106\n",
      "[Sample] d_loss: 1.16452909, g_loss: 0.85725152\n",
      "Epoch: [11] [ 445/1093] time: 9284.2008, d_loss: 1.1833, g_loss: 0.7890\n",
      "[Sample] d_loss: 1.18574739, g_loss: 0.83001131\n",
      "Epoch: [11] [ 455/1093] time: 9288.3157, d_loss: 1.1921, g_loss: 0.8116\n",
      "[Sample] d_loss: 1.19329667, g_loss: 0.82006645\n",
      "Epoch: [11] [ 465/1093] time: 9292.6746, d_loss: 1.1898, g_loss: 0.8391\n",
      "[Sample] d_loss: 1.21300936, g_loss: 0.80556941\n",
      "Epoch: [11] [ 475/1093] time: 9296.9315, d_loss: 1.2274, g_loss: 0.7976\n",
      "[Sample] d_loss: 1.20373905, g_loss: 0.81278074\n",
      "Epoch: [11] [ 485/1093] time: 9301.2556, d_loss: 1.2269, g_loss: 0.8121\n",
      "[Sample] d_loss: 1.19310951, g_loss: 0.82795811\n",
      "Epoch: [11] [ 495/1093] time: 9305.4128, d_loss: 1.1875, g_loss: 0.8016\n",
      "[Sample] d_loss: 1.19378042, g_loss: 0.82476431\n",
      "Epoch: [11] [ 505/1093] time: 9310.0301, d_loss: 1.2091, g_loss: 0.8374\n",
      "[Sample] d_loss: 1.20925236, g_loss: 0.81138724\n",
      "Epoch: [11] [ 515/1093] time: 9314.3145, d_loss: 1.2275, g_loss: 0.8469\n",
      "[Sample] d_loss: 1.17096508, g_loss: 0.85045069\n",
      "Epoch: [11] [ 525/1093] time: 9319.4424, d_loss: 1.2166, g_loss: 0.7915\n",
      "[Sample] d_loss: 1.19347537, g_loss: 0.83168328\n",
      "Epoch: [11] [ 535/1093] time: 9324.1888, d_loss: 1.1938, g_loss: 0.8007\n",
      "[Sample] d_loss: 1.18562603, g_loss: 0.84931111\n",
      "Epoch: [11] [ 545/1093] time: 9328.4108, d_loss: 1.1870, g_loss: 0.8149\n",
      "[Sample] d_loss: 1.19035220, g_loss: 0.83299971\n",
      "Epoch: [11] [ 555/1093] time: 9332.5277, d_loss: 1.1583, g_loss: 0.8422\n",
      "[Sample] d_loss: 1.17166996, g_loss: 0.84428453\n",
      "Epoch: [11] [ 565/1093] time: 9336.6929, d_loss: 1.1611, g_loss: 0.8407\n",
      "[Sample] d_loss: 1.15224290, g_loss: 0.87310398\n",
      "Epoch: [11] [ 575/1093] time: 9340.9795, d_loss: 1.1659, g_loss: 0.8263\n",
      "[Sample] d_loss: 1.15233374, g_loss: 0.86201346\n",
      "Epoch: [11] [ 585/1093] time: 9345.3683, d_loss: 1.1625, g_loss: 0.8292\n",
      "[Sample] d_loss: 1.15232182, g_loss: 0.86686450\n",
      "Epoch: [11] [ 595/1093] time: 9351.7253, d_loss: 1.1631, g_loss: 0.8471\n",
      "[Sample] d_loss: 1.16110611, g_loss: 0.85463035\n",
      "Epoch: [11] [ 605/1093] time: 9356.1226, d_loss: 1.1883, g_loss: 0.8250\n",
      "[Sample] d_loss: 1.16390383, g_loss: 0.85488224\n",
      "Epoch: [11] [ 615/1093] time: 9360.6111, d_loss: 1.1643, g_loss: 0.8165\n",
      "[Sample] d_loss: 1.18280673, g_loss: 0.82588279\n",
      "Epoch: [11] [ 625/1093] time: 9365.7806, d_loss: 1.1528, g_loss: 0.8212\n",
      "[Sample] d_loss: 1.18481112, g_loss: 0.82689750\n",
      "Epoch: [11] [ 635/1093] time: 9370.3819, d_loss: 1.1808, g_loss: 0.7993\n",
      "[Sample] d_loss: 1.17806828, g_loss: 0.82625371\n",
      "Epoch: [11] [ 645/1093] time: 9374.7899, d_loss: 1.1855, g_loss: 0.8062\n",
      "[Sample] d_loss: 1.17028117, g_loss: 0.85382819\n",
      "Epoch: [11] [ 655/1093] time: 9379.3661, d_loss: 1.2239, g_loss: 0.8107\n",
      "[Sample] d_loss: 1.17656517, g_loss: 0.84598637\n",
      "Epoch: [11] [ 665/1093] time: 9383.7416, d_loss: 1.1834, g_loss: 0.8414\n",
      "[Sample] d_loss: 1.18062735, g_loss: 0.83770424\n",
      "Epoch: [11] [ 675/1093] time: 9388.2158, d_loss: 1.1626, g_loss: 0.8305\n",
      "[Sample] d_loss: 1.18568707, g_loss: 0.83736271\n",
      "Epoch: [11] [ 685/1093] time: 9393.1173, d_loss: 1.2051, g_loss: 0.8092\n",
      "[Sample] d_loss: 1.18772435, g_loss: 0.82009161\n",
      "Epoch: [11] [ 695/1093] time: 9397.9579, d_loss: 1.2127, g_loss: 0.8380\n",
      "[Sample] d_loss: 1.17066157, g_loss: 0.84614396\n",
      "Epoch: [11] [ 705/1093] time: 9402.3944, d_loss: 1.2613, g_loss: 0.7836\n",
      "[Sample] d_loss: 1.20028853, g_loss: 0.81718373\n",
      "Epoch: [11] [ 715/1093] time: 9406.4864, d_loss: 1.2140, g_loss: 0.8026\n",
      "[Sample] d_loss: 1.19865179, g_loss: 0.82239425\n",
      "Epoch: [11] [ 725/1093] time: 9410.6949, d_loss: 1.1807, g_loss: 0.8161\n",
      "[Sample] d_loss: 1.18846989, g_loss: 0.82981914\n",
      "Epoch: [11] [ 735/1093] time: 9415.0285, d_loss: 1.2607, g_loss: 0.8361\n",
      "[Sample] d_loss: 1.19640589, g_loss: 0.82111061\n",
      "Epoch: [11] [ 745/1093] time: 9419.5326, d_loss: 1.2664, g_loss: 0.7903\n",
      "[Sample] d_loss: 1.19979930, g_loss: 0.81292295\n",
      "Epoch: [11] [ 755/1093] time: 9423.8480, d_loss: 1.1761, g_loss: 0.8275\n",
      "[Sample] d_loss: 1.19740844, g_loss: 0.82729983\n",
      "Epoch: [11] [ 765/1093] time: 9428.9269, d_loss: 1.1988, g_loss: 0.8140\n",
      "[Sample] d_loss: 1.19523382, g_loss: 0.83577174\n",
      "Epoch: [11] [ 775/1093] time: 9433.9723, d_loss: 1.2185, g_loss: 0.8233\n",
      "[Sample] d_loss: 1.18478262, g_loss: 0.83496165\n",
      "Epoch: [11] [ 785/1093] time: 9438.3220, d_loss: 1.1604, g_loss: 0.8408\n",
      "[Sample] d_loss: 1.17340040, g_loss: 0.84886074\n",
      "Epoch: [11] [ 795/1093] time: 9442.3945, d_loss: 1.1644, g_loss: 0.8051\n",
      "[Sample] d_loss: 1.18204665, g_loss: 0.83763671\n",
      "Epoch: [11] [ 805/1093] time: 9446.4004, d_loss: 1.1759, g_loss: 0.7999\n",
      "[Sample] d_loss: 1.17847681, g_loss: 0.86066473\n",
      "Epoch: [11] [ 815/1093] time: 9450.4810, d_loss: 1.1756, g_loss: 0.8115\n",
      "[Sample] d_loss: 1.18558025, g_loss: 0.83993173\n",
      "Epoch: [11] [ 825/1093] time: 9454.9043, d_loss: 1.1739, g_loss: 0.8582\n",
      "[Sample] d_loss: 1.18282628, g_loss: 0.83464766\n",
      "Epoch: [11] [ 835/1093] time: 9458.9956, d_loss: 1.2164, g_loss: 0.8236\n",
      "[Sample] d_loss: 1.17127597, g_loss: 0.86141211\n",
      "Epoch: [11] [ 845/1093] time: 9463.6642, d_loss: 1.1933, g_loss: 0.8257\n",
      "[Sample] d_loss: 1.16765380, g_loss: 0.86330104\n",
      "Epoch: [11] [ 855/1093] time: 9467.7075, d_loss: 1.1840, g_loss: 0.8162\n",
      "[Sample] d_loss: 1.16644025, g_loss: 0.86262506\n",
      "Epoch: [11] [ 865/1093] time: 9471.7798, d_loss: 1.1907, g_loss: 0.8356\n",
      "[Sample] d_loss: 1.16058290, g_loss: 0.87138265\n",
      "Epoch: [11] [ 875/1093] time: 9475.9416, d_loss: 1.1643, g_loss: 0.8733\n",
      "[Sample] d_loss: 1.18351591, g_loss: 0.84923577\n",
      "Epoch: [11] [ 885/1093] time: 9480.1709, d_loss: 1.2201, g_loss: 0.7991\n",
      "[Sample] d_loss: 1.18308628, g_loss: 0.84684300\n",
      "Epoch: [11] [ 895/1093] time: 9484.9816, d_loss: 1.1300, g_loss: 0.8540\n",
      "[Sample] d_loss: 1.19374394, g_loss: 0.83353716\n",
      "Epoch: [11] [ 905/1093] time: 9489.7445, d_loss: 1.2318, g_loss: 0.8011\n",
      "[Sample] d_loss: 1.19267178, g_loss: 0.82945675\n",
      "Epoch: [11] [ 915/1093] time: 9494.3866, d_loss: 1.1683, g_loss: 0.8321\n",
      "[Sample] d_loss: 1.19387770, g_loss: 0.82541287\n",
      "Epoch: [11] [ 925/1093] time: 9499.2781, d_loss: 1.2261, g_loss: 0.8030\n",
      "[Sample] d_loss: 1.20128632, g_loss: 0.82873261\n",
      "Epoch: [11] [ 935/1093] time: 9503.6979, d_loss: 1.1901, g_loss: 0.8138\n",
      "[Sample] d_loss: 1.19684553, g_loss: 0.83062232\n",
      "Epoch: [11] [ 945/1093] time: 9507.8033, d_loss: 1.2069, g_loss: 0.8360\n",
      "[Sample] d_loss: 1.18860328, g_loss: 0.83691084\n",
      "Epoch: [11] [ 955/1093] time: 9511.9549, d_loss: 1.2020, g_loss: 0.7987\n",
      "[Sample] d_loss: 1.19663787, g_loss: 0.82886529\n",
      "Epoch: [11] [ 965/1093] time: 9516.1361, d_loss: 1.1873, g_loss: 0.8151\n",
      "[Sample] d_loss: 1.20281076, g_loss: 0.81762940\n",
      "Epoch: [11] [ 975/1093] time: 9520.4553, d_loss: 1.1548, g_loss: 0.8021\n",
      "[Sample] d_loss: 1.21466303, g_loss: 0.80660772\n",
      "Epoch: [11] [ 985/1093] time: 9524.8977, d_loss: 1.2013, g_loss: 0.8286\n",
      "[Sample] d_loss: 1.19112325, g_loss: 0.83234441\n",
      "Epoch: [11] [ 995/1093] time: 9529.3692, d_loss: 1.1499, g_loss: 0.8562\n",
      "[Sample] d_loss: 1.19027710, g_loss: 0.83866441\n",
      "Epoch: [11] [1005/1093] time: 9533.6548, d_loss: 1.2071, g_loss: 0.8270\n",
      "[Sample] d_loss: 1.19987559, g_loss: 0.83750629\n",
      "Epoch: [11] [1015/1093] time: 9538.1582, d_loss: 1.1908, g_loss: 0.8343\n",
      "[Sample] d_loss: 1.18048859, g_loss: 0.84542644\n",
      "Epoch: [11] [1025/1093] time: 9542.3669, d_loss: 1.1763, g_loss: 0.8338\n",
      "[Sample] d_loss: 1.18845904, g_loss: 0.83784378\n",
      "Epoch: [11] [1035/1093] time: 9546.5966, d_loss: 1.1584, g_loss: 0.7990\n",
      "[Sample] d_loss: 1.17570996, g_loss: 0.85749322\n",
      "Epoch: [11] [1045/1093] time: 9550.8881, d_loss: 1.1678, g_loss: 0.8267\n",
      "[Sample] d_loss: 1.18077695, g_loss: 0.84655225\n",
      "Epoch: [11] [1055/1093] time: 9555.2270, d_loss: 1.1912, g_loss: 0.8291\n",
      "[Sample] d_loss: 1.18856907, g_loss: 0.83587241\n",
      "Epoch: [11] [1065/1093] time: 9559.8884, d_loss: 1.2143, g_loss: 0.8257\n",
      "[Sample] d_loss: 1.18862081, g_loss: 0.83657169\n",
      "Epoch: [11] [1075/1093] time: 9564.9235, d_loss: 1.1955, g_loss: 0.8077\n",
      "[Sample] d_loss: 1.21423531, g_loss: 0.79965246\n",
      "Epoch: [11] [1085/1093] time: 9569.1833, d_loss: 1.1410, g_loss: 0.8195\n",
      "[Sample] d_loss: 1.20742595, g_loss: 0.81257337\n",
      "[Sample] d_loss: 1.19353926, g_loss: 0.82854348\n",
      "Epoch: [12] [   2/1093] time: 9574.0589, d_loss: 1.1617, g_loss: 0.8335\n",
      "[Sample] d_loss: 1.20063782, g_loss: 0.81431931\n",
      "Epoch: [12] [  12/1093] time: 9578.1713, d_loss: 1.1872, g_loss: 0.8176\n",
      "[Sample] d_loss: 1.21118236, g_loss: 0.80772883\n",
      "Epoch: [12] [  22/1093] time: 9582.1342, d_loss: 1.1884, g_loss: 0.8104\n",
      "[Sample] d_loss: 1.20275259, g_loss: 0.81481290\n",
      "Epoch: [12] [  32/1093] time: 9586.1352, d_loss: 1.1923, g_loss: 0.7985\n",
      "[Sample] d_loss: 1.19191408, g_loss: 0.83296889\n",
      "Epoch: [12] [  42/1093] time: 9590.4005, d_loss: 1.2268, g_loss: 0.8235\n",
      "[Sample] d_loss: 1.19987488, g_loss: 0.82501936\n",
      "Epoch: [12] [  52/1093] time: 9594.8965, d_loss: 1.1702, g_loss: 0.8349\n",
      "[Sample] d_loss: 1.20709336, g_loss: 0.82830894\n",
      "Epoch: [12] [  62/1093] time: 9599.0762, d_loss: 1.1753, g_loss: 0.7935\n",
      "[Sample] d_loss: 1.21430206, g_loss: 0.81028581\n",
      "Epoch: [12] [  72/1093] time: 9603.4325, d_loss: 1.2496, g_loss: 0.8041\n",
      "[Sample] d_loss: 1.19630575, g_loss: 0.82707363\n",
      "Epoch: [12] [  82/1093] time: 9607.9127, d_loss: 1.2267, g_loss: 0.7821\n",
      "[Sample] d_loss: 1.17428529, g_loss: 0.85710227\n",
      "Epoch: [12] [  92/1093] time: 9612.6028, d_loss: 1.1569, g_loss: 0.8152\n",
      "[Sample] d_loss: 1.18737614, g_loss: 0.84187996\n",
      "Epoch: [12] [ 102/1093] time: 9617.6912, d_loss: 1.1524, g_loss: 0.8329\n",
      "[Sample] d_loss: 1.19144666, g_loss: 0.83361942\n",
      "Epoch: [12] [ 112/1093] time: 9622.2481, d_loss: 1.1707, g_loss: 0.8237\n",
      "[Sample] d_loss: 1.19683361, g_loss: 0.82787466\n",
      "Epoch: [12] [ 122/1093] time: 9626.7427, d_loss: 1.1832, g_loss: 0.8109\n",
      "[Sample] d_loss: 1.18077302, g_loss: 0.84899044\n",
      "Epoch: [12] [ 132/1093] time: 9631.2634, d_loss: 1.1716, g_loss: 0.8033\n",
      "[Sample] d_loss: 1.19218743, g_loss: 0.83637410\n",
      "Epoch: [12] [ 142/1093] time: 9635.3295, d_loss: 1.1895, g_loss: 0.7947\n",
      "[Sample] d_loss: 1.19277239, g_loss: 0.83800393\n",
      "Epoch: [12] [ 152/1093] time: 9639.6599, d_loss: 1.2448, g_loss: 0.8067\n",
      "[Sample] d_loss: 1.18062162, g_loss: 0.84850550\n",
      "Epoch: [12] [ 162/1093] time: 9643.5951, d_loss: 1.1905, g_loss: 0.7965\n",
      "[Sample] d_loss: 1.17347860, g_loss: 0.85190874\n",
      "Epoch: [12] [ 172/1093] time: 9647.7875, d_loss: 1.1962, g_loss: 0.8335\n",
      "[Sample] d_loss: 1.17897439, g_loss: 0.85703683\n",
      "Epoch: [12] [ 182/1093] time: 9651.9191, d_loss: 1.1916, g_loss: 0.8446\n",
      "[Sample] d_loss: 1.19834232, g_loss: 0.83573121\n",
      "Epoch: [12] [ 192/1093] time: 9656.0782, d_loss: 1.1855, g_loss: 0.8131\n",
      "[Sample] d_loss: 1.21172285, g_loss: 0.82074690\n",
      "Epoch: [12] [ 202/1093] time: 9660.3357, d_loss: 1.1670, g_loss: 0.8091\n",
      "[Sample] d_loss: 1.21114647, g_loss: 0.80995452\n",
      "Epoch: [12] [ 212/1093] time: 9664.5064, d_loss: 1.1546, g_loss: 0.8272\n",
      "[Sample] d_loss: 1.20329022, g_loss: 0.81542504\n",
      "Epoch: [12] [ 222/1093] time: 9668.5261, d_loss: 1.1433, g_loss: 0.8590\n",
      "[Sample] d_loss: 1.19055688, g_loss: 0.83308685\n",
      "Epoch: [12] [ 232/1093] time: 9672.7252, d_loss: 1.2069, g_loss: 0.8136\n",
      "[Sample] d_loss: 1.19083357, g_loss: 0.83173656\n",
      "Epoch: [12] [ 242/1093] time: 9677.2868, d_loss: 1.1581, g_loss: 0.8078\n",
      "[Sample] d_loss: 1.19249845, g_loss: 0.83149803\n",
      "Epoch: [12] [ 252/1093] time: 9681.5596, d_loss: 1.2068, g_loss: 0.8356\n",
      "[Sample] d_loss: 1.18259573, g_loss: 0.83730680\n",
      "Epoch: [12] [ 262/1093] time: 9686.1299, d_loss: 1.2614, g_loss: 0.8067\n",
      "[Sample] d_loss: 1.18918204, g_loss: 0.83533287\n",
      "Epoch: [12] [ 272/1093] time: 9690.3455, d_loss: 1.1606, g_loss: 0.8609\n",
      "[Sample] d_loss: 1.17481971, g_loss: 0.85851109\n",
      "Epoch: [12] [ 282/1093] time: 9694.3566, d_loss: 1.1612, g_loss: 0.8500\n",
      "[Sample] d_loss: 1.19005489, g_loss: 0.84087104\n",
      "Epoch: [12] [ 292/1093] time: 9698.5461, d_loss: 1.1571, g_loss: 0.8567\n",
      "[Sample] d_loss: 1.18171287, g_loss: 0.83940279\n",
      "Epoch: [12] [ 302/1093] time: 9702.7046, d_loss: 1.1421, g_loss: 0.8619\n",
      "[Sample] d_loss: 1.18102527, g_loss: 0.84503472\n",
      "Epoch: [12] [ 312/1093] time: 9707.0371, d_loss: 1.1753, g_loss: 0.8161\n",
      "[Sample] d_loss: 1.18706846, g_loss: 0.83370042\n",
      "Epoch: [12] [ 322/1093] time: 9711.3443, d_loss: 1.1897, g_loss: 0.8171\n",
      "[Sample] d_loss: 1.19080925, g_loss: 0.82840133\n",
      "Epoch: [12] [ 332/1093] time: 9715.7252, d_loss: 1.2385, g_loss: 0.8325\n",
      "[Sample] d_loss: 1.20282125, g_loss: 0.80457175\n",
      "Epoch: [12] [ 342/1093] time: 9719.9024, d_loss: 1.2177, g_loss: 0.7980\n",
      "[Sample] d_loss: 1.19131804, g_loss: 0.82501006\n",
      "Epoch: [12] [ 352/1093] time: 9723.9731, d_loss: 1.1549, g_loss: 0.8332\n",
      "[Sample] d_loss: 1.20010424, g_loss: 0.82138556\n",
      "Epoch: [12] [ 362/1093] time: 9728.1320, d_loss: 1.2591, g_loss: 0.8065\n",
      "[Sample] d_loss: 1.18235016, g_loss: 0.83469117\n",
      "Epoch: [12] [ 372/1093] time: 9732.2369, d_loss: 1.2218, g_loss: 0.8053\n",
      "[Sample] d_loss: 1.18924522, g_loss: 0.84128463\n",
      "Epoch: [12] [ 382/1093] time: 9736.7104, d_loss: 1.1973, g_loss: 0.8011\n",
      "[Sample] d_loss: 1.19607639, g_loss: 0.82710040\n",
      "Epoch: [12] [ 392/1093] time: 9740.8969, d_loss: 1.2045, g_loss: 0.8066\n",
      "[Sample] d_loss: 1.19075704, g_loss: 0.84059417\n",
      "Epoch: [12] [ 402/1093] time: 9745.0564, d_loss: 1.2246, g_loss: 0.8160\n",
      "[Sample] d_loss: 1.18907297, g_loss: 0.83025038\n",
      "Epoch: [12] [ 412/1093] time: 9749.4226, d_loss: 1.2611, g_loss: 0.8265\n",
      "[Sample] d_loss: 1.20887017, g_loss: 0.80678445\n",
      "Epoch: [12] [ 422/1093] time: 9753.8063, d_loss: 1.2126, g_loss: 0.8337\n",
      "[Sample] d_loss: 1.19562900, g_loss: 0.81752849\n",
      "Epoch: [12] [ 432/1093] time: 9758.1305, d_loss: 1.1516, g_loss: 0.8489\n",
      "[Sample] d_loss: 1.20295811, g_loss: 0.81452537\n",
      "Epoch: [12] [ 442/1093] time: 9762.3011, d_loss: 1.1615, g_loss: 0.8364\n",
      "[Sample] d_loss: 1.19233346, g_loss: 0.82578909\n",
      "Epoch: [12] [ 452/1093] time: 9766.6124, d_loss: 1.2249, g_loss: 0.7937\n",
      "[Sample] d_loss: 1.20680892, g_loss: 0.79934722\n",
      "Epoch: [12] [ 462/1093] time: 9770.9371, d_loss: 1.1367, g_loss: 0.8356\n",
      "[Sample] d_loss: 1.18090320, g_loss: 0.82916701\n",
      "Epoch: [12] [ 472/1093] time: 9774.9722, d_loss: 1.2742, g_loss: 0.8134\n",
      "[Sample] d_loss: 1.18344760, g_loss: 0.83570457\n",
      "Epoch: [12] [ 482/1093] time: 9779.1963, d_loss: 1.1568, g_loss: 0.8250\n",
      "[Sample] d_loss: 1.17914963, g_loss: 0.83975458\n",
      "Epoch: [12] [ 492/1093] time: 9783.4383, d_loss: 1.1780, g_loss: 0.8019\n",
      "[Sample] d_loss: 1.17717099, g_loss: 0.84546572\n",
      "Epoch: [12] [ 502/1093] time: 9787.4251, d_loss: 1.2081, g_loss: 0.7975\n",
      "[Sample] d_loss: 1.19170284, g_loss: 0.82333422\n",
      "Epoch: [12] [ 512/1093] time: 9791.7640, d_loss: 1.1599, g_loss: 0.8275\n",
      "[Sample] d_loss: 1.17119491, g_loss: 0.86137360\n",
      "Epoch: [12] [ 522/1093] time: 9797.3732, d_loss: 1.1340, g_loss: 0.8459\n",
      "[Sample] d_loss: 1.17679811, g_loss: 0.85293829\n",
      "Epoch: [12] [ 532/1093] time: 9804.4260, d_loss: 1.1516, g_loss: 0.8622\n",
      "[Sample] d_loss: 1.17337465, g_loss: 0.84570497\n",
      "Epoch: [12] [ 542/1093] time: 9809.6527, d_loss: 1.1695, g_loss: 0.8552\n",
      "[Sample] d_loss: 1.17604423, g_loss: 0.84798759\n",
      "Epoch: [12] [ 552/1093] time: 9814.7610, d_loss: 1.1239, g_loss: 0.8352\n",
      "[Sample] d_loss: 1.17759609, g_loss: 0.84383911\n",
      "Epoch: [12] [ 562/1093] time: 9820.1528, d_loss: 1.1976, g_loss: 0.8250\n",
      "[Sample] d_loss: 1.16949940, g_loss: 0.84582907\n",
      "Epoch: [12] [ 572/1093] time: 9824.6229, d_loss: 1.1359, g_loss: 0.8464\n",
      "[Sample] d_loss: 1.16856503, g_loss: 0.84334075\n",
      "Epoch: [12] [ 582/1093] time: 9829.8943, d_loss: 1.1736, g_loss: 0.8254\n",
      "[Sample] d_loss: 1.15558767, g_loss: 0.87328947\n",
      "Epoch: [12] [ 592/1093] time: 9834.6867, d_loss: 1.1935, g_loss: 0.8191\n",
      "[Sample] d_loss: 1.16154611, g_loss: 0.85899228\n",
      "Epoch: [12] [ 602/1093] time: 9839.4396, d_loss: 1.1549, g_loss: 0.8302\n",
      "[Sample] d_loss: 1.18207848, g_loss: 0.83741319\n",
      "Epoch: [12] [ 612/1093] time: 9844.4810, d_loss: 1.1711, g_loss: 0.8431\n",
      "[Sample] d_loss: 1.17514670, g_loss: 0.84162229\n",
      "Epoch: [12] [ 622/1093] time: 9849.6784, d_loss: 1.1398, g_loss: 0.8354\n",
      "[Sample] d_loss: 1.18323588, g_loss: 0.82091343\n",
      "Epoch: [12] [ 632/1093] time: 9855.0470, d_loss: 1.1138, g_loss: 0.8581\n",
      "[Sample] d_loss: 1.17306089, g_loss: 0.83309007\n",
      "Epoch: [12] [ 642/1093] time: 9860.1420, d_loss: 1.2027, g_loss: 0.8297\n",
      "[Sample] d_loss: 1.15472817, g_loss: 0.86290628\n",
      "Epoch: [12] [ 652/1093] time: 9865.1188, d_loss: 1.2217, g_loss: 0.8312\n",
      "[Sample] d_loss: 1.17197871, g_loss: 0.83214295\n",
      "Epoch: [12] [ 662/1093] time: 9869.7190, d_loss: 1.1880, g_loss: 0.8436\n",
      "[Sample] d_loss: 1.14421415, g_loss: 0.87271130\n",
      "Epoch: [12] [ 672/1093] time: 9874.7423, d_loss: 1.1472, g_loss: 0.8456\n",
      "[Sample] d_loss: 1.17435324, g_loss: 0.83961338\n",
      "Epoch: [12] [ 682/1093] time: 9879.9058, d_loss: 1.1791, g_loss: 0.8501\n",
      "[Sample] d_loss: 1.16248202, g_loss: 0.85778183\n",
      "Epoch: [12] [ 692/1093] time: 9884.8820, d_loss: 1.1642, g_loss: 0.8493\n",
      "[Sample] d_loss: 1.16921771, g_loss: 0.84827965\n",
      "Epoch: [12] [ 702/1093] time: 9889.2964, d_loss: 1.1825, g_loss: 0.8565\n",
      "[Sample] d_loss: 1.16772962, g_loss: 0.85602009\n",
      "Epoch: [12] [ 712/1093] time: 9893.6810, d_loss: 1.1956, g_loss: 0.8469\n",
      "[Sample] d_loss: 1.17092395, g_loss: 0.85137010\n",
      "Epoch: [12] [ 722/1093] time: 9898.4905, d_loss: 1.1836, g_loss: 0.8228\n",
      "[Sample] d_loss: 1.18243670, g_loss: 0.84102058\n",
      "Epoch: [12] [ 732/1093] time: 9903.0785, d_loss: 1.2137, g_loss: 0.8444\n",
      "[Sample] d_loss: 1.17024660, g_loss: 0.86192805\n",
      "Epoch: [12] [ 742/1093] time: 9907.6421, d_loss: 1.1594, g_loss: 0.8190\n",
      "[Sample] d_loss: 1.17898774, g_loss: 0.83381319\n",
      "Epoch: [12] [ 752/1093] time: 9912.3187, d_loss: 1.1461, g_loss: 0.8918\n",
      "[Sample] d_loss: 1.18125010, g_loss: 0.82185817\n",
      "Epoch: [12] [ 762/1093] time: 9916.4098, d_loss: 1.2171, g_loss: 0.8083\n",
      "[Sample] d_loss: 1.17580867, g_loss: 0.83354354\n",
      "Epoch: [12] [ 772/1093] time: 9920.8243, d_loss: 1.1711, g_loss: 0.8601\n",
      "[Sample] d_loss: 1.17857659, g_loss: 0.83087075\n",
      "Epoch: [12] [ 782/1093] time: 9924.9072, d_loss: 1.1478, g_loss: 0.8422\n",
      "[Sample] d_loss: 1.19441068, g_loss: 0.82423180\n",
      "Epoch: [12] [ 792/1093] time: 9929.7898, d_loss: 1.1493, g_loss: 0.8437\n",
      "[Sample] d_loss: 1.15104127, g_loss: 0.87075853\n",
      "Epoch: [12] [ 802/1093] time: 9934.5188, d_loss: 1.1500, g_loss: 0.8528\n",
      "[Sample] d_loss: 1.17236352, g_loss: 0.84262156\n",
      "Epoch: [12] [ 812/1093] time: 9938.5475, d_loss: 1.1717, g_loss: 0.8183\n",
      "[Sample] d_loss: 1.15244436, g_loss: 0.88013577\n",
      "Epoch: [12] [ 822/1093] time: 9942.5797, d_loss: 1.1801, g_loss: 0.8198\n",
      "[Sample] d_loss: 1.17427588, g_loss: 0.84334373\n",
      "Epoch: [12] [ 832/1093] time: 9946.6179, d_loss: 1.1834, g_loss: 0.7981\n",
      "[Sample] d_loss: 1.16650939, g_loss: 0.84881604\n",
      "Epoch: [12] [ 842/1093] time: 9950.6485, d_loss: 1.1407, g_loss: 0.8301\n",
      "[Sample] d_loss: 1.15543079, g_loss: 0.86668265\n",
      "Epoch: [12] [ 852/1093] time: 9954.6328, d_loss: 1.1534, g_loss: 0.8438\n",
      "[Sample] d_loss: 1.15551114, g_loss: 0.86476362\n",
      "Epoch: [12] [ 862/1093] time: 9958.6287, d_loss: 1.2057, g_loss: 0.8042\n",
      "[Sample] d_loss: 1.16138637, g_loss: 0.86518556\n",
      "Epoch: [12] [ 872/1093] time: 9962.8358, d_loss: 1.2023, g_loss: 0.8186\n",
      "[Sample] d_loss: 1.14913452, g_loss: 0.88414842\n",
      "Epoch: [12] [ 882/1093] time: 9966.8607, d_loss: 1.1494, g_loss: 0.8376\n",
      "[Sample] d_loss: 1.17058420, g_loss: 0.86101615\n",
      "Epoch: [12] [ 892/1093] time: 9970.8103, d_loss: 1.1908, g_loss: 0.8234\n",
      "[Sample] d_loss: 1.15353966, g_loss: 0.87111831\n",
      "Epoch: [12] [ 902/1093] time: 9975.1122, d_loss: 1.1534, g_loss: 0.8512\n",
      "[Sample] d_loss: 1.18098927, g_loss: 0.83994257\n",
      "Epoch: [12] [ 912/1093] time: 9979.2085, d_loss: 1.2058, g_loss: 0.8413\n",
      "[Sample] d_loss: 1.16088724, g_loss: 0.87234360\n",
      "Epoch: [12] [ 922/1093] time: 9983.2791, d_loss: 1.1821, g_loss: 0.8289\n",
      "[Sample] d_loss: 1.16674006, g_loss: 0.86374748\n",
      "Epoch: [12] [ 932/1093] time: 9987.3445, d_loss: 1.1181, g_loss: 0.8375\n",
      "[Sample] d_loss: 1.18344367, g_loss: 0.84926844\n",
      "Epoch: [12] [ 942/1093] time: 9991.3465, d_loss: 1.1703, g_loss: 0.8145\n",
      "[Sample] d_loss: 1.16789937, g_loss: 0.86717057\n",
      "Epoch: [12] [ 952/1093] time: 9995.3822, d_loss: 1.1712, g_loss: 0.8316\n",
      "[Sample] d_loss: 1.16977644, g_loss: 0.84911662\n",
      "Epoch: [12] [ 962/1093] time: 9999.4683, d_loss: 1.1587, g_loss: 0.8412\n",
      "[Sample] d_loss: 1.16281998, g_loss: 0.85526502\n",
      "Epoch: [12] [ 972/1093] time: 10003.5932, d_loss: 1.1744, g_loss: 0.8524\n",
      "[Sample] d_loss: 1.16009295, g_loss: 0.85020125\n",
      "Epoch: [12] [ 982/1093] time: 10007.6615, d_loss: 1.1800, g_loss: 0.8335\n",
      "[Sample] d_loss: 1.16640091, g_loss: 0.84555531\n",
      "Epoch: [12] [ 992/1093] time: 10011.7163, d_loss: 1.1525, g_loss: 0.8438\n",
      "[Sample] d_loss: 1.16482437, g_loss: 0.84176576\n",
      "Epoch: [12] [1002/1093] time: 10015.6946, d_loss: 1.1775, g_loss: 0.8244\n",
      "[Sample] d_loss: 1.15708494, g_loss: 0.85649747\n",
      "Epoch: [12] [1012/1093] time: 10019.7807, d_loss: 1.1802, g_loss: 0.8326\n",
      "[Sample] d_loss: 1.15122736, g_loss: 0.86351240\n",
      "Epoch: [12] [1022/1093] time: 10023.8258, d_loss: 1.2237, g_loss: 0.8008\n",
      "[Sample] d_loss: 1.15348554, g_loss: 0.85807717\n",
      "Epoch: [12] [1032/1093] time: 10028.0332, d_loss: 1.1329, g_loss: 0.8539\n",
      "[Sample] d_loss: 1.14715505, g_loss: 0.86172307\n",
      "Epoch: [12] [1042/1093] time: 10032.3841, d_loss: 1.1944, g_loss: 0.8182\n",
      "[Sample] d_loss: 1.15729308, g_loss: 0.86182201\n",
      "Epoch: [12] [1052/1093] time: 10036.8683, d_loss: 1.1304, g_loss: 0.8566\n",
      "[Sample] d_loss: 1.13804305, g_loss: 0.87424386\n",
      "Epoch: [12] [1062/1093] time: 10041.2903, d_loss: 1.1380, g_loss: 0.8666\n",
      "[Sample] d_loss: 1.15033245, g_loss: 0.86136520\n",
      "Epoch: [12] [1072/1093] time: 10045.4040, d_loss: 1.1270, g_loss: 0.8303\n",
      "[Sample] d_loss: 1.16496587, g_loss: 0.84265614\n",
      "Epoch: [12] [1082/1093] time: 10049.7614, d_loss: 1.1460, g_loss: 0.8464\n",
      "[Sample] d_loss: 1.15860343, g_loss: 0.84626323\n",
      "Epoch: [12] [1092/1093] time: 10053.8856, d_loss: 1.1078, g_loss: 0.8402\n",
      "[Sample] d_loss: 1.15428770, g_loss: 0.85952330\n",
      "Epoch: [13] [   9/1093] time: 10058.1464, d_loss: 1.1460, g_loss: 0.8736\n",
      "[Sample] d_loss: 1.14996266, g_loss: 0.86378598\n",
      "Epoch: [13] [  19/1093] time: 10062.4774, d_loss: 1.1836, g_loss: 0.8107\n",
      "[Sample] d_loss: 1.16729820, g_loss: 0.83562601\n",
      "Epoch: [13] [  29/1093] time: 10066.4362, d_loss: 1.2205, g_loss: 0.8063\n",
      "[Sample] d_loss: 1.15921974, g_loss: 0.85156524\n",
      "Epoch: [13] [  39/1093] time: 10070.4348, d_loss: 1.1985, g_loss: 0.8309\n",
      "[Sample] d_loss: 1.16800809, g_loss: 0.84418917\n",
      "Epoch: [13] [  49/1093] time: 10074.5029, d_loss: 1.1719, g_loss: 0.8469\n",
      "[Sample] d_loss: 1.16983604, g_loss: 0.85071504\n",
      "Epoch: [13] [  59/1093] time: 10078.5933, d_loss: 1.1867, g_loss: 0.8020\n",
      "[Sample] d_loss: 1.18101907, g_loss: 0.84629947\n",
      "Epoch: [13] [  69/1093] time: 10083.2306, d_loss: 1.1669, g_loss: 0.8702\n",
      "[Sample] d_loss: 1.16030908, g_loss: 0.86115450\n",
      "Epoch: [13] [  79/1093] time: 10088.2608, d_loss: 1.1462, g_loss: 0.8616\n",
      "[Sample] d_loss: 1.17836201, g_loss: 0.84772599\n",
      "Epoch: [13] [  89/1093] time: 10092.6306, d_loss: 1.1762, g_loss: 0.8639\n",
      "[Sample] d_loss: 1.15869749, g_loss: 0.86854839\n",
      "Epoch: [13] [  99/1093] time: 10097.8967, d_loss: 1.1362, g_loss: 0.8552\n",
      "[Sample] d_loss: 1.17431498, g_loss: 0.85026932\n",
      "Epoch: [13] [ 109/1093] time: 10102.4041, d_loss: 1.2002, g_loss: 0.8434\n",
      "[Sample] d_loss: 1.16436672, g_loss: 0.85428715\n",
      "Epoch: [13] [ 119/1093] time: 10106.7373, d_loss: 1.1969, g_loss: 0.8413\n",
      "[Sample] d_loss: 1.14050162, g_loss: 0.88430917\n",
      "Epoch: [13] [ 129/1093] time: 10112.1347, d_loss: 1.1687, g_loss: 0.8303\n",
      "[Sample] d_loss: 1.15700173, g_loss: 0.86256534\n",
      "Epoch: [13] [ 139/1093] time: 10116.4400, d_loss: 1.2021, g_loss: 0.8555\n",
      "[Sample] d_loss: 1.18004775, g_loss: 0.83633316\n",
      "Epoch: [13] [ 149/1093] time: 10120.9621, d_loss: 1.1471, g_loss: 0.8339\n",
      "[Sample] d_loss: 1.16159201, g_loss: 0.85319263\n",
      "Epoch: [13] [ 159/1093] time: 10125.5354, d_loss: 1.1349, g_loss: 0.8452\n",
      "[Sample] d_loss: 1.16289687, g_loss: 0.86156690\n",
      "Epoch: [13] [ 169/1093] time: 10130.2676, d_loss: 1.1229, g_loss: 0.8830\n",
      "[Sample] d_loss: 1.15454149, g_loss: 0.85992813\n",
      "Epoch: [13] [ 179/1093] time: 10137.5164, d_loss: 1.1366, g_loss: 0.8687\n",
      "[Sample] d_loss: 1.14477277, g_loss: 0.86966193\n",
      "Epoch: [13] [ 189/1093] time: 10142.2239, d_loss: 1.2166, g_loss: 0.8630\n",
      "[Sample] d_loss: 1.16515374, g_loss: 0.84337580\n",
      "Epoch: [13] [ 199/1093] time: 10147.6136, d_loss: 1.1375, g_loss: 0.8612\n",
      "[Sample] d_loss: 1.17806768, g_loss: 0.83385414\n",
      "Epoch: [13] [ 209/1093] time: 10152.3641, d_loss: 1.1834, g_loss: 0.8443\n",
      "[Sample] d_loss: 1.16963243, g_loss: 0.83842826\n",
      "Epoch: [13] [ 219/1093] time: 10157.7059, d_loss: 1.0766, g_loss: 0.9029\n",
      "[Sample] d_loss: 1.16347587, g_loss: 0.84762907\n",
      "Epoch: [13] [ 229/1093] time: 10162.2536, d_loss: 1.1535, g_loss: 0.8291\n",
      "[Sample] d_loss: 1.16381550, g_loss: 0.84734738\n",
      "Epoch: [13] [ 239/1093] time: 10166.9631, d_loss: 1.1505, g_loss: 0.8272\n",
      "[Sample] d_loss: 1.16857064, g_loss: 0.83822507\n",
      "Epoch: [13] [ 249/1093] time: 10171.6668, d_loss: 1.1153, g_loss: 0.8470\n",
      "[Sample] d_loss: 1.16047525, g_loss: 0.85054183\n",
      "Epoch: [13] [ 259/1093] time: 10176.3739, d_loss: 1.1635, g_loss: 0.8231\n",
      "[Sample] d_loss: 1.15290046, g_loss: 0.85871434\n",
      "Epoch: [13] [ 269/1093] time: 10180.9609, d_loss: 1.1644, g_loss: 0.8553\n",
      "[Sample] d_loss: 1.14781332, g_loss: 0.87094861\n",
      "Epoch: [13] [ 279/1093] time: 10185.8117, d_loss: 1.0980, g_loss: 0.8635\n",
      "[Sample] d_loss: 1.13154042, g_loss: 0.87994099\n",
      "Epoch: [13] [ 289/1093] time: 10191.3790, d_loss: 1.1341, g_loss: 0.8563\n",
      "[Sample] d_loss: 1.15714407, g_loss: 0.86844903\n",
      "Epoch: [13] [ 299/1093] time: 10196.3085, d_loss: 1.1448, g_loss: 0.8617\n",
      "[Sample] d_loss: 1.13818192, g_loss: 0.87882668\n",
      "Epoch: [13] [ 309/1093] time: 10201.6567, d_loss: 1.1329, g_loss: 0.8441\n",
      "[Sample] d_loss: 1.13608932, g_loss: 0.88493222\n",
      "Epoch: [13] [ 319/1093] time: 10206.3299, d_loss: 1.0899, g_loss: 0.8849\n",
      "[Sample] d_loss: 1.14300203, g_loss: 0.86895323\n",
      "Epoch: [13] [ 329/1093] time: 10210.6502, d_loss: 1.1567, g_loss: 0.8320\n",
      "[Sample] d_loss: 1.14032900, g_loss: 0.87680113\n",
      "Epoch: [13] [ 339/1093] time: 10215.2043, d_loss: 1.1594, g_loss: 0.8199\n",
      "[Sample] d_loss: 1.13030124, g_loss: 0.88528013\n",
      "Epoch: [13] [ 349/1093] time: 10219.2244, d_loss: 1.1392, g_loss: 0.8392\n",
      "[Sample] d_loss: 1.15772653, g_loss: 0.84507591\n",
      "Epoch: [13] [ 359/1093] time: 10223.7160, d_loss: 1.1752, g_loss: 0.8314\n",
      "[Sample] d_loss: 1.15548897, g_loss: 0.85246307\n",
      "Epoch: [13] [ 369/1093] time: 10228.0704, d_loss: 1.2032, g_loss: 0.8127\n",
      "[Sample] d_loss: 1.14530110, g_loss: 0.87497461\n",
      "Epoch: [13] [ 379/1093] time: 10232.1270, d_loss: 1.1663, g_loss: 0.8498\n",
      "[Sample] d_loss: 1.15377235, g_loss: 0.85245097\n",
      "Epoch: [13] [ 389/1093] time: 10236.4631, d_loss: 1.1380, g_loss: 0.8419\n",
      "[Sample] d_loss: 1.13553119, g_loss: 0.88248980\n",
      "Epoch: [13] [ 399/1093] time: 10240.8001, d_loss: 1.1331, g_loss: 0.8408\n",
      "[Sample] d_loss: 1.16046035, g_loss: 0.86616546\n",
      "Epoch: [13] [ 409/1093] time: 10245.1985, d_loss: 1.2173, g_loss: 0.8870\n",
      "[Sample] d_loss: 1.14168572, g_loss: 0.87554777\n",
      "Epoch: [13] [ 419/1093] time: 10249.7010, d_loss: 1.1442, g_loss: 0.8522\n",
      "[Sample] d_loss: 1.17127919, g_loss: 0.83891869\n",
      "Epoch: [13] [ 429/1093] time: 10253.9282, d_loss: 1.1943, g_loss: 0.8237\n",
      "[Sample] d_loss: 1.15412760, g_loss: 0.85610455\n",
      "Epoch: [13] [ 439/1093] time: 10258.4824, d_loss: 1.1711, g_loss: 0.8054\n",
      "[Sample] d_loss: 1.16230845, g_loss: 0.84752512\n",
      "Epoch: [13] [ 449/1093] time: 10263.2067, d_loss: 1.1834, g_loss: 0.8407\n",
      "[Sample] d_loss: 1.16197729, g_loss: 0.84960258\n",
      "Epoch: [13] [ 459/1093] time: 10267.8865, d_loss: 1.1911, g_loss: 0.8601\n",
      "[Sample] d_loss: 1.14982939, g_loss: 0.86247146\n",
      "Epoch: [13] [ 469/1093] time: 10272.3425, d_loss: 1.1799, g_loss: 0.8500\n",
      "[Sample] d_loss: 1.15494776, g_loss: 0.86469108\n",
      "Epoch: [13] [ 479/1093] time: 10276.6432, d_loss: 1.1699, g_loss: 0.8837\n",
      "[Sample] d_loss: 1.14142203, g_loss: 0.88888186\n",
      "Epoch: [13] [ 489/1093] time: 10280.8644, d_loss: 1.1932, g_loss: 0.8519\n",
      "[Sample] d_loss: 1.14841521, g_loss: 0.86572874\n",
      "Epoch: [13] [ 499/1093] time: 10285.0589, d_loss: 1.1640, g_loss: 0.8457\n",
      "[Sample] d_loss: 1.14128709, g_loss: 0.88165200\n",
      "Epoch: [13] [ 509/1093] time: 10289.0951, d_loss: 1.1329, g_loss: 0.8607\n",
      "[Sample] d_loss: 1.14131141, g_loss: 0.87235522\n",
      "Epoch: [13] [ 519/1093] time: 10293.1516, d_loss: 1.1375, g_loss: 0.8528\n",
      "[Sample] d_loss: 1.16049802, g_loss: 0.85035241\n",
      "Epoch: [13] [ 529/1093] time: 10297.2052, d_loss: 1.1883, g_loss: 0.8383\n",
      "[Sample] d_loss: 1.12758505, g_loss: 0.89116055\n",
      "Epoch: [13] [ 539/1093] time: 10301.2788, d_loss: 1.1740, g_loss: 0.8552\n",
      "[Sample] d_loss: 1.14947879, g_loss: 0.85946333\n",
      "Epoch: [13] [ 549/1093] time: 10305.5453, d_loss: 1.1807, g_loss: 0.8309\n",
      "[Sample] d_loss: 1.13057804, g_loss: 0.87710714\n",
      "Epoch: [13] [ 559/1093] time: 10309.8595, d_loss: 1.1855, g_loss: 0.8588\n",
      "[Sample] d_loss: 1.13516307, g_loss: 0.88618571\n",
      "Epoch: [13] [ 569/1093] time: 10314.0927, d_loss: 1.0920, g_loss: 0.8696\n",
      "[Sample] d_loss: 1.11966038, g_loss: 0.89416623\n",
      "Epoch: [13] [ 579/1093] time: 10318.1106, d_loss: 1.1547, g_loss: 0.8327\n",
      "[Sample] d_loss: 1.13350558, g_loss: 0.87403506\n",
      "Epoch: [13] [ 589/1093] time: 10322.4524, d_loss: 1.1540, g_loss: 0.8791\n",
      "[Sample] d_loss: 1.15036142, g_loss: 0.85108632\n",
      "Epoch: [13] [ 599/1093] time: 10326.6404, d_loss: 1.0815, g_loss: 0.8851\n",
      "[Sample] d_loss: 1.11671519, g_loss: 0.90845668\n",
      "Epoch: [13] [ 609/1093] time: 10330.7879, d_loss: 1.1013, g_loss: 0.8449\n",
      "[Sample] d_loss: 1.12764180, g_loss: 0.90116024\n",
      "Epoch: [13] [ 619/1093] time: 10334.9149, d_loss: 1.1828, g_loss: 0.8229\n",
      "[Sample] d_loss: 1.16355228, g_loss: 0.83569282\n",
      "Epoch: [13] [ 629/1093] time: 10339.2508, d_loss: 1.1546, g_loss: 0.8386\n",
      "[Sample] d_loss: 1.14881802, g_loss: 0.86149240\n",
      "Epoch: [13] [ 639/1093] time: 10343.9632, d_loss: 1.1451, g_loss: 0.8462\n",
      "[Sample] d_loss: 1.15398574, g_loss: 0.84572464\n",
      "Epoch: [13] [ 649/1093] time: 10348.6157, d_loss: 1.1447, g_loss: 0.8428\n",
      "[Sample] d_loss: 1.15721655, g_loss: 0.84092486\n",
      "Epoch: [13] [ 659/1093] time: 10352.7777, d_loss: 1.1698, g_loss: 0.8194\n",
      "[Sample] d_loss: 1.13272929, g_loss: 0.87147498\n",
      "Epoch: [13] [ 669/1093] time: 10357.1458, d_loss: 1.1127, g_loss: 0.8606\n",
      "[Sample] d_loss: 1.14079559, g_loss: 0.86392701\n",
      "Epoch: [13] [ 679/1093] time: 10361.3270, d_loss: 1.1585, g_loss: 0.8393\n",
      "[Sample] d_loss: 1.14662540, g_loss: 0.85399508\n",
      "Epoch: [13] [ 689/1093] time: 10365.6923, d_loss: 1.1498, g_loss: 0.8667\n",
      "[Sample] d_loss: 1.13730288, g_loss: 0.87668478\n",
      "Epoch: [13] [ 699/1093] time: 10369.8547, d_loss: 1.1777, g_loss: 0.8749\n",
      "[Sample] d_loss: 1.12152398, g_loss: 0.89716983\n",
      "Epoch: [13] [ 709/1093] time: 10374.1746, d_loss: 1.1148, g_loss: 0.8426\n",
      "[Sample] d_loss: 1.13875127, g_loss: 0.87741148\n",
      "Epoch: [13] [ 719/1093] time: 10378.3379, d_loss: 1.1567, g_loss: 0.8498\n",
      "[Sample] d_loss: 1.12854719, g_loss: 0.88053417\n",
      "Epoch: [13] [ 729/1093] time: 10382.4562, d_loss: 1.2013, g_loss: 0.8050\n",
      "[Sample] d_loss: 1.13576651, g_loss: 0.87226307\n",
      "Epoch: [13] [ 739/1093] time: 10386.6512, d_loss: 1.2075, g_loss: 0.8304\n",
      "[Sample] d_loss: 1.11947572, g_loss: 0.89711195\n",
      "Epoch: [13] [ 749/1093] time: 10391.1245, d_loss: 1.1161, g_loss: 0.8592\n",
      "[Sample] d_loss: 1.13087249, g_loss: 0.88103241\n",
      "Epoch: [13] [ 759/1093] time: 10395.5271, d_loss: 1.1395, g_loss: 0.8669\n",
      "[Sample] d_loss: 1.13218665, g_loss: 0.88922352\n",
      "Epoch: [13] [ 769/1093] time: 10400.0471, d_loss: 1.2188, g_loss: 0.8193\n",
      "[Sample] d_loss: 1.14889205, g_loss: 0.88019943\n",
      "Epoch: [13] [ 779/1093] time: 10404.7057, d_loss: 1.1501, g_loss: 0.8646\n",
      "[Sample] d_loss: 1.12674475, g_loss: 0.88391101\n",
      "Epoch: [13] [ 789/1093] time: 10408.7244, d_loss: 1.1655, g_loss: 0.8221\n",
      "[Sample] d_loss: 1.13158035, g_loss: 0.88450444\n",
      "Epoch: [13] [ 799/1093] time: 10412.6865, d_loss: 1.1215, g_loss: 0.9032\n",
      "[Sample] d_loss: 1.13295209, g_loss: 0.88237756\n",
      "Epoch: [13] [ 809/1093] time: 10416.7078, d_loss: 1.1367, g_loss: 0.8681\n",
      "[Sample] d_loss: 1.13001740, g_loss: 0.88093561\n",
      "Epoch: [13] [ 819/1093] time: 10420.7263, d_loss: 1.1030, g_loss: 0.8576\n",
      "[Sample] d_loss: 1.12410104, g_loss: 0.89763898\n",
      "Epoch: [13] [ 829/1093] time: 10424.7187, d_loss: 1.1525, g_loss: 0.8696\n",
      "[Sample] d_loss: 1.12401152, g_loss: 0.89910352\n",
      "Epoch: [13] [ 839/1093] time: 10428.6972, d_loss: 1.1466, g_loss: 0.8494\n",
      "[Sample] d_loss: 1.13463140, g_loss: 0.89164352\n",
      "Epoch: [13] [ 849/1093] time: 10432.6982, d_loss: 1.1403, g_loss: 0.8393\n",
      "[Sample] d_loss: 1.13820624, g_loss: 0.87735182\n",
      "Epoch: [13] [ 859/1093] time: 10436.9336, d_loss: 1.1550, g_loss: 0.8376\n",
      "[Sample] d_loss: 1.13813162, g_loss: 0.89068997\n",
      "Epoch: [13] [ 869/1093] time: 10441.4810, d_loss: 1.1601, g_loss: 0.8400\n",
      "[Sample] d_loss: 1.14512193, g_loss: 0.87094253\n",
      "Epoch: [13] [ 879/1093] time: 10445.6789, d_loss: 1.1618, g_loss: 0.8601\n",
      "[Sample] d_loss: 1.13385367, g_loss: 0.88565278\n",
      "Epoch: [13] [ 889/1093] time: 10449.8316, d_loss: 1.2130, g_loss: 0.8381\n",
      "[Sample] d_loss: 1.14173150, g_loss: 0.86695063\n",
      "Epoch: [13] [ 899/1093] time: 10455.0128, d_loss: 1.1437, g_loss: 0.8806\n",
      "[Sample] d_loss: 1.12026334, g_loss: 0.90485388\n",
      "Epoch: [13] [ 909/1093] time: 10460.1898, d_loss: 1.1314, g_loss: 0.8721\n",
      "[Sample] d_loss: 1.13284647, g_loss: 0.88696122\n",
      "Epoch: [13] [ 919/1093] time: 10464.9172, d_loss: 1.1757, g_loss: 0.8494\n",
      "[Sample] d_loss: 1.14148188, g_loss: 0.87313026\n",
      "Epoch: [13] [ 929/1093] time: 10469.4919, d_loss: 1.1202, g_loss: 0.8459\n",
      "[Sample] d_loss: 1.13360929, g_loss: 0.88112998\n",
      "Epoch: [13] [ 939/1093] time: 10474.4817, d_loss: 1.1480, g_loss: 0.8673\n",
      "[Sample] d_loss: 1.13830757, g_loss: 0.88424921\n",
      "Epoch: [13] [ 949/1093] time: 10479.3907, d_loss: 1.1714, g_loss: 0.8510\n",
      "[Sample] d_loss: 1.12877989, g_loss: 0.88479447\n",
      "Epoch: [13] [ 959/1093] time: 10483.7580, d_loss: 1.0902, g_loss: 0.8708\n",
      "[Sample] d_loss: 1.13636470, g_loss: 0.87056124\n",
      "Epoch: [13] [ 969/1093] time: 10488.2529, d_loss: 1.1265, g_loss: 0.8832\n",
      "[Sample] d_loss: 1.11128771, g_loss: 0.90854758\n",
      "Epoch: [13] [ 979/1093] time: 10494.5074, d_loss: 1.1424, g_loss: 0.9108\n",
      "[Sample] d_loss: 1.12995923, g_loss: 0.87472630\n",
      "Epoch: [13] [ 989/1093] time: 10501.1325, d_loss: 1.1274, g_loss: 0.8907\n",
      "[Sample] d_loss: 1.12137377, g_loss: 0.88343072\n",
      "Epoch: [13] [ 999/1093] time: 10506.6535, d_loss: 1.1170, g_loss: 0.8768\n",
      "[Sample] d_loss: 1.11861682, g_loss: 0.88363278\n",
      "Epoch: [13] [1009/1093] time: 10512.7592, d_loss: 1.1449, g_loss: 0.8535\n",
      "[Sample] d_loss: 1.14179313, g_loss: 0.85798240\n",
      "Epoch: [13] [1019/1093] time: 10517.9882, d_loss: 1.1490, g_loss: 0.8504\n",
      "[Sample] d_loss: 1.12670827, g_loss: 0.86567354\n",
      "Epoch: [13] [1029/1093] time: 10523.2699, d_loss: 1.1282, g_loss: 0.8662\n",
      "[Sample] d_loss: 1.12031782, g_loss: 0.88468850\n",
      "Epoch: [13] [1039/1093] time: 10528.6622, d_loss: 1.1660, g_loss: 0.8596\n",
      "[Sample] d_loss: 1.13774562, g_loss: 0.86489081\n",
      "Epoch: [13] [1049/1093] time: 10533.9923, d_loss: 1.1715, g_loss: 0.8406\n",
      "[Sample] d_loss: 1.14656401, g_loss: 0.85243648\n",
      "Epoch: [13] [1059/1093] time: 10539.1884, d_loss: 1.1574, g_loss: 0.8490\n",
      "[Sample] d_loss: 1.13605547, g_loss: 0.86910713\n",
      "Epoch: [13] [1069/1093] time: 10545.0000, d_loss: 1.1804, g_loss: 0.8569\n",
      "[Sample] d_loss: 1.13363469, g_loss: 0.87007987\n",
      "Epoch: [13] [1079/1093] time: 10551.2584, d_loss: 1.0972, g_loss: 0.8785\n",
      "[Sample] d_loss: 1.13376296, g_loss: 0.87138689\n",
      "Epoch: [13] [1089/1093] time: 10556.8314, d_loss: 1.1724, g_loss: 0.8358\n",
      "[Sample] d_loss: 1.14249516, g_loss: 0.86518764\n",
      "[Sample] d_loss: 1.14271760, g_loss: 0.87852192\n",
      "Epoch: [14] [   6/1093] time: 10561.7131, d_loss: 1.1584, g_loss: 0.8774\n",
      "[Sample] d_loss: 1.10310888, g_loss: 0.91677320\n",
      "Epoch: [14] [  16/1093] time: 10566.2083, d_loss: 1.1093, g_loss: 0.8708\n",
      "[Sample] d_loss: 1.11794257, g_loss: 0.88563865\n",
      "Epoch: [14] [  26/1093] time: 10570.4544, d_loss: 1.1387, g_loss: 0.8594\n",
      "[Sample] d_loss: 1.13400626, g_loss: 0.87237912\n",
      "Epoch: [14] [  36/1093] time: 10574.8632, d_loss: 1.1734, g_loss: 0.8535\n",
      "[Sample] d_loss: 1.11851716, g_loss: 0.89352858\n",
      "Epoch: [14] [  46/1093] time: 10579.0047, d_loss: 1.1729, g_loss: 0.8805\n",
      "[Sample] d_loss: 1.10338295, g_loss: 0.91979218\n",
      "Epoch: [14] [  56/1093] time: 10583.3204, d_loss: 1.1668, g_loss: 0.8750\n",
      "[Sample] d_loss: 1.10970473, g_loss: 0.89617145\n",
      "Epoch: [14] [  66/1093] time: 10587.5415, d_loss: 1.1608, g_loss: 0.8723\n",
      "[Sample] d_loss: 1.12400770, g_loss: 0.89467144\n",
      "Epoch: [14] [  76/1093] time: 10591.6743, d_loss: 1.1437, g_loss: 0.8630\n",
      "[Sample] d_loss: 1.11233950, g_loss: 0.89460289\n",
      "Epoch: [14] [  86/1093] time: 10595.9708, d_loss: 1.1162, g_loss: 0.8615\n",
      "[Sample] d_loss: 1.11424065, g_loss: 0.88770205\n",
      "Epoch: [14] [  96/1093] time: 10600.1842, d_loss: 1.1504, g_loss: 0.8385\n",
      "[Sample] d_loss: 1.12096286, g_loss: 0.88781118\n",
      "Epoch: [14] [ 106/1093] time: 10605.0442, d_loss: 1.1374, g_loss: 0.8784\n",
      "[Sample] d_loss: 1.11227775, g_loss: 0.88967478\n",
      "Epoch: [14] [ 116/1093] time: 10609.1458, d_loss: 1.1503, g_loss: 0.8856\n",
      "[Sample] d_loss: 1.12098885, g_loss: 0.89070594\n",
      "Epoch: [14] [ 126/1093] time: 10613.5047, d_loss: 1.1228, g_loss: 0.8649\n",
      "[Sample] d_loss: 1.11661744, g_loss: 0.87957048\n",
      "Epoch: [14] [ 136/1093] time: 10617.5431, d_loss: 1.1186, g_loss: 0.8403\n",
      "[Sample] d_loss: 1.10744882, g_loss: 0.90533197\n",
      "Epoch: [14] [ 146/1093] time: 10621.6247, d_loss: 1.1494, g_loss: 0.8718\n",
      "[Sample] d_loss: 1.11274767, g_loss: 0.89199668\n",
      "Epoch: [14] [ 156/1093] time: 10625.7963, d_loss: 1.0926, g_loss: 0.8722\n",
      "[Sample] d_loss: 1.11580443, g_loss: 0.88766158\n",
      "Epoch: [14] [ 166/1093] time: 10630.0552, d_loss: 1.1237, g_loss: 0.8714\n",
      "[Sample] d_loss: 1.10603750, g_loss: 0.90750933\n",
      "Epoch: [14] [ 176/1093] time: 10634.3353, d_loss: 1.0765, g_loss: 0.8872\n",
      "[Sample] d_loss: 1.10537052, g_loss: 0.91274309\n",
      "Epoch: [14] [ 186/1093] time: 10638.5320, d_loss: 1.1214, g_loss: 0.8482\n",
      "[Sample] d_loss: 1.10629511, g_loss: 0.90182501\n",
      "Epoch: [14] [ 196/1093] time: 10642.7458, d_loss: 1.1002, g_loss: 0.8962\n",
      "[Sample] d_loss: 1.10365748, g_loss: 0.90620375\n",
      "Epoch: [14] [ 206/1093] time: 10646.9525, d_loss: 1.1481, g_loss: 0.8592\n",
      "[Sample] d_loss: 1.09410262, g_loss: 0.92828763\n",
      "Epoch: [14] [ 216/1093] time: 10651.1821, d_loss: 1.1109, g_loss: 0.8888\n",
      "[Sample] d_loss: 1.11397839, g_loss: 0.89120770\n",
      "Epoch: [14] [ 226/1093] time: 10655.4355, d_loss: 1.0744, g_loss: 0.8974\n",
      "[Sample] d_loss: 1.12324774, g_loss: 0.88060421\n",
      "Epoch: [14] [ 236/1093] time: 10660.3770, d_loss: 1.1100, g_loss: 0.8773\n",
      "[Sample] d_loss: 1.10161483, g_loss: 0.90521204\n",
      "Epoch: [14] [ 246/1093] time: 10664.9485, d_loss: 1.0695, g_loss: 0.8948\n",
      "[Sample] d_loss: 1.12371922, g_loss: 0.86468661\n",
      "Epoch: [14] [ 256/1093] time: 10669.3495, d_loss: 1.0805, g_loss: 0.9114\n",
      "[Sample] d_loss: 1.13338733, g_loss: 0.86953390\n",
      "Epoch: [14] [ 266/1093] time: 10673.4178, d_loss: 1.1500, g_loss: 0.8254\n",
      "[Sample] d_loss: 1.10349441, g_loss: 0.91697907\n",
      "Epoch: [14] [ 276/1093] time: 10677.4577, d_loss: 1.1094, g_loss: 0.8629\n",
      "[Sample] d_loss: 1.13528609, g_loss: 0.87762213\n",
      "Epoch: [14] [ 286/1093] time: 10681.5133, d_loss: 1.0903, g_loss: 0.9187\n",
      "[Sample] d_loss: 1.11243415, g_loss: 0.89356047\n",
      "Epoch: [14] [ 296/1093] time: 10685.5337, d_loss: 1.1165, g_loss: 0.8693\n",
      "[Sample] d_loss: 1.12348318, g_loss: 0.88488054\n",
      "Epoch: [14] [ 306/1093] time: 10689.5774, d_loss: 1.1381, g_loss: 0.8728\n",
      "[Sample] d_loss: 1.12446105, g_loss: 0.88363594\n",
      "Epoch: [14] [ 316/1093] time: 10693.6676, d_loss: 1.1006, g_loss: 0.8632\n",
      "[Sample] d_loss: 1.12341416, g_loss: 0.88582408\n",
      "Epoch: [14] [ 326/1093] time: 10697.7202, d_loss: 1.1793, g_loss: 0.8539\n",
      "[Sample] d_loss: 1.13135242, g_loss: 0.88439071\n",
      "Epoch: [14] [ 336/1093] time: 10701.7544, d_loss: 1.1359, g_loss: 0.8740\n",
      "[Sample] d_loss: 1.14557266, g_loss: 0.87406969\n",
      "Epoch: [14] [ 346/1093] time: 10705.7581, d_loss: 1.1718, g_loss: 0.8554\n",
      "[Sample] d_loss: 1.14315104, g_loss: 0.86719704\n",
      "Epoch: [14] [ 356/1093] time: 10709.8086, d_loss: 1.1169, g_loss: 0.8804\n",
      "[Sample] d_loss: 1.12439275, g_loss: 0.88881117\n",
      "Epoch: [14] [ 366/1093] time: 10714.7436, d_loss: 1.0999, g_loss: 0.8713\n",
      "[Sample] d_loss: 1.13144803, g_loss: 0.87257773\n",
      "Epoch: [14] [ 376/1093] time: 10719.2063, d_loss: 1.1158, g_loss: 0.8736\n",
      "[Sample] d_loss: 1.11172175, g_loss: 0.89996088\n",
      "Epoch: [14] [ 386/1093] time: 10723.5888, d_loss: 1.0619, g_loss: 0.8794\n",
      "[Sample] d_loss: 1.14796758, g_loss: 0.85439074\n",
      "Epoch: [14] [ 396/1093] time: 10728.3520, d_loss: 1.1924, g_loss: 0.8600\n",
      "[Sample] d_loss: 1.12278259, g_loss: 0.88846791\n",
      "Epoch: [14] [ 406/1093] time: 10732.7580, d_loss: 1.0850, g_loss: 0.8802\n",
      "[Sample] d_loss: 1.12616324, g_loss: 0.87814564\n",
      "Epoch: [14] [ 416/1093] time: 10736.8960, d_loss: 1.0936, g_loss: 0.8397\n",
      "[Sample] d_loss: 1.13580704, g_loss: 0.86614883\n",
      "Epoch: [14] [ 426/1093] time: 10741.3035, d_loss: 1.1334, g_loss: 0.8826\n",
      "[Sample] d_loss: 1.13374400, g_loss: 0.86404228\n",
      "Epoch: [14] [ 436/1093] time: 10746.2462, d_loss: 1.1491, g_loss: 0.8719\n",
      "[Sample] d_loss: 1.13907361, g_loss: 0.86566627\n",
      "Epoch: [14] [ 446/1093] time: 10750.8025, d_loss: 1.0742, g_loss: 0.9079\n",
      "[Sample] d_loss: 1.12694454, g_loss: 0.87739289\n",
      "Epoch: [14] [ 456/1093] time: 10755.7021, d_loss: 1.1200, g_loss: 0.8607\n",
      "[Sample] d_loss: 1.13076472, g_loss: 0.86945581\n",
      "Epoch: [14] [ 466/1093] time: 10761.6318, d_loss: 1.1478, g_loss: 0.8857\n",
      "[Sample] d_loss: 1.13118744, g_loss: 0.86637104\n",
      "Epoch: [14] [ 476/1093] time: 10766.8234, d_loss: 1.0724, g_loss: 0.8689\n",
      "[Sample] d_loss: 1.12255096, g_loss: 0.89301437\n",
      "Epoch: [14] [ 486/1093] time: 10772.1271, d_loss: 1.1138, g_loss: 0.8585\n",
      "[Sample] d_loss: 1.12874234, g_loss: 0.88266921\n",
      "Epoch: [14] [ 496/1093] time: 10777.4827, d_loss: 1.1580, g_loss: 0.9056\n",
      "[Sample] d_loss: 1.12068796, g_loss: 0.89949107\n",
      "Epoch: [14] [ 506/1093] time: 10782.6775, d_loss: 1.1745, g_loss: 0.8467\n",
      "[Sample] d_loss: 1.10066223, g_loss: 0.92516047\n",
      "Epoch: [14] [ 516/1093] time: 10787.9909, d_loss: 1.1205, g_loss: 0.8592\n",
      "[Sample] d_loss: 1.10265744, g_loss: 0.90962696\n",
      "Epoch: [14] [ 526/1093] time: 10795.2209, d_loss: 1.1858, g_loss: 0.8664\n",
      "[Sample] d_loss: 1.12521005, g_loss: 0.88694441\n",
      "Epoch: [14] [ 536/1093] time: 10802.5195, d_loss: 1.1208, g_loss: 0.8625\n",
      "[Sample] d_loss: 1.11543179, g_loss: 0.87165201\n",
      "Epoch: [14] [ 546/1093] time: 10808.8672, d_loss: 1.0961, g_loss: 0.9040\n",
      "[Sample] d_loss: 1.11330652, g_loss: 0.89324677\n",
      "Epoch: [14] [ 556/1093] time: 10815.2245, d_loss: 1.1046, g_loss: 0.8240\n",
      "[Sample] d_loss: 1.11904192, g_loss: 0.87656873\n",
      "Epoch: [14] [ 566/1093] time: 10821.2689, d_loss: 1.1046, g_loss: 0.8733\n",
      "[Sample] d_loss: 1.11625290, g_loss: 0.89333040\n",
      "Epoch: [14] [ 576/1093] time: 10827.4010, d_loss: 1.1068, g_loss: 0.8901\n",
      "[Sample] d_loss: 1.09944856, g_loss: 0.89515269\n",
      "Epoch: [14] [ 586/1093] time: 10833.4667, d_loss: 1.0999, g_loss: 0.8634\n",
      "[Sample] d_loss: 1.10179389, g_loss: 0.91915286\n",
      "Epoch: [14] [ 596/1093] time: 10839.6136, d_loss: 1.1621, g_loss: 0.8930\n",
      "[Sample] d_loss: 1.09741843, g_loss: 0.91184384\n",
      "Epoch: [14] [ 606/1093] time: 10845.9546, d_loss: 1.0615, g_loss: 0.8859\n",
      "[Sample] d_loss: 1.11282372, g_loss: 0.89363146\n",
      "Epoch: [14] [ 616/1093] time: 10852.1207, d_loss: 1.1275, g_loss: 0.8409\n",
      "[Sample] d_loss: 1.10954559, g_loss: 0.89465493\n",
      "Epoch: [14] [ 626/1093] time: 10857.6583, d_loss: 1.0473, g_loss: 0.9103\n",
      "[Sample] d_loss: 1.09685183, g_loss: 0.90974188\n",
      "Epoch: [14] [ 636/1093] time: 10863.0028, d_loss: 1.0517, g_loss: 0.9435\n",
      "[Sample] d_loss: 1.10462737, g_loss: 0.89989048\n",
      "Epoch: [14] [ 646/1093] time: 10868.3716, d_loss: 1.1671, g_loss: 0.8858\n",
      "[Sample] d_loss: 1.11827219, g_loss: 0.87821841\n",
      "Epoch: [14] [ 656/1093] time: 10873.6731, d_loss: 1.0804, g_loss: 0.9268\n",
      "[Sample] d_loss: 1.11196017, g_loss: 0.88972497\n",
      "Epoch: [14] [ 666/1093] time: 10879.0171, d_loss: 1.1544, g_loss: 0.8590\n",
      "[Sample] d_loss: 1.09984875, g_loss: 0.89372718\n",
      "Epoch: [14] [ 676/1093] time: 10884.2765, d_loss: 1.0677, g_loss: 0.8739\n",
      "[Sample] d_loss: 1.10521770, g_loss: 0.89181030\n",
      "Epoch: [14] [ 686/1093] time: 10889.5887, d_loss: 1.0661, g_loss: 0.9021\n",
      "[Sample] d_loss: 1.10467684, g_loss: 0.90269166\n",
      "Epoch: [14] [ 696/1093] time: 10894.8776, d_loss: 1.1297, g_loss: 0.8850\n",
      "[Sample] d_loss: 1.09842157, g_loss: 0.92690897\n",
      "Epoch: [14] [ 706/1093] time: 10900.1640, d_loss: 1.1501, g_loss: 0.8641\n",
      "[Sample] d_loss: 1.11345673, g_loss: 0.88626337\n",
      "Epoch: [14] [ 716/1093] time: 10905.5725, d_loss: 1.0897, g_loss: 0.9130\n",
      "[Sample] d_loss: 1.10071325, g_loss: 0.91070759\n",
      "Epoch: [14] [ 726/1093] time: 10910.9988, d_loss: 1.1312, g_loss: 0.8893\n",
      "[Sample] d_loss: 1.10579252, g_loss: 0.90382594\n",
      "Epoch: [14] [ 736/1093] time: 10916.3391, d_loss: 1.0753, g_loss: 0.9037\n",
      "[Sample] d_loss: 1.11674535, g_loss: 0.88332170\n",
      "Epoch: [14] [ 746/1093] time: 10921.8226, d_loss: 1.1060, g_loss: 0.8967\n",
      "[Sample] d_loss: 1.12226856, g_loss: 0.88863361\n",
      "Epoch: [14] [ 756/1093] time: 10927.2575, d_loss: 1.1680, g_loss: 0.8545\n",
      "[Sample] d_loss: 1.09253478, g_loss: 0.90398097\n",
      "Epoch: [14] [ 766/1093] time: 10932.6139, d_loss: 1.0783, g_loss: 0.8919\n",
      "[Sample] d_loss: 1.09387147, g_loss: 0.90364361\n",
      "Epoch: [14] [ 776/1093] time: 10938.4645, d_loss: 1.0898, g_loss: 0.8905\n",
      "[Sample] d_loss: 1.10214901, g_loss: 0.89275718\n",
      "Epoch: [14] [ 786/1093] time: 10943.3544, d_loss: 1.1235, g_loss: 0.8905\n",
      "[Sample] d_loss: 1.09229946, g_loss: 0.89683723\n",
      "Epoch: [14] [ 796/1093] time: 10948.0166, d_loss: 1.0443, g_loss: 0.9006\n",
      "[Sample] d_loss: 1.09583449, g_loss: 0.91099662\n",
      "Epoch: [14] [ 806/1093] time: 10952.1123, d_loss: 1.1030, g_loss: 0.8661\n",
      "[Sample] d_loss: 1.09290922, g_loss: 0.92413342\n",
      "Epoch: [14] [ 816/1093] time: 10956.7952, d_loss: 1.1081, g_loss: 0.8767\n",
      "[Sample] d_loss: 1.07406807, g_loss: 0.93725407\n",
      "Epoch: [14] [ 826/1093] time: 10961.3536, d_loss: 1.0902, g_loss: 0.8873\n",
      "[Sample] d_loss: 1.06428266, g_loss: 0.94540143\n",
      "Epoch: [14] [ 836/1093] time: 10965.7023, d_loss: 1.1147, g_loss: 0.8779\n",
      "[Sample] d_loss: 1.07024837, g_loss: 0.92900968\n",
      "Epoch: [14] [ 846/1093] time: 10969.8523, d_loss: 1.0524, g_loss: 0.9242\n",
      "[Sample] d_loss: 1.09788132, g_loss: 0.89997315\n",
      "Epoch: [14] [ 856/1093] time: 10973.8651, d_loss: 1.1070, g_loss: 0.8771\n",
      "[Sample] d_loss: 1.07965171, g_loss: 0.91829598\n",
      "Epoch: [14] [ 866/1093] time: 10977.9084, d_loss: 1.1431, g_loss: 0.8610\n",
      "[Sample] d_loss: 1.08335721, g_loss: 0.91734719\n",
      "Epoch: [14] [ 876/1093] time: 10981.9792, d_loss: 1.0564, g_loss: 0.8759\n",
      "[Sample] d_loss: 1.08677197, g_loss: 0.91409099\n",
      "Epoch: [14] [ 886/1093] time: 10986.0212, d_loss: 1.1682, g_loss: 0.8721\n",
      "[Sample] d_loss: 1.09422684, g_loss: 0.90379167\n",
      "Epoch: [14] [ 896/1093] time: 10990.0325, d_loss: 1.0609, g_loss: 0.8909\n",
      "[Sample] d_loss: 1.10608196, g_loss: 0.89094305\n",
      "Epoch: [14] [ 906/1093] time: 10994.0297, d_loss: 1.0735, g_loss: 0.9094\n",
      "[Sample] d_loss: 1.09445846, g_loss: 0.90464389\n",
      "Epoch: [14] [ 916/1093] time: 10998.1441, d_loss: 1.0826, g_loss: 0.8819\n",
      "[Sample] d_loss: 1.07977033, g_loss: 0.91593564\n",
      "Epoch: [14] [ 926/1093] time: 11002.1462, d_loss: 1.1179, g_loss: 0.8936\n",
      "[Sample] d_loss: 1.07754576, g_loss: 0.90667957\n",
      "Epoch: [14] [ 936/1093] time: 11006.1423, d_loss: 1.1470, g_loss: 0.8987\n",
      "[Sample] d_loss: 1.08571291, g_loss: 0.90339780\n",
      "Epoch: [14] [ 946/1093] time: 11010.2026, d_loss: 1.1116, g_loss: 0.8825\n",
      "[Sample] d_loss: 1.10023856, g_loss: 0.89025265\n",
      "Epoch: [14] [ 956/1093] time: 11014.2316, d_loss: 1.1418, g_loss: 0.8855\n",
      "[Sample] d_loss: 1.08641672, g_loss: 0.91003883\n",
      "Epoch: [14] [ 966/1093] time: 11018.2229, d_loss: 1.0795, g_loss: 0.9133\n",
      "[Sample] d_loss: 1.08503342, g_loss: 0.90640336\n",
      "Epoch: [14] [ 976/1093] time: 11022.2618, d_loss: 1.0496, g_loss: 0.9455\n",
      "[Sample] d_loss: 1.08655238, g_loss: 0.90442175\n",
      "Epoch: [14] [ 986/1093] time: 11026.3276, d_loss: 1.0695, g_loss: 0.9012\n",
      "[Sample] d_loss: 1.09636474, g_loss: 0.89903820\n",
      "Epoch: [14] [ 996/1093] time: 11030.5254, d_loss: 1.0538, g_loss: 0.8860\n",
      "[Sample] d_loss: 1.07996202, g_loss: 0.90441102\n",
      "Epoch: [14] [1006/1093] time: 11034.7910, d_loss: 1.1362, g_loss: 0.8806\n",
      "[Sample] d_loss: 1.09211755, g_loss: 0.89177459\n",
      "Epoch: [14] [1016/1093] time: 11039.2422, d_loss: 1.1249, g_loss: 0.9008\n",
      "[Sample] d_loss: 1.08656216, g_loss: 0.89501458\n",
      "Epoch: [14] [1026/1093] time: 11043.6304, d_loss: 1.0721, g_loss: 0.8900\n",
      "[Sample] d_loss: 1.07329369, g_loss: 0.91622746\n",
      "Epoch: [14] [1036/1093] time: 11048.1573, d_loss: 1.1015, g_loss: 0.9044\n",
      "[Sample] d_loss: 1.08347678, g_loss: 0.90504557\n",
      "Epoch: [14] [1046/1093] time: 11052.3438, d_loss: 1.0441, g_loss: 0.9238\n",
      "[Sample] d_loss: 1.08241963, g_loss: 0.90895021\n",
      "Epoch: [14] [1056/1093] time: 11056.6429, d_loss: 1.1101, g_loss: 0.9117\n",
      "[Sample] d_loss: 1.09961772, g_loss: 0.89011395\n",
      "Epoch: [14] [1066/1093] time: 11060.9957, d_loss: 1.1386, g_loss: 0.8956\n",
      "[Sample] d_loss: 1.08302426, g_loss: 0.88641781\n",
      "Epoch: [14] [1076/1093] time: 11065.3265, d_loss: 1.1340, g_loss: 0.8773\n",
      "[Sample] d_loss: 1.06586528, g_loss: 0.91390711\n",
      "Epoch: [14] [1086/1093] time: 11069.4140, d_loss: 1.0893, g_loss: 0.8979\n",
      "[Sample] d_loss: 1.05641139, g_loss: 0.93688238\n",
      "[Sample] d_loss: 1.06519461, g_loss: 0.92118931\n",
      "Epoch: [15] [   3/1093] time: 11073.7398, d_loss: 1.1058, g_loss: 0.8866\n",
      "[Sample] d_loss: 1.09572124, g_loss: 0.88459384\n",
      "Epoch: [15] [  13/1093] time: 11077.7198, d_loss: 1.0932, g_loss: 0.9136\n",
      "[Sample] d_loss: 1.07390428, g_loss: 0.90231216\n",
      "Epoch: [15] [  23/1093] time: 11081.7397, d_loss: 1.0446, g_loss: 0.9015\n",
      "[Sample] d_loss: 1.08287823, g_loss: 0.89246523\n",
      "Epoch: [15] [  33/1093] time: 11085.7623, d_loss: 1.0419, g_loss: 0.9200\n",
      "[Sample] d_loss: 1.07880521, g_loss: 0.89795470\n",
      "Epoch: [15] [  43/1093] time: 11089.7459, d_loss: 1.0420, g_loss: 0.8946\n",
      "[Sample] d_loss: 1.07971776, g_loss: 0.90106785\n",
      "Epoch: [15] [  53/1093] time: 11093.9677, d_loss: 1.0685, g_loss: 0.9264\n",
      "[Sample] d_loss: 1.06792355, g_loss: 0.92361057\n",
      "Epoch: [15] [  63/1093] time: 11097.9878, d_loss: 1.0799, g_loss: 0.8905\n",
      "[Sample] d_loss: 1.05470073, g_loss: 0.93827426\n",
      "Epoch: [15] [  73/1093] time: 11101.9851, d_loss: 1.0489, g_loss: 0.9298\n",
      "[Sample] d_loss: 1.05638051, g_loss: 0.93667758\n",
      "Epoch: [15] [  83/1093] time: 11105.9784, d_loss: 1.0878, g_loss: 0.9311\n",
      "[Sample] d_loss: 1.06139123, g_loss: 0.92800468\n",
      "Epoch: [15] [  93/1093] time: 11109.9859, d_loss: 1.1241, g_loss: 0.8656\n",
      "[Sample] d_loss: 1.06800878, g_loss: 0.92273414\n",
      "Epoch: [15] [ 103/1093] time: 11113.9626, d_loss: 1.1498, g_loss: 0.9152\n",
      "[Sample] d_loss: 1.07127953, g_loss: 0.91363311\n",
      "Epoch: [15] [ 113/1093] time: 11117.9689, d_loss: 1.0889, g_loss: 0.9133\n",
      "[Sample] d_loss: 1.08004069, g_loss: 0.90788949\n",
      "Epoch: [15] [ 123/1093] time: 11121.9395, d_loss: 1.0762, g_loss: 0.9146\n",
      "[Sample] d_loss: 1.08075261, g_loss: 0.91077924\n",
      "Epoch: [15] [ 133/1093] time: 11125.9151, d_loss: 1.0798, g_loss: 0.9244\n",
      "[Sample] d_loss: 1.07175946, g_loss: 0.92292666\n",
      "Epoch: [15] [ 143/1093] time: 11129.9227, d_loss: 1.1013, g_loss: 0.9165\n",
      "[Sample] d_loss: 1.07028365, g_loss: 0.92158967\n",
      "Epoch: [15] [ 153/1093] time: 11133.9540, d_loss: 1.0509, g_loss: 0.9087\n",
      "[Sample] d_loss: 1.06283045, g_loss: 0.94607377\n",
      "Epoch: [15] [ 163/1093] time: 11138.0114, d_loss: 1.1018, g_loss: 0.9217\n",
      "[Sample] d_loss: 1.05642283, g_loss: 0.94272661\n",
      "Epoch: [15] [ 173/1093] time: 11141.9426, d_loss: 1.0120, g_loss: 0.9518\n",
      "[Sample] d_loss: 1.05283785, g_loss: 0.94255358\n",
      "Epoch: [15] [ 183/1093] time: 11146.0023, d_loss: 1.0803, g_loss: 0.9018\n",
      "[Sample] d_loss: 1.04745555, g_loss: 0.95144510\n",
      "Epoch: [15] [ 193/1093] time: 11150.1907, d_loss: 1.0759, g_loss: 0.9390\n",
      "[Sample] d_loss: 1.05566072, g_loss: 0.94549316\n",
      "Epoch: [15] [ 203/1093] time: 11154.1863, d_loss: 1.0687, g_loss: 0.9093\n",
      "[Sample] d_loss: 1.07339442, g_loss: 0.90949285\n",
      "Epoch: [15] [ 213/1093] time: 11158.1459, d_loss: 1.0427, g_loss: 0.9663\n",
      "[Sample] d_loss: 1.08461356, g_loss: 0.89589214\n",
      "Epoch: [15] [ 223/1093] time: 11162.2800, d_loss: 1.0980, g_loss: 0.8992\n",
      "[Sample] d_loss: 1.04638898, g_loss: 0.94705164\n",
      "Epoch: [15] [ 233/1093] time: 11166.2518, d_loss: 1.0320, g_loss: 0.9061\n",
      "[Sample] d_loss: 1.02599847, g_loss: 0.97582954\n",
      "Epoch: [15] [ 243/1093] time: 11170.1930, d_loss: 1.0896, g_loss: 0.9067\n",
      "[Sample] d_loss: 1.05874145, g_loss: 0.92587650\n",
      "Epoch: [15] [ 253/1093] time: 11174.1483, d_loss: 1.1034, g_loss: 0.8860\n",
      "[Sample] d_loss: 1.06702578, g_loss: 0.91344392\n",
      "Epoch: [15] [ 263/1093] time: 11178.2067, d_loss: 1.1470, g_loss: 0.9247\n",
      "[Sample] d_loss: 1.04831839, g_loss: 0.94062936\n",
      "Epoch: [15] [ 273/1093] time: 11182.1738, d_loss: 1.0491, g_loss: 0.9226\n",
      "[Sample] d_loss: 1.04107285, g_loss: 0.94737387\n",
      "Epoch: [15] [ 283/1093] time: 11186.1364, d_loss: 1.0813, g_loss: 0.8848\n",
      "[Sample] d_loss: 1.05237412, g_loss: 0.92692918\n",
      "Epoch: [15] [ 293/1093] time: 11190.0894, d_loss: 1.1377, g_loss: 0.8793\n",
      "[Sample] d_loss: 1.04889607, g_loss: 0.94927967\n",
      "Epoch: [15] [ 303/1093] time: 11194.0568, d_loss: 1.0665, g_loss: 0.9455\n",
      "[Sample] d_loss: 1.05468845, g_loss: 0.92545086\n",
      "Epoch: [15] [ 313/1093] time: 11198.0472, d_loss: 1.0374, g_loss: 0.9362\n",
      "[Sample] d_loss: 1.07186842, g_loss: 0.90104443\n",
      "Epoch: [15] [ 323/1093] time: 11201.9750, d_loss: 1.0471, g_loss: 0.8936\n",
      "[Sample] d_loss: 1.07893765, g_loss: 0.89711738\n",
      "Epoch: [15] [ 333/1093] time: 11205.9725, d_loss: 1.0775, g_loss: 0.9077\n",
      "[Sample] d_loss: 1.06837320, g_loss: 0.90680182\n",
      "Epoch: [15] [ 343/1093] time: 11209.9586, d_loss: 1.0791, g_loss: 0.9630\n",
      "[Sample] d_loss: 1.08353448, g_loss: 0.89708734\n",
      "Epoch: [15] [ 353/1093] time: 11213.9037, d_loss: 1.0592, g_loss: 0.8891\n",
      "[Sample] d_loss: 1.03715074, g_loss: 0.94519484\n",
      "Epoch: [15] [ 363/1093] time: 11217.8596, d_loss: 1.0739, g_loss: 0.9181\n",
      "[Sample] d_loss: 1.04652441, g_loss: 0.94257259\n",
      "Epoch: [15] [ 373/1093] time: 11221.8243, d_loss: 1.0066, g_loss: 0.9040\n",
      "[Sample] d_loss: 1.04538715, g_loss: 0.93278563\n",
      "Epoch: [15] [ 383/1093] time: 11225.8242, d_loss: 1.1040, g_loss: 0.8724\n",
      "[Sample] d_loss: 1.04746342, g_loss: 0.92475355\n",
      "Epoch: [15] [ 393/1093] time: 11229.7750, d_loss: 1.0295, g_loss: 0.9007\n",
      "[Sample] d_loss: 1.05787039, g_loss: 0.92625642\n",
      "Epoch: [15] [ 403/1093] time: 11233.7487, d_loss: 1.0803, g_loss: 0.8976\n",
      "[Sample] d_loss: 1.05294478, g_loss: 0.92981482\n",
      "Epoch: [15] [ 413/1093] time: 11237.6709, d_loss: 1.0213, g_loss: 0.9478\n",
      "[Sample] d_loss: 1.05045521, g_loss: 0.92080075\n",
      "Epoch: [15] [ 423/1093] time: 11241.6454, d_loss: 0.9977, g_loss: 0.9161\n",
      "[Sample] d_loss: 1.05400884, g_loss: 0.91956961\n",
      "Epoch: [15] [ 433/1093] time: 11245.5660, d_loss: 1.0696, g_loss: 0.9505\n",
      "[Sample] d_loss: 1.03924417, g_loss: 0.93134701\n",
      "Epoch: [15] [ 443/1093] time: 11249.5686, d_loss: 1.0605, g_loss: 0.9051\n",
      "[Sample] d_loss: 1.04193091, g_loss: 0.92227197\n",
      "Epoch: [15] [ 453/1093] time: 11253.5615, d_loss: 1.0484, g_loss: 0.9270\n",
      "[Sample] d_loss: 1.03152990, g_loss: 0.93746251\n",
      "Epoch: [15] [ 463/1093] time: 11257.4682, d_loss: 1.0797, g_loss: 0.9110\n",
      "[Sample] d_loss: 1.05086112, g_loss: 0.89589906\n",
      "Epoch: [15] [ 473/1093] time: 11261.3761, d_loss: 1.0590, g_loss: 0.9176\n",
      "[Sample] d_loss: 1.05427027, g_loss: 0.89239103\n",
      "Epoch: [15] [ 483/1093] time: 11265.4333, d_loss: 1.0661, g_loss: 0.8986\n",
      "[Sample] d_loss: 1.05003238, g_loss: 0.89801431\n",
      "Epoch: [15] [ 493/1093] time: 11269.3686, d_loss: 1.0507, g_loss: 0.9151\n",
      "[Sample] d_loss: 1.03991938, g_loss: 0.93112546\n",
      "Epoch: [15] [ 503/1093] time: 11273.3900, d_loss: 1.1166, g_loss: 0.9825\n",
      "[Sample] d_loss: 1.04034245, g_loss: 0.92223024\n",
      "Epoch: [15] [ 513/1093] time: 11277.3798, d_loss: 1.0493, g_loss: 0.9736\n",
      "[Sample] d_loss: 1.05364537, g_loss: 0.90061873\n",
      "Epoch: [15] [ 523/1093] time: 11281.3101, d_loss: 1.0259, g_loss: 0.9258\n",
      "[Sample] d_loss: 1.04193079, g_loss: 0.91487116\n",
      "Epoch: [15] [ 533/1093] time: 11285.2911, d_loss: 1.0430, g_loss: 0.9126\n",
      "[Sample] d_loss: 1.03989959, g_loss: 0.91927338\n",
      "Epoch: [15] [ 543/1093] time: 11289.2283, d_loss: 1.0533, g_loss: 0.9232\n",
      "[Sample] d_loss: 1.03683281, g_loss: 0.92454410\n",
      "Epoch: [15] [ 553/1093] time: 11293.2436, d_loss: 1.0519, g_loss: 0.9392\n",
      "[Sample] d_loss: 1.05313969, g_loss: 0.91999638\n",
      "Epoch: [15] [ 563/1093] time: 11297.3493, d_loss: 1.0778, g_loss: 0.9290\n",
      "[Sample] d_loss: 1.03939486, g_loss: 0.92255664\n",
      "Epoch: [15] [ 573/1093] time: 11301.3028, d_loss: 1.0648, g_loss: 0.9345\n",
      "[Sample] d_loss: 1.04057288, g_loss: 0.91697091\n",
      "Epoch: [15] [ 583/1093] time: 11305.2548, d_loss: 1.0657, g_loss: 0.9107\n",
      "[Sample] d_loss: 1.03971815, g_loss: 0.92675066\n",
      "Epoch: [15] [ 593/1093] time: 11309.1966, d_loss: 1.1017, g_loss: 0.9213\n",
      "[Sample] d_loss: 1.03191340, g_loss: 0.94064641\n",
      "Epoch: [15] [ 603/1093] time: 11313.1060, d_loss: 1.0542, g_loss: 0.9443\n",
      "[Sample] d_loss: 1.01117039, g_loss: 0.97914433\n",
      "Epoch: [15] [ 613/1093] time: 11317.1465, d_loss: 1.0360, g_loss: 0.9475\n",
      "[Sample] d_loss: 1.02840352, g_loss: 0.94467235\n",
      "Epoch: [15] [ 623/1093] time: 11321.0973, d_loss: 1.0612, g_loss: 0.9177\n",
      "[Sample] d_loss: 1.01051664, g_loss: 0.96112502\n",
      "Epoch: [15] [ 633/1093] time: 11325.0253, d_loss: 1.1016, g_loss: 0.9262\n",
      "[Sample] d_loss: 1.01843166, g_loss: 0.96146798\n",
      "Epoch: [15] [ 643/1093] time: 11328.9924, d_loss: 1.0301, g_loss: 0.9649\n",
      "[Sample] d_loss: 1.00357080, g_loss: 0.97004056\n",
      "Epoch: [15] [ 653/1093] time: 11332.9532, d_loss: 1.0008, g_loss: 0.9759\n",
      "[Sample] d_loss: 1.02515411, g_loss: 0.95670444\n",
      "Epoch: [15] [ 663/1093] time: 11336.9095, d_loss: 1.0836, g_loss: 0.9175\n",
      "[Sample] d_loss: 1.03322458, g_loss: 0.93910372\n",
      "Epoch: [15] [ 673/1093] time: 11340.8783, d_loss: 0.9765, g_loss: 0.9508\n",
      "[Sample] d_loss: 1.00655425, g_loss: 0.98062223\n",
      "Epoch: [15] [ 683/1093] time: 11344.8629, d_loss: 1.0759, g_loss: 0.9220\n",
      "[Sample] d_loss: 1.02965891, g_loss: 0.95417643\n",
      "Epoch: [15] [ 693/1093] time: 11348.8886, d_loss: 1.1009, g_loss: 0.9363\n",
      "[Sample] d_loss: 1.00186622, g_loss: 0.98181510\n",
      "Epoch: [15] [ 703/1093] time: 11352.8434, d_loss: 0.9941, g_loss: 0.9703\n",
      "[Sample] d_loss: 1.03478432, g_loss: 0.92949837\n",
      "Epoch: [15] [ 713/1093] time: 11356.8499, d_loss: 1.0634, g_loss: 0.9708\n",
      "[Sample] d_loss: 1.02863467, g_loss: 0.93766344\n",
      "Epoch: [15] [ 723/1093] time: 11360.8071, d_loss: 1.0437, g_loss: 0.9342\n",
      "[Sample] d_loss: 1.01657879, g_loss: 0.95971310\n",
      "Epoch: [15] [ 733/1093] time: 11364.7686, d_loss: 1.0085, g_loss: 0.9386\n",
      "[Sample] d_loss: 1.01918316, g_loss: 0.95514429\n",
      "Epoch: [15] [ 743/1093] time: 11368.7297, d_loss: 1.0681, g_loss: 0.9576\n",
      "[Sample] d_loss: 1.01731133, g_loss: 0.95638663\n",
      "Epoch: [15] [ 753/1093] time: 11372.8550, d_loss: 1.0345, g_loss: 0.9021\n",
      "[Sample] d_loss: 0.99887401, g_loss: 0.97908711\n",
      "Epoch: [15] [ 763/1093] time: 11376.7964, d_loss: 0.9855, g_loss: 0.9794\n",
      "[Sample] d_loss: 0.99024045, g_loss: 0.99566281\n",
      "Epoch: [15] [ 773/1093] time: 11380.7397, d_loss: 1.0074, g_loss: 0.9921\n",
      "[Sample] d_loss: 0.97544038, g_loss: 1.00895000\n",
      "Epoch: [15] [ 783/1093] time: 11384.7084, d_loss: 0.9811, g_loss: 0.9380\n",
      "[Sample] d_loss: 1.00371766, g_loss: 0.97286755\n",
      "Epoch: [15] [ 793/1093] time: 11388.6448, d_loss: 1.0420, g_loss: 0.9623\n",
      "[Sample] d_loss: 1.00086403, g_loss: 0.97571397\n",
      "Epoch: [15] [ 803/1093] time: 11392.8533, d_loss: 0.9944, g_loss: 0.9281\n",
      "[Sample] d_loss: 0.99720943, g_loss: 0.98098028\n",
      "Epoch: [15] [ 813/1093] time: 11396.8232, d_loss: 0.9889, g_loss: 0.9798\n",
      "[Sample] d_loss: 0.99160302, g_loss: 0.99656916\n",
      "Epoch: [15] [ 823/1093] time: 11400.7819, d_loss: 1.0388, g_loss: 0.9509\n",
      "[Sample] d_loss: 1.00426459, g_loss: 1.00031757\n",
      "Epoch: [15] [ 833/1093] time: 11404.7675, d_loss: 1.0215, g_loss: 0.9828\n",
      "[Sample] d_loss: 0.98908257, g_loss: 0.98055911\n",
      "Epoch: [15] [ 843/1093] time: 11408.7128, d_loss: 0.9699, g_loss: 1.0224\n",
      "[Sample] d_loss: 0.99853283, g_loss: 0.97091722\n",
      "Epoch: [15] [ 853/1093] time: 11412.6991, d_loss: 1.0168, g_loss: 0.9109\n",
      "[Sample] d_loss: 0.99616992, g_loss: 0.98522162\n",
      "Epoch: [15] [ 863/1093] time: 11416.6861, d_loss: 1.0657, g_loss: 0.9719\n",
      "[Sample] d_loss: 0.99875766, g_loss: 0.98413193\n",
      "Epoch: [15] [ 873/1093] time: 11420.7329, d_loss: 0.9972, g_loss: 0.9461\n",
      "[Sample] d_loss: 0.99442858, g_loss: 0.97870415\n",
      "Epoch: [15] [ 883/1093] time: 11424.6880, d_loss: 1.0805, g_loss: 0.9244\n",
      "[Sample] d_loss: 0.99577153, g_loss: 0.97239083\n",
      "Epoch: [15] [ 893/1093] time: 11428.6615, d_loss: 1.0532, g_loss: 0.9658\n",
      "[Sample] d_loss: 0.99966174, g_loss: 0.96707428\n",
      "Epoch: [15] [ 903/1093] time: 11432.5970, d_loss: 1.0132, g_loss: 0.9408\n",
      "[Sample] d_loss: 0.98309076, g_loss: 0.98940718\n",
      "Epoch: [15] [ 913/1093] time: 11436.5464, d_loss: 0.9913, g_loss: 0.9930\n",
      "[Sample] d_loss: 0.98281133, g_loss: 0.98128474\n",
      "Epoch: [15] [ 923/1093] time: 11440.5041, d_loss: 1.0322, g_loss: 0.9460\n",
      "[Sample] d_loss: 1.00602019, g_loss: 0.94655949\n",
      "Epoch: [15] [ 933/1093] time: 11444.5152, d_loss: 1.0465, g_loss: 0.9699\n",
      "[Sample] d_loss: 1.00665224, g_loss: 0.95068765\n",
      "Epoch: [15] [ 943/1093] time: 11448.5069, d_loss: 1.0160, g_loss: 0.9169\n",
      "[Sample] d_loss: 0.98609793, g_loss: 0.97476792\n",
      "Epoch: [15] [ 953/1093] time: 11452.4582, d_loss: 1.0585, g_loss: 0.9684\n",
      "[Sample] d_loss: 0.96834087, g_loss: 0.98256660\n",
      "Epoch: [15] [ 963/1093] time: 11456.4118, d_loss: 0.9971, g_loss: 0.9587\n",
      "[Sample] d_loss: 0.98266590, g_loss: 0.96359217\n",
      "Epoch: [15] [ 973/1093] time: 11460.4043, d_loss: 0.9806, g_loss: 0.9526\n",
      "[Sample] d_loss: 0.99367607, g_loss: 0.95430720\n",
      "Epoch: [15] [ 983/1093] time: 11464.3853, d_loss: 1.0446, g_loss: 0.9393\n",
      "[Sample] d_loss: 0.99337518, g_loss: 0.95515603\n",
      "Epoch: [15] [ 993/1093] time: 11468.3309, d_loss: 0.9668, g_loss: 0.9333\n",
      "[Sample] d_loss: 0.98877746, g_loss: 0.97338283\n",
      "Epoch: [15] [1003/1093] time: 11472.2626, d_loss: 0.9941, g_loss: 0.9089\n",
      "[Sample] d_loss: 0.99861860, g_loss: 0.97613931\n",
      "Epoch: [15] [1013/1093] time: 11476.1982, d_loss: 1.0571, g_loss: 0.9211\n",
      "[Sample] d_loss: 1.00294602, g_loss: 0.97514606\n",
      "Epoch: [15] [1023/1093] time: 11480.1685, d_loss: 1.0612, g_loss: 0.9346\n",
      "[Sample] d_loss: 0.99755710, g_loss: 0.97577405\n",
      "Epoch: [15] [1033/1093] time: 11484.1652, d_loss: 0.9810, g_loss: 0.9465\n",
      "[Sample] d_loss: 0.99595034, g_loss: 0.98764074\n",
      "Epoch: [15] [1043/1093] time: 11488.3269, d_loss: 1.0712, g_loss: 0.8953\n",
      "[Sample] d_loss: 1.00112271, g_loss: 0.97795105\n",
      "Epoch: [15] [1053/1093] time: 11492.7303, d_loss: 1.0215, g_loss: 0.9331\n",
      "[Sample] d_loss: 0.98682463, g_loss: 0.98320723\n",
      "Epoch: [15] [1063/1093] time: 11496.7984, d_loss: 1.0928, g_loss: 0.9288\n",
      "[Sample] d_loss: 0.98095077, g_loss: 0.99149597\n",
      "Epoch: [15] [1073/1093] time: 11500.9080, d_loss: 1.0037, g_loss: 0.9385\n",
      "[Sample] d_loss: 0.99566859, g_loss: 0.96242416\n",
      "Epoch: [15] [1083/1093] time: 11504.9531, d_loss: 1.1183, g_loss: 0.9257\n",
      "[Sample] d_loss: 0.99915498, g_loss: 0.97493255\n",
      "Epoch: [16] [   0/1093] time: 11509.0198, d_loss: 1.0226, g_loss: 0.9425\n",
      "[Sample] d_loss: 1.00011718, g_loss: 0.96762079\n",
      "Epoch: [16] [  10/1093] time: 11513.0660, d_loss: 1.0903, g_loss: 0.9449\n",
      "[Sample] d_loss: 1.01247883, g_loss: 0.95636040\n",
      "Epoch: [16] [  20/1093] time: 11517.0525, d_loss: 1.0629, g_loss: 0.9183\n",
      "[Sample] d_loss: 1.02210438, g_loss: 0.96745956\n",
      "Epoch: [16] [  30/1093] time: 11521.0310, d_loss: 1.0576, g_loss: 0.9579\n",
      "[Sample] d_loss: 1.00169849, g_loss: 0.97607255\n",
      "Epoch: [16] [  40/1093] time: 11524.9921, d_loss: 1.0102, g_loss: 0.9494\n",
      "[Sample] d_loss: 0.98734426, g_loss: 0.99241543\n",
      "Epoch: [16] [  50/1093] time: 11528.9249, d_loss: 1.0339, g_loss: 0.9841\n",
      "[Sample] d_loss: 0.97935903, g_loss: 1.02372122\n",
      "Epoch: [16] [  60/1093] time: 11532.8655, d_loss: 0.9835, g_loss: 0.9815\n",
      "[Sample] d_loss: 0.97067988, g_loss: 1.01317978\n",
      "Epoch: [16] [  70/1093] time: 11536.7969, d_loss: 1.0460, g_loss: 0.9915\n",
      "[Sample] d_loss: 0.97742665, g_loss: 1.00464070\n",
      "Epoch: [16] [  80/1093] time: 11540.7270, d_loss: 1.0371, g_loss: 0.9607\n",
      "[Sample] d_loss: 0.96816635, g_loss: 1.00448906\n",
      "Epoch: [16] [  90/1093] time: 11544.6675, d_loss: 1.0690, g_loss: 0.9491\n",
      "[Sample] d_loss: 0.99219769, g_loss: 0.96632147\n",
      "Epoch: [16] [ 100/1093] time: 11548.5938, d_loss: 1.0793, g_loss: 0.9533\n",
      "[Sample] d_loss: 0.99306023, g_loss: 0.96834749\n",
      "Epoch: [16] [ 110/1093] time: 11552.5507, d_loss: 0.9893, g_loss: 0.9532\n",
      "[Sample] d_loss: 1.01587856, g_loss: 0.93953258\n",
      "Epoch: [16] [ 120/1093] time: 11556.4930, d_loss: 0.9841, g_loss: 0.9469\n",
      "[Sample] d_loss: 1.01045084, g_loss: 0.95176202\n",
      "Epoch: [16] [ 130/1093] time: 11560.4217, d_loss: 1.0655, g_loss: 0.9289\n",
      "[Sample] d_loss: 1.00350213, g_loss: 0.94698918\n",
      "Epoch: [16] [ 140/1093] time: 11564.3583, d_loss: 1.0362, g_loss: 0.9680\n",
      "[Sample] d_loss: 1.01023304, g_loss: 0.94913918\n",
      "Epoch: [16] [ 150/1093] time: 11568.2946, d_loss: 1.0609, g_loss: 0.9374\n",
      "[Sample] d_loss: 1.00939989, g_loss: 0.94282252\n",
      "Epoch: [16] [ 160/1093] time: 11572.2669, d_loss: 0.9736, g_loss: 0.9972\n",
      "[Sample] d_loss: 1.00798631, g_loss: 0.95251477\n",
      "Epoch: [16] [ 170/1093] time: 11576.1800, d_loss: 1.0512, g_loss: 0.9419\n",
      "[Sample] d_loss: 0.99511999, g_loss: 0.96474373\n",
      "Epoch: [16] [ 180/1093] time: 11580.1146, d_loss: 1.0422, g_loss: 0.9494\n",
      "[Sample] d_loss: 0.99769211, g_loss: 0.95305061\n",
      "Epoch: [16] [ 190/1093] time: 11584.0535, d_loss: 1.0275, g_loss: 0.9678\n",
      "[Sample] d_loss: 0.98561275, g_loss: 0.97093636\n",
      "Epoch: [16] [ 200/1093] time: 11587.9690, d_loss: 1.0407, g_loss: 0.9838\n",
      "[Sample] d_loss: 0.99341756, g_loss: 0.96623409\n",
      "Epoch: [16] [ 210/1093] time: 11591.9353, d_loss: 1.0165, g_loss: 0.9320\n",
      "[Sample] d_loss: 0.97058105, g_loss: 0.99904132\n",
      "Epoch: [16] [ 220/1093] time: 11595.9980, d_loss: 0.9926, g_loss: 0.9692\n",
      "[Sample] d_loss: 0.98268878, g_loss: 0.97481465\n",
      "Epoch: [16] [ 230/1093] time: 11599.9491, d_loss: 1.0068, g_loss: 0.9347\n",
      "[Sample] d_loss: 0.99258608, g_loss: 0.96024108\n",
      "Epoch: [16] [ 240/1093] time: 11603.8978, d_loss: 0.9471, g_loss: 0.9543\n",
      "[Sample] d_loss: 0.99141538, g_loss: 0.96837378\n",
      "Epoch: [16] [ 250/1093] time: 11608.1251, d_loss: 1.0323, g_loss: 0.9973\n",
      "[Sample] d_loss: 0.97618943, g_loss: 1.00545239\n",
      "Epoch: [16] [ 260/1093] time: 11613.7477, d_loss: 1.0514, g_loss: 0.9490\n",
      "[Sample] d_loss: 0.96889865, g_loss: 1.01154542\n",
      "Epoch: [16] [ 270/1093] time: 11618.9630, d_loss: 1.0048, g_loss: 0.9580\n",
      "[Sample] d_loss: 0.96204287, g_loss: 0.99650669\n",
      "Epoch: [16] [ 280/1093] time: 11624.2321, d_loss: 0.9976, g_loss: 0.9401\n",
      "[Sample] d_loss: 0.97753346, g_loss: 0.98461330\n",
      "Epoch: [16] [ 290/1093] time: 11629.8469, d_loss: 1.0932, g_loss: 0.9240\n",
      "[Sample] d_loss: 0.98431504, g_loss: 0.98708439\n",
      "Epoch: [16] [ 300/1093] time: 11635.1499, d_loss: 0.9967, g_loss: 0.9864\n",
      "[Sample] d_loss: 0.98680210, g_loss: 0.97012085\n",
      "Epoch: [16] [ 310/1093] time: 11640.8290, d_loss: 1.0553, g_loss: 0.9533\n",
      "[Sample] d_loss: 1.00076389, g_loss: 0.94958866\n",
      "Epoch: [16] [ 320/1093] time: 11646.5102, d_loss: 1.0022, g_loss: 0.9356\n",
      "[Sample] d_loss: 0.98762834, g_loss: 0.96831429\n",
      "Epoch: [16] [ 330/1093] time: 11653.6170, d_loss: 0.9468, g_loss: 0.9475\n",
      "[Sample] d_loss: 0.98006839, g_loss: 0.98286420\n",
      "Epoch: [16] [ 340/1093] time: 11659.6897, d_loss: 1.0416, g_loss: 0.9302\n",
      "[Sample] d_loss: 0.96518898, g_loss: 1.00202060\n",
      "Epoch: [16] [ 350/1093] time: 11665.0010, d_loss: 1.0031, g_loss: 0.9462\n",
      "[Sample] d_loss: 0.99295413, g_loss: 0.97420895\n",
      "Epoch: [16] [ 360/1093] time: 11670.2573, d_loss: 1.0061, g_loss: 0.9785\n",
      "[Sample] d_loss: 0.99113619, g_loss: 0.97232461\n",
      "Epoch: [16] [ 370/1093] time: 11676.1141, d_loss: 0.9456, g_loss: 0.9831\n",
      "[Sample] d_loss: 0.97339779, g_loss: 1.00432825\n",
      "Epoch: [16] [ 380/1093] time: 11681.5098, d_loss: 0.9819, g_loss: 0.9539\n",
      "[Sample] d_loss: 0.97858500, g_loss: 0.98657727\n",
      "Epoch: [16] [ 390/1093] time: 11687.0572, d_loss: 0.9458, g_loss: 0.9901\n",
      "[Sample] d_loss: 0.99315274, g_loss: 0.98797882\n",
      "Epoch: [16] [ 400/1093] time: 11692.6316, d_loss: 0.9495, g_loss: 0.9929\n",
      "[Sample] d_loss: 0.97694182, g_loss: 1.00372863\n",
      "Epoch: [16] [ 410/1093] time: 11697.9167, d_loss: 0.9829, g_loss: 1.0002\n",
      "[Sample] d_loss: 0.97586548, g_loss: 0.98999268\n",
      "Epoch: [16] [ 420/1093] time: 11703.2273, d_loss: 0.9981, g_loss: 0.9870\n",
      "[Sample] d_loss: 0.98466170, g_loss: 0.99081051\n",
      "Epoch: [16] [ 430/1093] time: 11708.5916, d_loss: 1.0513, g_loss: 0.9600\n",
      "[Sample] d_loss: 0.97108877, g_loss: 0.99881703\n",
      "Epoch: [16] [ 440/1093] time: 11713.8693, d_loss: 0.9898, g_loss: 0.9710\n",
      "[Sample] d_loss: 0.98255175, g_loss: 0.98591799\n",
      "Epoch: [16] [ 450/1093] time: 11720.1338, d_loss: 1.0135, g_loss: 0.9959\n",
      "[Sample] d_loss: 0.98319274, g_loss: 0.96688735\n",
      "Epoch: [16] [ 460/1093] time: 11726.6515, d_loss: 0.9545, g_loss: 0.9849\n",
      "[Sample] d_loss: 0.97881526, g_loss: 0.97268444\n",
      "Epoch: [16] [ 470/1093] time: 11733.4002, d_loss: 0.9644, g_loss: 1.0057\n",
      "[Sample] d_loss: 0.98247361, g_loss: 0.95916665\n",
      "Epoch: [16] [ 480/1093] time: 11740.5228, d_loss: 0.9567, g_loss: 0.9729\n",
      "[Sample] d_loss: 0.96672994, g_loss: 0.98766685\n",
      "Epoch: [16] [ 490/1093] time: 11746.5194, d_loss: 0.9988, g_loss: 0.9880\n",
      "[Sample] d_loss: 0.96385449, g_loss: 1.00767529\n",
      "Epoch: [16] [ 500/1093] time: 11752.5197, d_loss: 0.9762, g_loss: 0.9591\n",
      "[Sample] d_loss: 0.95701134, g_loss: 1.02005780\n",
      "Epoch: [16] [ 510/1093] time: 11759.3566, d_loss: 0.9836, g_loss: 1.0063\n",
      "[Sample] d_loss: 0.94716227, g_loss: 1.04992104\n",
      "Epoch: [16] [ 520/1093] time: 11765.6094, d_loss: 0.9996, g_loss: 0.9844\n",
      "[Sample] d_loss: 0.95856404, g_loss: 1.01541364\n",
      "Epoch: [16] [ 530/1093] time: 11772.1536, d_loss: 0.9732, g_loss: 1.0157\n",
      "[Sample] d_loss: 0.94457328, g_loss: 1.03270900\n",
      "Epoch: [16] [ 540/1093] time: 11778.0678, d_loss: 0.9900, g_loss: 0.9815\n",
      "[Sample] d_loss: 0.94900870, g_loss: 1.01698422\n",
      "Epoch: [16] [ 550/1093] time: 11783.8179, d_loss: 0.9553, g_loss: 0.9957\n",
      "[Sample] d_loss: 0.94654709, g_loss: 1.02435875\n",
      "Epoch: [16] [ 560/1093] time: 11790.2427, d_loss: 0.9845, g_loss: 1.0172\n",
      "[Sample] d_loss: 0.97051537, g_loss: 0.98759031\n",
      "Epoch: [16] [ 570/1093] time: 11794.9153, d_loss: 1.0221, g_loss: 1.0070\n",
      "[Sample] d_loss: 0.94562149, g_loss: 1.02971959\n",
      "Epoch: [16] [ 580/1093] time: 11799.3940, d_loss: 0.9578, g_loss: 0.9897\n",
      "[Sample] d_loss: 0.93165648, g_loss: 1.04340816\n",
      "Epoch: [16] [ 590/1093] time: 11803.8029, d_loss: 0.9535, g_loss: 0.9493\n",
      "[Sample] d_loss: 0.96042407, g_loss: 0.98752791\n",
      "Epoch: [16] [ 600/1093] time: 11807.8502, d_loss: 0.9437, g_loss: 0.9623\n",
      "[Sample] d_loss: 0.95881939, g_loss: 1.00768173\n",
      "Epoch: [16] [ 610/1093] time: 11812.0145, d_loss: 0.9631, g_loss: 1.0440\n",
      "[Sample] d_loss: 0.94553769, g_loss: 1.02522111\n",
      "Epoch: [16] [ 620/1093] time: 11816.3746, d_loss: 0.9583, g_loss: 1.0088\n",
      "[Sample] d_loss: 0.94005996, g_loss: 1.02251625\n",
      "Epoch: [16] [ 630/1093] time: 11820.7650, d_loss: 1.0571, g_loss: 0.9752\n",
      "[Sample] d_loss: 0.94183683, g_loss: 1.02287793\n",
      "Epoch: [16] [ 640/1093] time: 11825.1643, d_loss: 1.0433, g_loss: 0.9840\n",
      "[Sample] d_loss: 0.94303024, g_loss: 1.00948882\n",
      "Epoch: [16] [ 650/1093] time: 11829.5583, d_loss: 0.9754, g_loss: 0.9785\n",
      "[Sample] d_loss: 0.94470507, g_loss: 1.02511406\n",
      "Epoch: [16] [ 660/1093] time: 11833.8668, d_loss: 1.0107, g_loss: 0.9925\n",
      "[Sample] d_loss: 0.94412953, g_loss: 1.00198054\n",
      "Epoch: [16] [ 670/1093] time: 11838.0855, d_loss: 0.9487, g_loss: 1.0078\n",
      "[Sample] d_loss: 0.93539518, g_loss: 1.02172804\n",
      "Epoch: [16] [ 680/1093] time: 11842.3287, d_loss: 0.9571, g_loss: 1.0158\n",
      "[Sample] d_loss: 0.91856503, g_loss: 1.05459535\n",
      "Epoch: [16] [ 690/1093] time: 11846.4549, d_loss: 0.9533, g_loss: 1.0074\n",
      "[Sample] d_loss: 0.92569834, g_loss: 1.03258967\n",
      "Epoch: [16] [ 700/1093] time: 11850.5049, d_loss: 1.0057, g_loss: 1.0117\n",
      "[Sample] d_loss: 0.92565346, g_loss: 1.01547909\n",
      "Epoch: [16] [ 710/1093] time: 11854.6180, d_loss: 0.9618, g_loss: 1.0375\n",
      "[Sample] d_loss: 0.90611869, g_loss: 1.05370259\n",
      "Epoch: [16] [ 720/1093] time: 11858.7658, d_loss: 1.0202, g_loss: 1.0245\n",
      "[Sample] d_loss: 0.91137552, g_loss: 1.06125450\n",
      "Epoch: [16] [ 730/1093] time: 11862.7622, d_loss: 0.9632, g_loss: 1.0088\n",
      "[Sample] d_loss: 0.90468347, g_loss: 1.05773270\n",
      "Epoch: [16] [ 740/1093] time: 11867.0808, d_loss: 0.9726, g_loss: 1.0653\n",
      "[Sample] d_loss: 0.91341823, g_loss: 1.05823755\n",
      "Epoch: [16] [ 750/1093] time: 11871.8536, d_loss: 0.9446, g_loss: 1.0168\n",
      "[Sample] d_loss: 0.92467195, g_loss: 1.03141809\n",
      "Epoch: [16] [ 760/1093] time: 11875.8373, d_loss: 0.9240, g_loss: 1.0377\n",
      "[Sample] d_loss: 0.92606807, g_loss: 1.03228164\n",
      "Epoch: [16] [ 770/1093] time: 11879.8529, d_loss: 0.9800, g_loss: 1.0491\n",
      "[Sample] d_loss: 0.90118927, g_loss: 1.06175661\n",
      "Epoch: [16] [ 780/1093] time: 11883.9433, d_loss: 0.9165, g_loss: 1.0625\n",
      "[Sample] d_loss: 0.88841665, g_loss: 1.07256222\n",
      "Epoch: [16] [ 790/1093] time: 11888.2378, d_loss: 0.8917, g_loss: 1.0231\n",
      "[Sample] d_loss: 0.93002534, g_loss: 1.00822663\n",
      "Epoch: [16] [ 800/1093] time: 11892.3336, d_loss: 0.8718, g_loss: 1.0449\n",
      "[Sample] d_loss: 0.91217291, g_loss: 1.03812432\n",
      "Epoch: [16] [ 810/1093] time: 11896.2819, d_loss: 0.8947, g_loss: 1.0152\n",
      "[Sample] d_loss: 0.91370237, g_loss: 1.05206776\n",
      "Epoch: [16] [ 820/1093] time: 11900.4722, d_loss: 0.9744, g_loss: 1.0014\n",
      "[Sample] d_loss: 0.93449372, g_loss: 1.02506554\n",
      "Epoch: [16] [ 830/1093] time: 11904.4553, d_loss: 1.0469, g_loss: 1.0003\n",
      "[Sample] d_loss: 0.95511377, g_loss: 0.99640924\n",
      "Epoch: [16] [ 840/1093] time: 11908.3987, d_loss: 0.9591, g_loss: 0.9959\n",
      "[Sample] d_loss: 0.93990064, g_loss: 1.02120149\n",
      "Epoch: [16] [ 850/1093] time: 11912.3567, d_loss: 0.9921, g_loss: 0.9938\n",
      "[Sample] d_loss: 0.94902766, g_loss: 1.02211261\n",
      "Epoch: [16] [ 860/1093] time: 11916.3136, d_loss: 0.9253, g_loss: 1.0040\n",
      "[Sample] d_loss: 0.91720575, g_loss: 1.04551554\n",
      "Epoch: [16] [ 870/1093] time: 11920.2540, d_loss: 0.9234, g_loss: 1.0224\n",
      "[Sample] d_loss: 0.94484913, g_loss: 1.01391816\n",
      "Epoch: [16] [ 880/1093] time: 11924.1788, d_loss: 0.8827, g_loss: 0.9779\n",
      "[Sample] d_loss: 0.93764180, g_loss: 1.02020025\n",
      "Epoch: [16] [ 890/1093] time: 11928.1327, d_loss: 0.9597, g_loss: 1.0220\n",
      "[Sample] d_loss: 0.91949475, g_loss: 1.04673219\n",
      "Epoch: [16] [ 900/1093] time: 11932.1661, d_loss: 0.9505, g_loss: 0.9930\n",
      "[Sample] d_loss: 0.94940519, g_loss: 1.01110923\n",
      "Epoch: [16] [ 910/1093] time: 11936.1022, d_loss: 1.0720, g_loss: 1.0144\n",
      "[Sample] d_loss: 0.93895578, g_loss: 1.01259804\n",
      "Epoch: [16] [ 920/1093] time: 11940.0184, d_loss: 0.9968, g_loss: 1.0456\n",
      "[Sample] d_loss: 0.92408288, g_loss: 1.05927896\n",
      "Epoch: [16] [ 930/1093] time: 11943.9896, d_loss: 0.9780, g_loss: 1.0067\n",
      "[Sample] d_loss: 0.93767995, g_loss: 1.03144646\n",
      "Epoch: [16] [ 940/1093] time: 11948.1139, d_loss: 0.8986, g_loss: 1.0121\n",
      "[Sample] d_loss: 0.95711291, g_loss: 1.00764441\n",
      "Epoch: [16] [ 950/1093] time: 11952.1963, d_loss: 0.9842, g_loss: 1.0048\n",
      "[Sample] d_loss: 0.94411016, g_loss: 1.02115083\n",
      "Epoch: [16] [ 960/1093] time: 11956.1892, d_loss: 1.0064, g_loss: 1.0096\n",
      "[Sample] d_loss: 0.95151818, g_loss: 1.01289988\n",
      "Epoch: [16] [ 970/1093] time: 11960.1659, d_loss: 0.9237, g_loss: 1.0199\n",
      "[Sample] d_loss: 0.94414455, g_loss: 1.00688720\n",
      "Epoch: [16] [ 980/1093] time: 11964.1283, d_loss: 0.9492, g_loss: 1.0300\n",
      "[Sample] d_loss: 0.93949091, g_loss: 1.01964045\n",
      "Epoch: [16] [ 990/1093] time: 11968.1056, d_loss: 0.9987, g_loss: 1.0213\n",
      "[Sample] d_loss: 0.92480898, g_loss: 1.03376067\n",
      "Epoch: [16] [1000/1093] time: 11972.1567, d_loss: 0.9693, g_loss: 0.9991\n",
      "[Sample] d_loss: 0.94437027, g_loss: 1.02297711\n",
      "Epoch: [16] [1010/1093] time: 11976.2006, d_loss: 1.0121, g_loss: 1.0315\n",
      "[Sample] d_loss: 0.93525982, g_loss: 1.01206136\n",
      "Epoch: [16] [1020/1093] time: 11980.2466, d_loss: 0.9429, g_loss: 1.0278\n",
      "[Sample] d_loss: 0.93592763, g_loss: 1.01829576\n",
      "Epoch: [16] [1030/1093] time: 11984.2025, d_loss: 0.9401, g_loss: 1.0251\n",
      "[Sample] d_loss: 0.94651139, g_loss: 1.00768793\n",
      "Epoch: [16] [1040/1093] time: 11988.1904, d_loss: 0.8827, g_loss: 1.0358\n",
      "[Sample] d_loss: 0.93101662, g_loss: 1.02047360\n",
      "Epoch: [16] [1050/1093] time: 11992.2076, d_loss: 0.9418, g_loss: 1.0153\n",
      "[Sample] d_loss: 0.92315614, g_loss: 1.04108047\n",
      "Epoch: [16] [1060/1093] time: 11996.1255, d_loss: 0.9230, g_loss: 1.0403\n",
      "[Sample] d_loss: 0.91839248, g_loss: 1.04443479\n",
      "Epoch: [16] [1070/1093] time: 12000.2877, d_loss: 0.9471, g_loss: 1.0136\n",
      "[Sample] d_loss: 0.91559744, g_loss: 1.05609739\n",
      "Epoch: [16] [1080/1093] time: 12004.8700, d_loss: 0.9417, g_loss: 1.0284\n",
      "[Sample] d_loss: 0.91159582, g_loss: 1.05765033\n",
      "Epoch: [16] [1090/1093] time: 12009.3460, d_loss: 0.8986, g_loss: 1.0607\n",
      "[Sample] d_loss: 0.90243697, g_loss: 1.05956304\n",
      "[Sample] d_loss: 0.89548051, g_loss: 1.06768155\n",
      "Epoch: [17] [   7/1093] time: 12013.7930, d_loss: 0.9484, g_loss: 1.0502\n",
      "[Sample] d_loss: 0.89102632, g_loss: 1.07384801\n",
      "Epoch: [17] [  17/1093] time: 12018.6670, d_loss: 0.8967, g_loss: 0.9954\n",
      "[Sample] d_loss: 0.90517706, g_loss: 1.06172347\n",
      "Epoch: [17] [  27/1093] time: 12023.2819, d_loss: 0.9126, g_loss: 1.0395\n",
      "[Sample] d_loss: 0.91077638, g_loss: 1.05600584\n",
      "Epoch: [17] [  37/1093] time: 12028.0235, d_loss: 0.9186, g_loss: 1.0285\n",
      "[Sample] d_loss: 0.91627014, g_loss: 1.05099249\n",
      "Epoch: [17] [  47/1093] time: 12032.3678, d_loss: 0.9315, g_loss: 1.0488\n",
      "[Sample] d_loss: 0.90856308, g_loss: 1.07292020\n",
      "Epoch: [17] [  57/1093] time: 12036.4829, d_loss: 0.9615, g_loss: 1.0527\n",
      "[Sample] d_loss: 0.89769828, g_loss: 1.08562338\n",
      "Epoch: [17] [  67/1093] time: 12040.6058, d_loss: 0.9274, g_loss: 1.0697\n",
      "[Sample] d_loss: 0.92999840, g_loss: 1.02680695\n",
      "Epoch: [17] [  77/1093] time: 12044.8281, d_loss: 0.9003, g_loss: 1.0539\n",
      "[Sample] d_loss: 0.90824562, g_loss: 1.04695916\n",
      "Epoch: [17] [  87/1093] time: 12049.5567, d_loss: 0.9910, g_loss: 1.0517\n",
      "[Sample] d_loss: 0.90298104, g_loss: 1.06132507\n",
      "Epoch: [17] [  97/1093] time: 12054.1511, d_loss: 0.9752, g_loss: 1.0796\n",
      "[Sample] d_loss: 0.90334809, g_loss: 1.06419230\n",
      "Epoch: [17] [ 107/1093] time: 12058.9134, d_loss: 0.9706, g_loss: 1.0498\n",
      "[Sample] d_loss: 0.92029238, g_loss: 1.04467916\n",
      "Epoch: [17] [ 117/1093] time: 12064.3464, d_loss: 0.8827, g_loss: 1.0455\n",
      "[Sample] d_loss: 0.93055820, g_loss: 1.02623880\n",
      "Epoch: [17] [ 127/1093] time: 12068.4740, d_loss: 0.9256, g_loss: 1.0455\n",
      "[Sample] d_loss: 0.93060476, g_loss: 1.01885808\n",
      "Epoch: [17] [ 137/1093] time: 12072.6355, d_loss: 0.9176, g_loss: 1.0323\n",
      "[Sample] d_loss: 0.93096852, g_loss: 1.02472854\n",
      "Epoch: [17] [ 147/1093] time: 12076.7930, d_loss: 0.9078, g_loss: 1.0563\n",
      "[Sample] d_loss: 0.90623116, g_loss: 1.06134784\n",
      "Epoch: [17] [ 157/1093] time: 12080.9525, d_loss: 0.9190, g_loss: 1.0586\n",
      "[Sample] d_loss: 0.90941954, g_loss: 1.03667438\n",
      "Epoch: [17] [ 167/1093] time: 12085.1195, d_loss: 0.9757, g_loss: 1.0495\n",
      "[Sample] d_loss: 0.91285276, g_loss: 1.05049944\n",
      "Epoch: [17] [ 177/1093] time: 12089.3301, d_loss: 0.9310, g_loss: 1.0373\n",
      "[Sample] d_loss: 0.91171223, g_loss: 1.04731131\n",
      "Epoch: [17] [ 187/1093] time: 12093.4451, d_loss: 0.9296, g_loss: 1.0504\n",
      "[Sample] d_loss: 0.91050124, g_loss: 1.04104567\n",
      "Epoch: [17] [ 197/1093] time: 12097.6187, d_loss: 0.8811, g_loss: 1.0431\n",
      "[Sample] d_loss: 0.89865541, g_loss: 1.06787109\n",
      "Epoch: [17] [ 207/1093] time: 12101.7367, d_loss: 0.9678, g_loss: 1.0537\n",
      "[Sample] d_loss: 0.88708293, g_loss: 1.09160709\n",
      "Epoch: [17] [ 217/1093] time: 12105.9464, d_loss: 0.8932, g_loss: 1.0450\n",
      "[Sample] d_loss: 0.90102452, g_loss: 1.06329942\n",
      "Epoch: [17] [ 227/1093] time: 12110.0692, d_loss: 0.9113, g_loss: 1.0220\n",
      "[Sample] d_loss: 0.88370734, g_loss: 1.09317851\n",
      "Epoch: [17] [ 237/1093] time: 12114.2113, d_loss: 0.8756, g_loss: 1.0739\n",
      "[Sample] d_loss: 0.89908773, g_loss: 1.07215893\n",
      "Epoch: [17] [ 247/1093] time: 12118.3895, d_loss: 0.9013, g_loss: 1.0143\n",
      "[Sample] d_loss: 0.90701210, g_loss: 1.05425417\n",
      "Epoch: [17] [ 257/1093] time: 12122.6294, d_loss: 0.9002, g_loss: 1.0603\n",
      "[Sample] d_loss: 0.89440066, g_loss: 1.05803621\n",
      "Epoch: [17] [ 267/1093] time: 12126.8183, d_loss: 0.9235, g_loss: 1.0415\n",
      "[Sample] d_loss: 0.89069963, g_loss: 1.06917071\n",
      "Epoch: [17] [ 277/1093] time: 12131.0466, d_loss: 0.9766, g_loss: 1.0468\n",
      "[Sample] d_loss: 0.88219178, g_loss: 1.08968520\n",
      "Epoch: [17] [ 287/1093] time: 12135.2201, d_loss: 0.9534, g_loss: 1.0360\n",
      "[Sample] d_loss: 0.90401816, g_loss: 1.04901838\n",
      "Epoch: [17] [ 297/1093] time: 12139.3319, d_loss: 0.9270, g_loss: 1.0263\n",
      "[Sample] d_loss: 0.87967777, g_loss: 1.08362532\n",
      "Epoch: [17] [ 307/1093] time: 12143.4659, d_loss: 0.8886, g_loss: 1.0694\n",
      "[Sample] d_loss: 0.90089786, g_loss: 1.07772088\n",
      "Epoch: [17] [ 317/1093] time: 12147.5886, d_loss: 0.9088, g_loss: 1.0767\n",
      "[Sample] d_loss: 0.89228010, g_loss: 1.08440280\n",
      "Epoch: [17] [ 327/1093] time: 12151.9108, d_loss: 0.9932, g_loss: 1.0471\n",
      "[Sample] d_loss: 0.90095639, g_loss: 1.07102287\n",
      "Epoch: [17] [ 337/1093] time: 12156.1664, d_loss: 0.9311, g_loss: 1.0963\n",
      "[Sample] d_loss: 0.90527487, g_loss: 1.08080053\n",
      "Epoch: [17] [ 347/1093] time: 12160.2371, d_loss: 0.8989, g_loss: 1.0358\n",
      "[Sample] d_loss: 0.90196991, g_loss: 1.08066964\n",
      "Epoch: [17] [ 357/1093] time: 12164.3289, d_loss: 0.9245, g_loss: 1.0839\n",
      "[Sample] d_loss: 0.89546400, g_loss: 1.05306840\n",
      "Epoch: [17] [ 367/1093] time: 12168.4233, d_loss: 0.8887, g_loss: 1.0612\n",
      "[Sample] d_loss: 0.89242661, g_loss: 1.06991053\n",
      "Epoch: [17] [ 377/1093] time: 12172.5418, d_loss: 0.8603, g_loss: 1.0739\n",
      "[Sample] d_loss: 0.87864071, g_loss: 1.08175731\n",
      "Epoch: [17] [ 387/1093] time: 12176.6113, d_loss: 0.8483, g_loss: 1.0740\n",
      "[Sample] d_loss: 0.87864584, g_loss: 1.09165955\n",
      "Epoch: [17] [ 397/1093] time: 12180.9104, d_loss: 0.8960, g_loss: 1.0462\n",
      "[Sample] d_loss: 0.90073621, g_loss: 1.06217384\n",
      "Epoch: [17] [ 407/1093] time: 12185.5606, d_loss: 0.9098, g_loss: 1.0613\n",
      "[Sample] d_loss: 0.89487439, g_loss: 1.07455873\n",
      "Epoch: [17] [ 417/1093] time: 12189.8481, d_loss: 0.9444, g_loss: 1.0461\n",
      "[Sample] d_loss: 0.90105170, g_loss: 1.04937387\n",
      "Epoch: [17] [ 427/1093] time: 12194.1084, d_loss: 0.8794, g_loss: 1.0489\n",
      "[Sample] d_loss: 0.90341169, g_loss: 1.05808806\n",
      "Epoch: [17] [ 437/1093] time: 12198.2499, d_loss: 0.9403, g_loss: 1.0819\n",
      "[Sample] d_loss: 0.85910034, g_loss: 1.11445355\n",
      "Epoch: [17] [ 447/1093] time: 12202.4437, d_loss: 0.8711, g_loss: 1.0502\n",
      "[Sample] d_loss: 0.88231158, g_loss: 1.08408070\n",
      "Epoch: [17] [ 457/1093] time: 12206.5553, d_loss: 0.8948, g_loss: 1.0698\n",
      "[Sample] d_loss: 0.86617672, g_loss: 1.11636925\n",
      "Epoch: [17] [ 467/1093] time: 12210.6045, d_loss: 0.8973, g_loss: 1.0479\n",
      "[Sample] d_loss: 0.85377222, g_loss: 1.11376703\n",
      "Epoch: [17] [ 477/1093] time: 12214.6979, d_loss: 0.9281, g_loss: 1.0404\n",
      "[Sample] d_loss: 0.88538855, g_loss: 1.07339239\n",
      "Epoch: [17] [ 487/1093] time: 12218.7802, d_loss: 0.9114, g_loss: 1.0411\n",
      "[Sample] d_loss: 0.89062810, g_loss: 1.06073070\n",
      "Epoch: [17] [ 497/1093] time: 12222.8767, d_loss: 0.9374, g_loss: 1.0442\n",
      "[Sample] d_loss: 0.88999057, g_loss: 1.07713509\n",
      "Epoch: [17] [ 507/1093] time: 12226.9645, d_loss: 0.9595, g_loss: 1.0550\n",
      "[Sample] d_loss: 0.88378924, g_loss: 1.09503031\n",
      "Epoch: [17] [ 517/1093] time: 12231.1104, d_loss: 0.9012, g_loss: 1.0485\n",
      "[Sample] d_loss: 0.87457395, g_loss: 1.09810245\n",
      "Epoch: [17] [ 527/1093] time: 12235.2039, d_loss: 0.8787, g_loss: 1.0482\n",
      "[Sample] d_loss: 0.86861169, g_loss: 1.09223938\n",
      "Epoch: [17] [ 537/1093] time: 12239.2928, d_loss: 0.9241, g_loss: 1.0475\n",
      "[Sample] d_loss: 0.87010741, g_loss: 1.09488690\n",
      "Epoch: [17] [ 547/1093] time: 12243.4003, d_loss: 0.9013, g_loss: 1.0679\n",
      "[Sample] d_loss: 0.86053395, g_loss: 1.08882594\n",
      "Epoch: [17] [ 557/1093] time: 12247.6361, d_loss: 0.8924, g_loss: 1.0496\n",
      "[Sample] d_loss: 0.85933805, g_loss: 1.09590864\n",
      "Epoch: [17] [ 567/1093] time: 12251.8249, d_loss: 0.9092, g_loss: 1.0557\n",
      "[Sample] d_loss: 0.87848318, g_loss: 1.07987273\n",
      "Epoch: [17] [ 577/1093] time: 12256.0351, d_loss: 0.9241, g_loss: 1.0785\n",
      "[Sample] d_loss: 0.87189722, g_loss: 1.09291553\n",
      "Epoch: [17] [ 587/1093] time: 12260.2359, d_loss: 1.0162, g_loss: 1.0756\n",
      "[Sample] d_loss: 0.85976964, g_loss: 1.08997250\n",
      "Epoch: [17] [ 597/1093] time: 12264.3003, d_loss: 0.8768, g_loss: 1.0757\n",
      "[Sample] d_loss: 0.86413670, g_loss: 1.07647824\n",
      "Epoch: [17] [ 607/1093] time: 12268.3805, d_loss: 0.9140, g_loss: 1.0644\n",
      "[Sample] d_loss: 0.85391390, g_loss: 1.10299134\n",
      "Epoch: [17] [ 617/1093] time: 12272.5088, d_loss: 0.9172, g_loss: 1.1078\n",
      "[Sample] d_loss: 0.87040198, g_loss: 1.07112670\n",
      "Epoch: [17] [ 627/1093] time: 12276.6931, d_loss: 0.8969, g_loss: 1.0581\n",
      "[Sample] d_loss: 0.86734760, g_loss: 1.08525801\n",
      "Epoch: [17] [ 637/1093] time: 12280.8386, d_loss: 0.8794, g_loss: 1.0667\n",
      "[Sample] d_loss: 0.86485469, g_loss: 1.05767751\n",
      "Epoch: [17] [ 647/1093] time: 12284.9375, d_loss: 0.9132, g_loss: 1.0653\n",
      "[Sample] d_loss: 0.85510123, g_loss: 1.09514451\n",
      "Epoch: [17] [ 657/1093] time: 12289.0050, d_loss: 0.8527, g_loss: 1.0975\n",
      "[Sample] d_loss: 0.85561979, g_loss: 1.09284425\n",
      "Epoch: [17] [ 667/1093] time: 12293.4791, d_loss: 0.8889, g_loss: 1.0560\n",
      "[Sample] d_loss: 0.87798852, g_loss: 1.08555460\n",
      "Epoch: [17] [ 677/1093] time: 12297.6373, d_loss: 0.9126, g_loss: 1.0849\n",
      "[Sample] d_loss: 0.88061643, g_loss: 1.05428374\n",
      "Epoch: [17] [ 687/1093] time: 12301.7859, d_loss: 0.8903, g_loss: 1.0586\n",
      "[Sample] d_loss: 0.86823356, g_loss: 1.06833696\n",
      "Epoch: [17] [ 697/1093] time: 12305.9047, d_loss: 0.8872, g_loss: 1.0601\n",
      "[Sample] d_loss: 0.85759163, g_loss: 1.08092070\n",
      "Epoch: [17] [ 707/1093] time: 12310.0479, d_loss: 0.8920, g_loss: 1.0535\n",
      "[Sample] d_loss: 0.86688012, g_loss: 1.06980026\n",
      "Epoch: [17] [ 717/1093] time: 12314.2396, d_loss: 0.8246, g_loss: 1.0718\n",
      "[Sample] d_loss: 0.86110306, g_loss: 1.11368608\n",
      "Epoch: [17] [ 727/1093] time: 12318.4839, d_loss: 0.9303, g_loss: 1.0529\n",
      "[Sample] d_loss: 0.84287876, g_loss: 1.10951054\n",
      "Epoch: [17] [ 737/1093] time: 12322.5715, d_loss: 0.8319, g_loss: 1.1122\n",
      "[Sample] d_loss: 0.85507166, g_loss: 1.09561181\n",
      "Epoch: [17] [ 747/1093] time: 12326.8298, d_loss: 0.8773, g_loss: 1.0932\n",
      "[Sample] d_loss: 0.84868175, g_loss: 1.09751260\n",
      "Epoch: [17] [ 757/1093] time: 12330.9012, d_loss: 0.9069, g_loss: 1.0756\n",
      "[Sample] d_loss: 0.83920217, g_loss: 1.10107481\n",
      "Epoch: [17] [ 767/1093] time: 12335.0254, d_loss: 0.8263, g_loss: 1.0738\n",
      "[Sample] d_loss: 0.85783052, g_loss: 1.05792236\n",
      "Epoch: [17] [ 777/1093] time: 12339.1378, d_loss: 0.9308, g_loss: 1.0897\n",
      "[Sample] d_loss: 0.85257417, g_loss: 1.09262395\n",
      "Epoch: [17] [ 787/1093] time: 12343.2586, d_loss: 0.8811, g_loss: 1.0731\n",
      "[Sample] d_loss: 0.83848387, g_loss: 1.09763098\n",
      "Epoch: [17] [ 797/1093] time: 12347.5182, d_loss: 0.8452, g_loss: 1.0901\n",
      "[Sample] d_loss: 0.87075675, g_loss: 1.08367610\n",
      "Epoch: [17] [ 807/1093] time: 12351.7995, d_loss: 0.9623, g_loss: 1.0610\n",
      "[Sample] d_loss: 0.84079456, g_loss: 1.11736774\n",
      "Epoch: [17] [ 817/1093] time: 12355.9332, d_loss: 0.8701, g_loss: 1.0869\n",
      "[Sample] d_loss: 0.84529084, g_loss: 1.10732818\n",
      "Epoch: [17] [ 827/1093] time: 12360.0527, d_loss: 0.9307, g_loss: 1.0901\n",
      "[Sample] d_loss: 0.83327043, g_loss: 1.11210096\n",
      "Epoch: [17] [ 837/1093] time: 12364.2122, d_loss: 0.8846, g_loss: 1.1200\n",
      "[Sample] d_loss: 0.82826215, g_loss: 1.09838510\n",
      "Epoch: [17] [ 847/1093] time: 12368.3991, d_loss: 0.9054, g_loss: 1.0984\n",
      "[Sample] d_loss: 0.84294081, g_loss: 1.07287359\n",
      "Epoch: [17] [ 857/1093] time: 12372.5331, d_loss: 0.8635, g_loss: 1.1117\n",
      "[Sample] d_loss: 0.84732199, g_loss: 1.06630397\n",
      "Epoch: [17] [ 867/1093] time: 12376.6464, d_loss: 0.8532, g_loss: 1.0832\n",
      "[Sample] d_loss: 0.84519434, g_loss: 1.06731808\n",
      "Epoch: [17] [ 877/1093] time: 12380.7729, d_loss: 0.8600, g_loss: 1.0772\n",
      "[Sample] d_loss: 0.86169511, g_loss: 1.04626226\n",
      "Epoch: [17] [ 887/1093] time: 12384.8423, d_loss: 0.9894, g_loss: 1.0598\n",
      "[Sample] d_loss: 0.84919304, g_loss: 1.07358122\n",
      "Epoch: [17] [ 897/1093] time: 12388.9436, d_loss: 0.8484, g_loss: 1.0671\n",
      "[Sample] d_loss: 0.83070558, g_loss: 1.11221993\n",
      "Epoch: [17] [ 907/1093] time: 12393.0626, d_loss: 0.8621, g_loss: 1.0846\n",
      "[Sample] d_loss: 0.84648967, g_loss: 1.07046020\n",
      "Epoch: [17] [ 917/1093] time: 12397.1988, d_loss: 0.8892, g_loss: 1.0831\n",
      "[Sample] d_loss: 0.84810674, g_loss: 1.08103776\n",
      "Epoch: [17] [ 927/1093] time: 12401.3609, d_loss: 0.8420, g_loss: 1.1018\n",
      "[Sample] d_loss: 0.83681989, g_loss: 1.06774819\n",
      "Epoch: [17] [ 937/1093] time: 12405.5037, d_loss: 0.8576, g_loss: 1.0750\n",
      "[Sample] d_loss: 0.86815512, g_loss: 1.03762341\n",
      "Epoch: [17] [ 947/1093] time: 12409.5803, d_loss: 0.8974, g_loss: 1.0331\n",
      "[Sample] d_loss: 0.86746567, g_loss: 1.05010760\n",
      "Epoch: [17] [ 957/1093] time: 12413.6831, d_loss: 0.8939, g_loss: 1.0700\n",
      "[Sample] d_loss: 0.83928478, g_loss: 1.08737636\n",
      "Epoch: [17] [ 967/1093] time: 12417.7855, d_loss: 0.8936, g_loss: 1.0653\n",
      "[Sample] d_loss: 0.82124770, g_loss: 1.11508250\n",
      "Epoch: [17] [ 977/1093] time: 12421.9127, d_loss: 0.8956, g_loss: 1.0885\n",
      "[Sample] d_loss: 0.84046078, g_loss: 1.07908857\n",
      "Epoch: [17] [ 987/1093] time: 12426.0212, d_loss: 0.8404, g_loss: 1.1005\n",
      "[Sample] d_loss: 0.84146357, g_loss: 1.08559728\n",
      "Epoch: [17] [ 997/1093] time: 12430.1255, d_loss: 0.8570, g_loss: 1.0812\n",
      "[Sample] d_loss: 0.83707905, g_loss: 1.10786629\n",
      "Epoch: [17] [1007/1093] time: 12434.1967, d_loss: 0.8013, g_loss: 1.1107\n",
      "[Sample] d_loss: 0.83559680, g_loss: 1.10991263\n",
      "Epoch: [17] [1017/1093] time: 12438.3585, d_loss: 0.9162, g_loss: 1.1221\n",
      "[Sample] d_loss: 0.83903229, g_loss: 1.10006166\n",
      "Epoch: [17] [1027/1093] time: 12442.5485, d_loss: 0.8874, g_loss: 1.0926\n",
      "[Sample] d_loss: 0.85162413, g_loss: 1.07962871\n",
      "Epoch: [17] [1037/1093] time: 12446.6889, d_loss: 0.8817, g_loss: 1.0747\n",
      "[Sample] d_loss: 0.86401314, g_loss: 1.05726218\n",
      "Epoch: [17] [1047/1093] time: 12450.9054, d_loss: 0.8231, g_loss: 1.1130\n",
      "[Sample] d_loss: 0.85924101, g_loss: 1.05325544\n",
      "Epoch: [17] [1057/1093] time: 12455.0805, d_loss: 0.7988, g_loss: 1.1223\n",
      "[Sample] d_loss: 0.85660827, g_loss: 1.07509995\n",
      "Epoch: [17] [1067/1093] time: 12459.2368, d_loss: 0.9019, g_loss: 1.0877\n",
      "[Sample] d_loss: 0.83781683, g_loss: 1.08805656\n",
      "Epoch: [17] [1077/1093] time: 12463.3401, d_loss: 0.8695, g_loss: 1.0806\n",
      "[Sample] d_loss: 0.84387946, g_loss: 1.09060454\n",
      "Epoch: [17] [1087/1093] time: 12467.4801, d_loss: 0.8599, g_loss: 1.1239\n",
      "[Sample] d_loss: 0.84339941, g_loss: 1.08964634\n",
      "[Sample] d_loss: 0.84802407, g_loss: 1.07975411\n",
      "Epoch: [18] [   4/1093] time: 12471.7310, d_loss: 0.8326, g_loss: 1.1223\n",
      "[Sample] d_loss: 0.82016897, g_loss: 1.11598372\n",
      "Epoch: [18] [  14/1093] time: 12475.8202, d_loss: 0.8570, g_loss: 1.0383\n",
      "[Sample] d_loss: 0.82455724, g_loss: 1.12612629\n",
      "Epoch: [18] [  24/1093] time: 12479.9163, d_loss: 0.9311, g_loss: 1.0493\n",
      "[Sample] d_loss: 0.83419812, g_loss: 1.10370421\n",
      "Epoch: [18] [  34/1093] time: 12484.0822, d_loss: 0.9192, g_loss: 1.1007\n",
      "[Sample] d_loss: 0.84418988, g_loss: 1.08664131\n",
      "Epoch: [18] [  44/1093] time: 12488.1830, d_loss: 0.8839, g_loss: 1.0815\n",
      "[Sample] d_loss: 0.84764802, g_loss: 1.07987881\n",
      "Epoch: [18] [  54/1093] time: 12492.3070, d_loss: 0.7780, g_loss: 1.0951\n",
      "[Sample] d_loss: 0.84376639, g_loss: 1.09627938\n",
      "Epoch: [18] [  64/1093] time: 12496.4658, d_loss: 0.9067, g_loss: 1.0749\n",
      "[Sample] d_loss: 0.84043825, g_loss: 1.11219072\n",
      "Epoch: [18] [  74/1093] time: 12500.7194, d_loss: 0.9292, g_loss: 1.0848\n",
      "[Sample] d_loss: 0.84392965, g_loss: 1.11350417\n",
      "Epoch: [18] [  84/1093] time: 12504.8820, d_loss: 0.8700, g_loss: 1.0640\n",
      "[Sample] d_loss: 0.82729352, g_loss: 1.12246668\n",
      "Epoch: [18] [  94/1093] time: 12509.0642, d_loss: 0.9384, g_loss: 1.0875\n",
      "[Sample] d_loss: 0.85309923, g_loss: 1.10050964\n",
      "Epoch: [18] [ 104/1093] time: 12513.2632, d_loss: 0.8386, g_loss: 1.1180\n",
      "[Sample] d_loss: 0.84875947, g_loss: 1.09445477\n",
      "Epoch: [18] [ 114/1093] time: 12517.4161, d_loss: 0.9060, g_loss: 1.0554\n",
      "[Sample] d_loss: 0.85239571, g_loss: 1.08029771\n",
      "Epoch: [18] [ 124/1093] time: 12521.5239, d_loss: 0.8690, g_loss: 1.0809\n",
      "[Sample] d_loss: 0.82980454, g_loss: 1.11697721\n",
      "Epoch: [18] [ 134/1093] time: 12525.6976, d_loss: 0.8600, g_loss: 1.0607\n",
      "[Sample] d_loss: 0.83877975, g_loss: 1.12495184\n",
      "Epoch: [18] [ 144/1093] time: 12529.8455, d_loss: 0.8377, g_loss: 1.1362\n",
      "[Sample] d_loss: 0.84270048, g_loss: 1.10453129\n",
      "Epoch: [18] [ 154/1093] time: 12533.9371, d_loss: 0.8344, g_loss: 1.0933\n",
      "[Sample] d_loss: 0.81537509, g_loss: 1.13127732\n",
      "Epoch: [18] [ 164/1093] time: 12538.0492, d_loss: 0.8951, g_loss: 1.0658\n",
      "[Sample] d_loss: 0.86062306, g_loss: 1.06623197\n",
      "Epoch: [18] [ 174/1093] time: 12542.1944, d_loss: 0.9139, g_loss: 1.0906\n",
      "[Sample] d_loss: 0.85979766, g_loss: 1.06465530\n",
      "Epoch: [18] [ 184/1093] time: 12546.2849, d_loss: 0.8662, g_loss: 1.0694\n",
      "[Sample] d_loss: 0.85796642, g_loss: 1.07712710\n",
      "Epoch: [18] [ 194/1093] time: 12550.4978, d_loss: 0.8063, g_loss: 1.0626\n",
      "[Sample] d_loss: 0.82677519, g_loss: 1.11877573\n",
      "Epoch: [18] [ 204/1093] time: 12554.6102, d_loss: 0.8636, g_loss: 1.0793\n",
      "[Sample] d_loss: 0.83155930, g_loss: 1.11181891\n",
      "Epoch: [18] [ 214/1093] time: 12558.8164, d_loss: 0.8298, g_loss: 1.0894\n",
      "[Sample] d_loss: 0.83276927, g_loss: 1.12400579\n",
      "Epoch: [18] [ 224/1093] time: 12562.9292, d_loss: 0.8883, g_loss: 1.0880\n",
      "[Sample] d_loss: 0.83480424, g_loss: 1.11154485\n",
      "Epoch: [18] [ 234/1093] time: 12567.0408, d_loss: 0.8463, g_loss: 1.1169\n",
      "[Sample] d_loss: 0.82148886, g_loss: 1.14213943\n",
      "Epoch: [18] [ 244/1093] time: 12571.1824, d_loss: 0.9282, g_loss: 1.1072\n",
      "[Sample] d_loss: 0.82193774, g_loss: 1.12816954\n",
      "Epoch: [18] [ 254/1093] time: 12575.2609, d_loss: 0.8842, g_loss: 1.0767\n",
      "[Sample] d_loss: 0.84110856, g_loss: 1.09712386\n",
      "Epoch: [18] [ 264/1093] time: 12579.4289, d_loss: 0.9020, g_loss: 1.0914\n",
      "[Sample] d_loss: 0.84162802, g_loss: 1.08304381\n",
      "Epoch: [18] [ 274/1093] time: 12583.6543, d_loss: 0.8841, g_loss: 1.0969\n",
      "[Sample] d_loss: 0.83860505, g_loss: 1.09734368\n",
      "Epoch: [18] [ 284/1093] time: 12587.7979, d_loss: 0.9006, g_loss: 1.0689\n",
      "[Sample] d_loss: 0.82763004, g_loss: 1.10914505\n",
      "Epoch: [18] [ 294/1093] time: 12591.9012, d_loss: 0.9414, g_loss: 1.0744\n",
      "[Sample] d_loss: 0.82270467, g_loss: 1.10842526\n",
      "Epoch: [18] [ 304/1093] time: 12596.0365, d_loss: 0.8313, g_loss: 1.0771\n",
      "[Sample] d_loss: 0.82178068, g_loss: 1.12108994\n",
      "Epoch: [18] [ 314/1093] time: 12600.2334, d_loss: 0.8538, g_loss: 1.0771\n",
      "[Sample] d_loss: 0.81599820, g_loss: 1.12753391\n",
      "Epoch: [18] [ 324/1093] time: 12604.3504, d_loss: 0.8744, g_loss: 1.0680\n",
      "[Sample] d_loss: 0.82126677, g_loss: 1.11690879\n",
      "Epoch: [18] [ 334/1093] time: 12608.4682, d_loss: 0.8842, g_loss: 1.0911\n",
      "[Sample] d_loss: 0.81961370, g_loss: 1.11740947\n",
      "Epoch: [18] [ 344/1093] time: 12612.6612, d_loss: 0.8539, g_loss: 1.0983\n",
      "[Sample] d_loss: 0.83426303, g_loss: 1.09053349\n",
      "Epoch: [18] [ 354/1093] time: 12616.8680, d_loss: 0.8678, g_loss: 1.0707\n",
      "[Sample] d_loss: 0.82939166, g_loss: 1.11530519\n",
      "Epoch: [18] [ 364/1093] time: 12621.1490, d_loss: 0.9428, g_loss: 1.0761\n",
      "[Sample] d_loss: 0.82860947, g_loss: 1.11822283\n",
      "Epoch: [18] [ 374/1093] time: 12625.2590, d_loss: 0.8094, g_loss: 1.1078\n",
      "[Sample] d_loss: 0.84200531, g_loss: 1.08600926\n",
      "Epoch: [18] [ 384/1093] time: 12629.4299, d_loss: 0.8860, g_loss: 1.0671\n",
      "[Sample] d_loss: 0.84088570, g_loss: 1.10664797\n",
      "Epoch: [18] [ 394/1093] time: 12633.6057, d_loss: 0.8444, g_loss: 1.1166\n",
      "[Sample] d_loss: 0.83930373, g_loss: 1.10314417\n",
      "Epoch: [18] [ 404/1093] time: 12637.6898, d_loss: 0.9048, g_loss: 1.0728\n",
      "[Sample] d_loss: 0.83583057, g_loss: 1.10530746\n",
      "Epoch: [18] [ 414/1093] time: 12641.7849, d_loss: 0.9170, g_loss: 1.0715\n",
      "[Sample] d_loss: 0.83865017, g_loss: 1.09673274\n",
      "Epoch: [18] [ 424/1093] time: 12645.9357, d_loss: 0.8603, g_loss: 1.0963\n",
      "[Sample] d_loss: 0.83862323, g_loss: 1.10129547\n",
      "Epoch: [18] [ 434/1093] time: 12650.0821, d_loss: 0.7988, g_loss: 1.1025\n",
      "[Sample] d_loss: 0.83289719, g_loss: 1.09616423\n",
      "Epoch: [18] [ 444/1093] time: 12654.2646, d_loss: 0.8953, g_loss: 1.0657\n",
      "[Sample] d_loss: 0.83960450, g_loss: 1.07183242\n",
      "Epoch: [18] [ 454/1093] time: 12658.3960, d_loss: 0.8521, g_loss: 1.0856\n",
      "[Sample] d_loss: 0.83625209, g_loss: 1.10666358\n",
      "Epoch: [18] [ 464/1093] time: 12662.5352, d_loss: 0.8342, g_loss: 1.1089\n",
      "[Sample] d_loss: 0.84180009, g_loss: 1.09130132\n",
      "Epoch: [18] [ 474/1093] time: 12666.6836, d_loss: 0.9200, g_loss: 1.0932\n",
      "[Sample] d_loss: 0.85387659, g_loss: 1.05838168\n",
      "Epoch: [18] [ 484/1093] time: 12670.7850, d_loss: 0.8662, g_loss: 1.1028\n",
      "[Sample] d_loss: 0.84598315, g_loss: 1.08043492\n",
      "Epoch: [18] [ 494/1093] time: 12674.9944, d_loss: 0.8937, g_loss: 1.0998\n",
      "[Sample] d_loss: 0.85032141, g_loss: 1.07252276\n",
      "Epoch: [18] [ 504/1093] time: 12679.1983, d_loss: 0.8468, g_loss: 1.0971\n",
      "[Sample] d_loss: 0.83888507, g_loss: 1.10659230\n",
      "Epoch: [18] [ 514/1093] time: 12683.2854, d_loss: 0.9420, g_loss: 1.1093\n",
      "[Sample] d_loss: 0.84648710, g_loss: 1.08383405\n",
      "Epoch: [18] [ 524/1093] time: 12687.3936, d_loss: 0.8397, g_loss: 1.1203\n",
      "[Sample] d_loss: 0.84144783, g_loss: 1.08404016\n",
      "Epoch: [18] [ 534/1093] time: 12691.4943, d_loss: 0.8768, g_loss: 1.0916\n",
      "[Sample] d_loss: 0.84241498, g_loss: 1.07688189\n",
      "Epoch: [18] [ 544/1093] time: 12695.6034, d_loss: 0.8918, g_loss: 1.0664\n",
      "[Sample] d_loss: 0.84147155, g_loss: 1.08722687\n",
      "Epoch: [18] [ 554/1093] time: 12699.6924, d_loss: 0.8905, g_loss: 1.1157\n",
      "[Sample] d_loss: 0.83263630, g_loss: 1.09916449\n",
      "Epoch: [18] [ 564/1093] time: 12703.7928, d_loss: 0.9292, g_loss: 1.1133\n",
      "[Sample] d_loss: 0.84222925, g_loss: 1.11337996\n",
      "Epoch: [18] [ 574/1093] time: 12707.9634, d_loss: 0.8065, g_loss: 1.0883\n",
      "[Sample] d_loss: 0.83483106, g_loss: 1.10746288\n",
      "Epoch: [18] [ 584/1093] time: 12712.0933, d_loss: 0.9255, g_loss: 1.0792\n",
      "[Sample] d_loss: 0.82680458, g_loss: 1.11321461\n",
      "Epoch: [18] [ 594/1093] time: 12716.2795, d_loss: 0.8333, g_loss: 1.0943\n",
      "[Sample] d_loss: 0.83866322, g_loss: 1.08416986\n",
      "Epoch: [18] [ 604/1093] time: 12720.4171, d_loss: 0.8531, g_loss: 1.0681\n",
      "[Sample] d_loss: 0.84235477, g_loss: 1.07710671\n",
      "Epoch: [18] [ 614/1093] time: 12724.5500, d_loss: 0.8657, g_loss: 1.0499\n",
      "[Sample] d_loss: 0.84016556, g_loss: 1.09573746\n",
      "Epoch: [18] [ 624/1093] time: 12728.6778, d_loss: 0.8087, g_loss: 1.1064\n",
      "[Sample] d_loss: 0.83261752, g_loss: 1.10219002\n",
      "Epoch: [18] [ 634/1093] time: 12732.7758, d_loss: 0.8608, g_loss: 1.0984\n",
      "[Sample] d_loss: 0.84006649, g_loss: 1.06044662\n",
      "Epoch: [18] [ 644/1093] time: 12736.9360, d_loss: 0.8738, g_loss: 1.1016\n",
      "[Sample] d_loss: 0.84004259, g_loss: 1.06431150\n",
      "Epoch: [18] [ 654/1093] time: 12741.0603, d_loss: 0.9212, g_loss: 1.0985\n",
      "[Sample] d_loss: 0.82705563, g_loss: 1.09124541\n",
      "Epoch: [18] [ 664/1093] time: 12745.2267, d_loss: 0.8365, g_loss: 1.1012\n",
      "[Sample] d_loss: 0.83417553, g_loss: 1.06443393\n",
      "Epoch: [18] [ 674/1093] time: 12749.3706, d_loss: 0.8847, g_loss: 1.1292\n",
      "[Sample] d_loss: 0.84447891, g_loss: 1.06236839\n",
      "Epoch: [18] [ 684/1093] time: 12753.4644, d_loss: 0.8180, g_loss: 1.0954\n",
      "[Sample] d_loss: 0.83901417, g_loss: 1.07172918\n",
      "Epoch: [18] [ 694/1093] time: 12757.5506, d_loss: 0.8063, g_loss: 1.1484\n",
      "[Sample] d_loss: 0.84628016, g_loss: 1.06026554\n",
      "Epoch: [18] [ 704/1093] time: 12761.7223, d_loss: 0.8661, g_loss: 1.1046\n",
      "[Sample] d_loss: 0.83239144, g_loss: 1.07300472\n",
      "Epoch: [18] [ 714/1093] time: 12765.7935, d_loss: 0.8637, g_loss: 1.1253\n",
      "[Sample] d_loss: 0.82463157, g_loss: 1.09211636\n",
      "Epoch: [18] [ 724/1093] time: 12769.9365, d_loss: 0.8974, g_loss: 1.0927\n",
      "[Sample] d_loss: 0.81332207, g_loss: 1.14465833\n",
      "Epoch: [18] [ 734/1093] time: 12774.1988, d_loss: 0.8875, g_loss: 1.1256\n",
      "[Sample] d_loss: 0.80700427, g_loss: 1.12776804\n",
      "Epoch: [18] [ 744/1093] time: 12778.3120, d_loss: 0.8351, g_loss: 1.1104\n",
      "[Sample] d_loss: 0.81113303, g_loss: 1.11320245\n",
      "Epoch: [18] [ 754/1093] time: 12782.4324, d_loss: 0.8835, g_loss: 1.0910\n",
      "[Sample] d_loss: 0.81075692, g_loss: 1.11684966\n",
      "Epoch: [18] [ 764/1093] time: 12786.5188, d_loss: 0.8852, g_loss: 1.1455\n",
      "[Sample] d_loss: 0.81918955, g_loss: 1.12573504\n",
      "Epoch: [18] [ 774/1093] time: 12790.6753, d_loss: 0.8727, g_loss: 1.1358\n",
      "[Sample] d_loss: 0.78239322, g_loss: 1.18166828\n",
      "Epoch: [18] [ 784/1093] time: 12794.7920, d_loss: 0.8622, g_loss: 1.1179\n",
      "[Sample] d_loss: 0.81263274, g_loss: 1.12095594\n",
      "Epoch: [18] [ 794/1093] time: 12798.8924, d_loss: 0.8311, g_loss: 1.0843\n",
      "[Sample] d_loss: 0.81377900, g_loss: 1.13434088\n",
      "Epoch: [18] [ 804/1093] time: 12803.1023, d_loss: 0.8758, g_loss: 1.1269\n",
      "[Sample] d_loss: 0.79881024, g_loss: 1.14179039\n",
      "Epoch: [18] [ 814/1093] time: 12807.5055, d_loss: 0.8158, g_loss: 1.1481\n",
      "[Sample] d_loss: 0.83520234, g_loss: 1.09905243\n",
      "Epoch: [18] [ 824/1093] time: 12811.8087, d_loss: 0.8614, g_loss: 1.1391\n",
      "[Sample] d_loss: 0.82642967, g_loss: 1.12024498\n",
      "Epoch: [18] [ 834/1093] time: 12815.8979, d_loss: 0.7910, g_loss: 1.1564\n",
      "[Sample] d_loss: 0.82564646, g_loss: 1.10934424\n",
      "Epoch: [18] [ 844/1093] time: 12820.0497, d_loss: 0.8172, g_loss: 1.1631\n",
      "[Sample] d_loss: 0.79979873, g_loss: 1.13022995\n",
      "Epoch: [18] [ 854/1093] time: 12824.4716, d_loss: 0.8499, g_loss: 1.0878\n",
      "[Sample] d_loss: 0.82818866, g_loss: 1.09707808\n",
      "Epoch: [18] [ 864/1093] time: 12828.5698, d_loss: 0.8109, g_loss: 1.1223\n",
      "[Sample] d_loss: 0.80997527, g_loss: 1.11239052\n",
      "Epoch: [18] [ 874/1093] time: 12832.7275, d_loss: 0.9040, g_loss: 1.1317\n",
      "[Sample] d_loss: 0.80868238, g_loss: 1.11860216\n",
      "Epoch: [18] [ 884/1093] time: 12836.8123, d_loss: 0.9111, g_loss: 1.1042\n",
      "[Sample] d_loss: 0.80015790, g_loss: 1.12906194\n",
      "Epoch: [18] [ 894/1093] time: 12840.8826, d_loss: 0.8004, g_loss: 1.1166\n",
      "[Sample] d_loss: 0.79848778, g_loss: 1.14539886\n",
      "Epoch: [18] [ 904/1093] time: 12844.9573, d_loss: 0.8127, g_loss: 1.1350\n",
      "[Sample] d_loss: 0.82837236, g_loss: 1.08626354\n",
      "Epoch: [18] [ 914/1093] time: 12849.1395, d_loss: 0.8139, g_loss: 1.1303\n",
      "[Sample] d_loss: 0.81445038, g_loss: 1.10378003\n",
      "Epoch: [18] [ 924/1093] time: 12853.2791, d_loss: 0.8187, g_loss: 1.0859\n",
      "[Sample] d_loss: 0.80094683, g_loss: 1.11692679\n",
      "Epoch: [18] [ 934/1093] time: 12857.4262, d_loss: 0.8125, g_loss: 1.1128\n",
      "[Sample] d_loss: 0.79483807, g_loss: 1.14441073\n",
      "Epoch: [18] [ 944/1093] time: 12861.5232, d_loss: 0.8148, g_loss: 1.1411\n",
      "[Sample] d_loss: 0.80361640, g_loss: 1.13175714\n",
      "Epoch: [18] [ 954/1093] time: 12865.6385, d_loss: 0.8362, g_loss: 1.1125\n",
      "[Sample] d_loss: 0.81101763, g_loss: 1.10986745\n",
      "Epoch: [18] [ 964/1093] time: 12869.8089, d_loss: 0.9067, g_loss: 1.1501\n",
      "[Sample] d_loss: 0.79686904, g_loss: 1.13568020\n",
      "Epoch: [18] [ 974/1093] time: 12873.9511, d_loss: 0.8270, g_loss: 1.1153\n",
      "[Sample] d_loss: 0.80647063, g_loss: 1.11950326\n",
      "Epoch: [18] [ 984/1093] time: 12878.0731, d_loss: 0.8168, g_loss: 1.1375\n",
      "[Sample] d_loss: 0.79644084, g_loss: 1.12096751\n",
      "Epoch: [18] [ 994/1093] time: 12882.2354, d_loss: 0.8294, g_loss: 1.1522\n",
      "[Sample] d_loss: 0.78494883, g_loss: 1.13607287\n",
      "Epoch: [18] [1004/1093] time: 12886.2973, d_loss: 0.8963, g_loss: 1.1066\n",
      "[Sample] d_loss: 0.78166878, g_loss: 1.14747643\n",
      "Epoch: [18] [1014/1093] time: 12890.4034, d_loss: 0.8410, g_loss: 1.1031\n",
      "[Sample] d_loss: 0.78143704, g_loss: 1.15019238\n",
      "Epoch: [18] [1024/1093] time: 12894.6599, d_loss: 0.7660, g_loss: 1.1275\n",
      "[Sample] d_loss: 0.78762162, g_loss: 1.15574419\n",
      "Epoch: [18] [1034/1093] time: 12899.1819, d_loss: 0.8646, g_loss: 1.1425\n",
      "[Sample] d_loss: 0.78840995, g_loss: 1.14481699\n",
      "Epoch: [18] [1044/1093] time: 12903.6341, d_loss: 0.8012, g_loss: 1.1026\n",
      "[Sample] d_loss: 0.80499953, g_loss: 1.13485479\n",
      "Epoch: [18] [1054/1093] time: 12908.0307, d_loss: 0.8126, g_loss: 1.1097\n",
      "[Sample] d_loss: 0.80922854, g_loss: 1.11271977\n",
      "Epoch: [18] [1064/1093] time: 12912.3335, d_loss: 0.8372, g_loss: 1.1361\n",
      "[Sample] d_loss: 0.79516172, g_loss: 1.12362528\n",
      "Epoch: [18] [1074/1093] time: 12916.6123, d_loss: 0.7635, g_loss: 1.1361\n",
      "[Sample] d_loss: 0.78309888, g_loss: 1.13825333\n",
      "Epoch: [18] [1084/1093] time: 12920.9414, d_loss: 0.7895, g_loss: 1.1209\n",
      "[Sample] d_loss: 0.80157435, g_loss: 1.11248350\n",
      "[Sample] d_loss: 0.79436660, g_loss: 1.10102749\n",
      "Epoch: [19] [   1/1093] time: 12925.3315, d_loss: 0.8193, g_loss: 1.1385\n",
      "[Sample] d_loss: 0.78655708, g_loss: 1.12410355\n",
      "Epoch: [19] [  11/1093] time: 12929.6159, d_loss: 0.7745, g_loss: 1.1486\n",
      "[Sample] d_loss: 0.79586327, g_loss: 1.11308920\n",
      "Epoch: [19] [  21/1093] time: 12933.9483, d_loss: 0.8086, g_loss: 1.1562\n",
      "[Sample] d_loss: 0.81299698, g_loss: 1.08324230\n",
      "Epoch: [19] [  31/1093] time: 12938.3922, d_loss: 0.8208, g_loss: 1.1537\n",
      "[Sample] d_loss: 0.78075713, g_loss: 1.14873791\n",
      "Epoch: [19] [  41/1093] time: 12942.7814, d_loss: 0.8248, g_loss: 1.1632\n",
      "[Sample] d_loss: 0.77486134, g_loss: 1.14275050\n",
      "Epoch: [19] [  51/1093] time: 12947.3664, d_loss: 0.7741, g_loss: 1.1821\n",
      "[Sample] d_loss: 0.76012886, g_loss: 1.17461932\n",
      "Epoch: [19] [  61/1093] time: 12951.6201, d_loss: 0.8154, g_loss: 1.1659\n",
      "[Sample] d_loss: 0.78916740, g_loss: 1.12406087\n",
      "Epoch: [19] [  71/1093] time: 12955.7327, d_loss: 0.7797, g_loss: 1.1832\n",
      "[Sample] d_loss: 0.76595652, g_loss: 1.17025876\n",
      "Epoch: [19] [  81/1093] time: 12959.9019, d_loss: 0.8076, g_loss: 1.1732\n",
      "[Sample] d_loss: 0.78516304, g_loss: 1.12527847\n",
      "Epoch: [19] [  91/1093] time: 12964.0529, d_loss: 0.8517, g_loss: 1.1599\n",
      "[Sample] d_loss: 0.78138846, g_loss: 1.14456129\n",
      "Epoch: [19] [ 101/1093] time: 12968.1769, d_loss: 0.7811, g_loss: 1.1680\n",
      "[Sample] d_loss: 0.79943901, g_loss: 1.10151100\n",
      "Epoch: [19] [ 111/1093] time: 12972.4032, d_loss: 0.7720, g_loss: 1.1198\n",
      "[Sample] d_loss: 0.77577984, g_loss: 1.14320540\n",
      "Epoch: [19] [ 121/1093] time: 12976.5605, d_loss: 0.8083, g_loss: 1.1378\n",
      "[Sample] d_loss: 0.77790523, g_loss: 1.11605954\n",
      "Epoch: [19] [ 131/1093] time: 12980.6660, d_loss: 0.7889, g_loss: 1.1030\n",
      "[Sample] d_loss: 0.77533364, g_loss: 1.15660191\n",
      "Epoch: [19] [ 141/1093] time: 12984.7797, d_loss: 0.8098, g_loss: 1.1814\n",
      "[Sample] d_loss: 0.76963007, g_loss: 1.15463829\n",
      "Epoch: [19] [ 151/1093] time: 12988.8868, d_loss: 0.8575, g_loss: 1.1936\n",
      "[Sample] d_loss: 0.76971871, g_loss: 1.16539979\n",
      "Epoch: [19] [ 161/1093] time: 12992.9727, d_loss: 0.8116, g_loss: 1.1443\n",
      "[Sample] d_loss: 0.76691127, g_loss: 1.16617310\n",
      "Epoch: [19] [ 171/1093] time: 12997.1337, d_loss: 0.8795, g_loss: 1.1479\n",
      "[Sample] d_loss: 0.76407063, g_loss: 1.14155686\n",
      "Epoch: [19] [ 181/1093] time: 13001.2969, d_loss: 0.7887, g_loss: 1.1887\n",
      "[Sample] d_loss: 0.78977823, g_loss: 1.11886740\n",
      "Epoch: [19] [ 191/1093] time: 13005.4617, d_loss: 0.7665, g_loss: 1.1765\n",
      "[Sample] d_loss: 0.75468141, g_loss: 1.17282367\n",
      "Epoch: [19] [ 201/1093] time: 13009.5691, d_loss: 0.9005, g_loss: 1.1898\n",
      "[Sample] d_loss: 0.77885795, g_loss: 1.12324810\n",
      "Epoch: [19] [ 211/1093] time: 13013.6582, d_loss: 0.8502, g_loss: 1.1253\n",
      "[Sample] d_loss: 0.76139975, g_loss: 1.14410663\n",
      "Epoch: [19] [ 221/1093] time: 13017.7843, d_loss: 0.7532, g_loss: 1.1440\n",
      "[Sample] d_loss: 0.77373141, g_loss: 1.14133072\n",
      "Epoch: [19] [ 231/1093] time: 13021.8911, d_loss: 0.8467, g_loss: 1.1268\n",
      "[Sample] d_loss: 0.77479863, g_loss: 1.14515972\n",
      "Epoch: [19] [ 241/1093] time: 13025.9644, d_loss: 0.8361, g_loss: 1.1154\n",
      "[Sample] d_loss: 0.77286398, g_loss: 1.14089417\n",
      "Epoch: [19] [ 251/1093] time: 13030.0989, d_loss: 0.7878, g_loss: 1.1689\n",
      "[Sample] d_loss: 0.77914172, g_loss: 1.12496030\n",
      "Epoch: [19] [ 261/1093] time: 13034.3280, d_loss: 0.8752, g_loss: 1.1694\n",
      "[Sample] d_loss: 0.75465530, g_loss: 1.16745138\n",
      "Epoch: [19] [ 271/1093] time: 13038.4684, d_loss: 0.8613, g_loss: 1.1754\n",
      "[Sample] d_loss: 0.76935941, g_loss: 1.12929642\n",
      "Epoch: [19] [ 281/1093] time: 13042.5883, d_loss: 0.8111, g_loss: 1.1320\n",
      "[Sample] d_loss: 0.76630175, g_loss: 1.13932395\n",
      "Epoch: [19] [ 291/1093] time: 13046.7397, d_loss: 0.7828, g_loss: 1.1333\n",
      "[Sample] d_loss: 0.74802840, g_loss: 1.14338219\n",
      "Epoch: [19] [ 301/1093] time: 13050.8230, d_loss: 0.8377, g_loss: 1.1542\n",
      "[Sample] d_loss: 0.75047624, g_loss: 1.16440856\n",
      "Epoch: [19] [ 311/1093] time: 13054.9207, d_loss: 0.7474, g_loss: 1.1471\n",
      "[Sample] d_loss: 0.76240039, g_loss: 1.16201282\n",
      "Epoch: [19] [ 321/1093] time: 13059.0509, d_loss: 0.8817, g_loss: 1.1536\n",
      "[Sample] d_loss: 0.75189179, g_loss: 1.15391541\n",
      "Epoch: [19] [ 331/1093] time: 13063.1600, d_loss: 0.7613, g_loss: 1.1580\n",
      "[Sample] d_loss: 0.74478424, g_loss: 1.16139948\n",
      "Epoch: [19] [ 341/1093] time: 13067.2817, d_loss: 0.8418, g_loss: 1.1884\n",
      "[Sample] d_loss: 0.73496288, g_loss: 1.21245027\n",
      "Epoch: [19] [ 351/1093] time: 13071.4390, d_loss: 0.7552, g_loss: 1.1449\n",
      "[Sample] d_loss: 0.73459238, g_loss: 1.20564151\n",
      "Epoch: [19] [ 361/1093] time: 13075.5269, d_loss: 0.8672, g_loss: 1.1659\n",
      "[Sample] d_loss: 0.72310853, g_loss: 1.22052264\n",
      "Epoch: [19] [ 371/1093] time: 13079.6729, d_loss: 0.7924, g_loss: 1.2064\n",
      "[Sample] d_loss: 0.76027024, g_loss: 1.21012366\n",
      "Epoch: [19] [ 381/1093] time: 13083.9600, d_loss: 0.8647, g_loss: 1.2106\n",
      "[Sample] d_loss: 0.74419439, g_loss: 1.15043688\n",
      "Epoch: [19] [ 391/1093] time: 13088.0583, d_loss: 0.7884, g_loss: 1.1789\n",
      "[Sample] d_loss: 0.74946111, g_loss: 1.14750481\n",
      "Epoch: [19] [ 401/1093] time: 13092.1925, d_loss: 0.7720, g_loss: 1.1491\n",
      "[Sample] d_loss: 0.76794106, g_loss: 1.13757849\n",
      "Epoch: [19] [ 411/1093] time: 13096.2844, d_loss: 0.7553, g_loss: 1.2077\n",
      "[Sample] d_loss: 0.77823257, g_loss: 1.12174988\n",
      "Epoch: [19] [ 421/1093] time: 13100.5050, d_loss: 0.7660, g_loss: 1.1236\n",
      "[Sample] d_loss: 0.75262541, g_loss: 1.16696692\n",
      "Epoch: [19] [ 431/1093] time: 13104.6573, d_loss: 0.8064, g_loss: 1.1771\n",
      "[Sample] d_loss: 0.74169874, g_loss: 1.18177915\n",
      "Epoch: [19] [ 441/1093] time: 13108.7469, d_loss: 0.7471, g_loss: 1.1764\n",
      "[Sample] d_loss: 0.73340487, g_loss: 1.20603156\n",
      "Epoch: [19] [ 451/1093] time: 13112.8173, d_loss: 0.8473, g_loss: 1.1765\n",
      "[Sample] d_loss: 0.75688756, g_loss: 1.14264488\n",
      "Epoch: [19] [ 461/1093] time: 13116.9343, d_loss: 0.7607, g_loss: 1.2059\n",
      "[Sample] d_loss: 0.75188351, g_loss: 1.16729188\n",
      "Epoch: [19] [ 471/1093] time: 13121.0999, d_loss: 0.7488, g_loss: 1.1563\n",
      "[Sample] d_loss: 0.74653387, g_loss: 1.19117832\n",
      "Epoch: [19] [ 481/1093] time: 13125.6622, d_loss: 0.8240, g_loss: 1.2266\n",
      "[Sample] d_loss: 0.74724740, g_loss: 1.15872574\n",
      "Epoch: [19] [ 491/1093] time: 13129.9760, d_loss: 0.7685, g_loss: 1.1596\n",
      "[Sample] d_loss: 0.76343966, g_loss: 1.14501631\n",
      "Epoch: [19] [ 501/1093] time: 13134.3583, d_loss: 0.8056, g_loss: 1.1726\n",
      "[Sample] d_loss: 0.75532162, g_loss: 1.16963458\n",
      "Epoch: [19] [ 511/1093] time: 13138.9061, d_loss: 0.8512, g_loss: 1.1518\n",
      "[Sample] d_loss: 0.75638425, g_loss: 1.12354004\n",
      "Epoch: [19] [ 521/1093] time: 13143.2788, d_loss: 0.7941, g_loss: 1.1757\n",
      "[Sample] d_loss: 0.76617229, g_loss: 1.13134122\n",
      "Epoch: [19] [ 531/1093] time: 13147.4760, d_loss: 0.7814, g_loss: 1.1450\n",
      "[Sample] d_loss: 0.75778568, g_loss: 1.14278483\n",
      "Epoch: [19] [ 541/1093] time: 13151.5932, d_loss: 0.8119, g_loss: 1.1950\n",
      "[Sample] d_loss: 0.76009715, g_loss: 1.14644349\n",
      "Epoch: [19] [ 551/1093] time: 13155.7166, d_loss: 0.7935, g_loss: 1.1422\n",
      "[Sample] d_loss: 0.76290363, g_loss: 1.16044390\n",
      "Epoch: [19] [ 561/1093] time: 13159.8825, d_loss: 0.8193, g_loss: 1.1498\n",
      "[Sample] d_loss: 0.75665826, g_loss: 1.14480698\n",
      "Epoch: [19] [ 571/1093] time: 13164.3328, d_loss: 0.7539, g_loss: 1.1813\n",
      "[Sample] d_loss: 0.73744553, g_loss: 1.18137670\n",
      "Epoch: [19] [ 581/1093] time: 13168.6568, d_loss: 0.8468, g_loss: 1.1582\n",
      "[Sample] d_loss: 0.73493010, g_loss: 1.20368755\n",
      "Epoch: [19] [ 591/1093] time: 13172.7478, d_loss: 0.8039, g_loss: 1.1708\n",
      "[Sample] d_loss: 0.75087285, g_loss: 1.17085671\n",
      "Epoch: [19] [ 601/1093] time: 13176.8518, d_loss: 0.8104, g_loss: 1.1652\n",
      "[Sample] d_loss: 0.74087501, g_loss: 1.19725084\n",
      "Epoch: [19] [ 611/1093] time: 13180.9792, d_loss: 0.7700, g_loss: 1.1533\n",
      "[Sample] d_loss: 0.73709899, g_loss: 1.20495665\n",
      "Epoch: [19] [ 621/1093] time: 13185.2377, d_loss: 0.7138, g_loss: 1.1628\n",
      "[Sample] d_loss: 0.73244792, g_loss: 1.20804107\n",
      "Epoch: [19] [ 631/1093] time: 13189.3455, d_loss: 0.8603, g_loss: 1.1899\n",
      "[Sample] d_loss: 0.71970153, g_loss: 1.21747828\n",
      "Epoch: [19] [ 641/1093] time: 13193.6164, d_loss: 0.8621, g_loss: 1.1482\n",
      "[Sample] d_loss: 0.74742013, g_loss: 1.16044450\n",
      "Epoch: [19] [ 651/1093] time: 13197.8304, d_loss: 0.8106, g_loss: 1.1761\n",
      "[Sample] d_loss: 0.74233770, g_loss: 1.17464364\n",
      "Epoch: [19] [ 661/1093] time: 13202.1711, d_loss: 0.7538, g_loss: 1.2055\n",
      "[Sample] d_loss: 0.73298991, g_loss: 1.19333768\n",
      "Epoch: [19] [ 671/1093] time: 13206.6351, d_loss: 0.8129, g_loss: 1.1873\n",
      "[Sample] d_loss: 0.72758126, g_loss: 1.20888221\n",
      "Epoch: [19] [ 681/1093] time: 13211.1434, d_loss: 0.8840, g_loss: 1.1519\n",
      "[Sample] d_loss: 0.71712321, g_loss: 1.25964785\n",
      "Epoch: [19] [ 691/1093] time: 13215.3309, d_loss: 0.7934, g_loss: 1.2181\n",
      "[Sample] d_loss: 0.74851871, g_loss: 1.17771423\n",
      "Epoch: [19] [ 701/1093] time: 13219.5947, d_loss: 0.7745, g_loss: 1.2276\n",
      "[Sample] d_loss: 0.74989241, g_loss: 1.17730808\n",
      "Epoch: [19] [ 711/1093] time: 13224.0627, d_loss: 0.7198, g_loss: 1.1934\n",
      "[Sample] d_loss: 0.72513103, g_loss: 1.18777728\n",
      "Epoch: [19] [ 721/1093] time: 13228.4194, d_loss: 0.7739, g_loss: 1.1903\n",
      "[Sample] d_loss: 0.74137193, g_loss: 1.19415593\n",
      "Epoch: [19] [ 731/1093] time: 13232.7281, d_loss: 0.7890, g_loss: 1.1375\n",
      "[Sample] d_loss: 0.73347533, g_loss: 1.20481491\n",
      "Epoch: [19] [ 741/1093] time: 13236.8805, d_loss: 0.7860, g_loss: 1.1936\n",
      "[Sample] d_loss: 0.75095665, g_loss: 1.15938616\n",
      "Epoch: [19] [ 751/1093] time: 13241.1004, d_loss: 0.7605, g_loss: 1.2180\n",
      "[Sample] d_loss: 0.71784365, g_loss: 1.21912313\n",
      "Epoch: [19] [ 761/1093] time: 13245.3428, d_loss: 0.7783, g_loss: 1.2320\n",
      "[Sample] d_loss: 0.72060305, g_loss: 1.21804035\n",
      "Epoch: [19] [ 771/1093] time: 13249.7207, d_loss: 0.8770, g_loss: 1.2080\n",
      "[Sample] d_loss: 0.73271430, g_loss: 1.22647142\n",
      "Epoch: [19] [ 781/1093] time: 13253.9120, d_loss: 0.7539, g_loss: 1.2376\n",
      "[Sample] d_loss: 0.72594011, g_loss: 1.20702612\n",
      "Epoch: [19] [ 791/1093] time: 13257.8758, d_loss: 0.7534, g_loss: 1.2303\n",
      "[Sample] d_loss: 0.71779531, g_loss: 1.22493577\n",
      "Epoch: [19] [ 801/1093] time: 13261.8494, d_loss: 0.8507, g_loss: 1.2029\n",
      "[Sample] d_loss: 0.70356333, g_loss: 1.24141860\n",
      "Epoch: [19] [ 811/1093] time: 13265.8550, d_loss: 0.8335, g_loss: 1.2320\n",
      "[Sample] d_loss: 0.71924376, g_loss: 1.24681163\n",
      "Epoch: [19] [ 821/1093] time: 13269.8651, d_loss: 0.7951, g_loss: 1.2069\n",
      "[Sample] d_loss: 0.71447235, g_loss: 1.24064302\n",
      "Epoch: [19] [ 831/1093] time: 13273.8756, d_loss: 0.8196, g_loss: 1.2181\n",
      "[Sample] d_loss: 0.71415949, g_loss: 1.23696804\n",
      "Epoch: [19] [ 841/1093] time: 13277.9056, d_loss: 0.7309, g_loss: 1.2491\n",
      "[Sample] d_loss: 0.73101795, g_loss: 1.20374990\n",
      "Epoch: [19] [ 851/1093] time: 13281.9479, d_loss: 0.7355, g_loss: 1.2160\n",
      "[Sample] d_loss: 0.72471583, g_loss: 1.18930268\n",
      "Epoch: [19] [ 861/1093] time: 13285.9070, d_loss: 0.7045, g_loss: 1.2064\n",
      "[Sample] d_loss: 0.71611881, g_loss: 1.21312428\n",
      "Epoch: [19] [ 871/1093] time: 13289.9450, d_loss: 0.8348, g_loss: 1.1871\n",
      "[Sample] d_loss: 0.73349398, g_loss: 1.18929696\n",
      "Epoch: [19] [ 881/1093] time: 13294.2770, d_loss: 0.7825, g_loss: 1.2031\n",
      "[Sample] d_loss: 0.73502940, g_loss: 1.18624687\n",
      "Epoch: [19] [ 891/1093] time: 13298.5919, d_loss: 0.8287, g_loss: 1.2364\n",
      "[Sample] d_loss: 0.71754307, g_loss: 1.19052458\n",
      "Epoch: [19] [ 901/1093] time: 13302.6255, d_loss: 0.7915, g_loss: 1.1846\n",
      "[Sample] d_loss: 0.71074927, g_loss: 1.22146749\n",
      "Epoch: [19] [ 911/1093] time: 13307.0704, d_loss: 0.7900, g_loss: 1.1991\n",
      "[Sample] d_loss: 0.73057950, g_loss: 1.20030189\n",
      "Epoch: [19] [ 921/1093] time: 13311.1558, d_loss: 0.7319, g_loss: 1.1985\n",
      "[Sample] d_loss: 0.72251403, g_loss: 1.18380404\n",
      "Epoch: [19] [ 931/1093] time: 13315.0928, d_loss: 0.7213, g_loss: 1.1780\n",
      "[Sample] d_loss: 0.70427692, g_loss: 1.25341201\n",
      "Epoch: [19] [ 941/1093] time: 13319.0718, d_loss: 0.7876, g_loss: 1.2015\n",
      "[Sample] d_loss: 0.72141254, g_loss: 1.19909024\n",
      "Epoch: [19] [ 951/1093] time: 13323.3523, d_loss: 0.8294, g_loss: 1.2041\n",
      "[Sample] d_loss: 0.72182453, g_loss: 1.22227156\n",
      "Epoch: [19] [ 961/1093] time: 13327.4780, d_loss: 0.7333, g_loss: 1.1951\n",
      "[Sample] d_loss: 0.71344596, g_loss: 1.21969771\n",
      "Epoch: [19] [ 971/1093] time: 13331.5821, d_loss: 0.7465, g_loss: 1.2281\n",
      "[Sample] d_loss: 0.70636737, g_loss: 1.22585106\n",
      "Epoch: [19] [ 981/1093] time: 13335.6747, d_loss: 0.7395, g_loss: 1.2445\n",
      "[Sample] d_loss: 0.69990039, g_loss: 1.24332905\n",
      "Epoch: [19] [ 991/1093] time: 13339.9567, d_loss: 0.7731, g_loss: 1.2096\n",
      "[Sample] d_loss: 0.70189536, g_loss: 1.23634887\n",
      "Epoch: [19] [1001/1093] time: 13344.2299, d_loss: 0.7664, g_loss: 1.2118\n",
      "[Sample] d_loss: 0.71414930, g_loss: 1.22325516\n",
      "Epoch: [19] [1011/1093] time: 13348.4420, d_loss: 0.8402, g_loss: 1.2629\n",
      "[Sample] d_loss: 0.72221112, g_loss: 1.20352495\n",
      "Epoch: [19] [1021/1093] time: 13352.4456, d_loss: 0.7627, g_loss: 1.2038\n",
      "[Sample] d_loss: 0.71359110, g_loss: 1.20034039\n",
      "Epoch: [19] [1031/1093] time: 13356.4710, d_loss: 0.7364, g_loss: 1.2483\n",
      "[Sample] d_loss: 0.70580435, g_loss: 1.23419118\n",
      "Epoch: [19] [1041/1093] time: 13360.4417, d_loss: 0.7661, g_loss: 1.2114\n",
      "[Sample] d_loss: 0.71005249, g_loss: 1.22027075\n",
      "Epoch: [19] [1051/1093] time: 13364.4235, d_loss: 0.7150, g_loss: 1.1997\n",
      "[Sample] d_loss: 0.70645785, g_loss: 1.22533786\n",
      "Epoch: [19] [1061/1093] time: 13368.4012, d_loss: 0.8321, g_loss: 1.1630\n",
      "[Sample] d_loss: 0.70977104, g_loss: 1.23545945\n",
      "Epoch: [19] [1071/1093] time: 13372.3689, d_loss: 0.7468, g_loss: 1.2058\n",
      "[Sample] d_loss: 0.70803028, g_loss: 1.22084188\n",
      "Epoch: [19] [1081/1093] time: 13376.2992, d_loss: 0.6829, g_loss: 1.2494\n",
      "[Sample] d_loss: 0.69612885, g_loss: 1.25476062\n",
      "Epoch: [19] [1091/1093] time: 13380.3078, d_loss: 0.7434, g_loss: 1.2646\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import math\n",
    "from glob import glob\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random\n",
    "#from mnist_utils import *\n",
    "#from mnist_modules import *\n",
    "import matplotlib.pyplot as plt\n",
    "import PIL\n",
    "from PIL import Image\n",
    "from PIL import ImageFont, ImageDraw\n",
    "from PIL import Image\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_losses(d_losses, g_losses):\n",
    "    # Calculate the number of epochs based on the discriminator losses\n",
    "    epochs = len(d_losses)\n",
    "    \n",
    "    # Plot the discriminator losses over epochs\n",
    "    plt.plot(range(epochs), d_losses, label='Discriminator Loss')\n",
    "    \n",
    "    # Plot the generator losses over epochs\n",
    "    plt.plot(range(epochs), g_losses, label='Generator Loss')\n",
    "    \n",
    "    # Set the label for the x-axis as \"Epoch\"\n",
    "    plt.xlabel('Epoch')\n",
    "    \n",
    "    # Set the label for the y-axis as \"Loss\"\n",
    "    plt.ylabel('Loss')\n",
    "    \n",
    "    # Set the title of the plot\n",
    "    plt.title('GAN Losses over Time')\n",
    "    \n",
    "    # Display a legend for the plot\n",
    "    plt.legend()\n",
    "    \n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "\n",
    "class LayoutGAN(object):\n",
    "    def __init__(self, geometric_dim=2, n_class=1, batch_size=64, n_component=128, layout_dim=(28, 28), d_lr=1e-5, g_lr=1.e-5, update_ratio=2, clip_value=0.08568, dataset_name='default', dataset_path='./data/pre_data_cls.npy', checkpoint_dir=None, sample_dir=None):\n",
    "        # Initialize the LayoutGAN object with the given parameters\n",
    "        self.batch_size = batch_size  # Batch size for training\n",
    "        self.n_component = n_component  # Number of components\n",
    "        self.n_class = n_class  # Number of classes\n",
    "        self.geometric_dim = geometric_dim  # Dimensionality of geometric space\n",
    "        self.layout_dim = layout_dim  # Dimensionality of the layout\n",
    "        self.dataset_name = dataset_name  # Name of the dataset\n",
    "        self.checkpoint_dir = checkpoint_dir  # Directory to save checkpoints\n",
    "        self.data = np.load(dataset_path)  # Load the dataset from the specified path\n",
    "        self.build_model(d_lr, g_lr)  # Build the generator and discriminator models\n",
    "        self.sample_dir = sample_dir  # Directory to save generated samples\n",
    "        self.update_ratio = update_ratio  # Update ratio for generator and discriminator training\n",
    "        self.clip_value = clip_value  # Clip value for discriminator weights during training\n",
    "        epoch_step = len(self.data) // self.batch_size  # Number of steps per epoch\n",
    "        dlr = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "            1e-5, epoch_step*10, 0.1, staircase=True, name=None)  # Learning rate schedule for the discriminator\n",
    "\n",
    "    def build_model(self, dlr, g_lr):\n",
    "        self.G = self.build_generator()  # Build the generator model\n",
    "        self.D = self.build_discriminator()  # Build the discriminator model\n",
    "        self.d_opt = tf.keras.optimizers.Adam(dlr)  # Adam optimizer for the discriminator\n",
    "        self.g_opt = tf.keras.optimizers.Adam(g_lr)  # Adam optimizer for the generator\n",
    "\n",
    "\n",
    "    def step(self, real_data, noise, training=True):\n",
    "        with tf.GradientTape() as disc_tape:\n",
    "            disc_loss = self.discriminator_loss(real_data, noise)  # Compute the discriminator loss\n",
    "\n",
    "        if(training):\n",
    "            gradients_of_discriminator = disc_tape.gradient(\n",
    "                disc_loss, self.D.trainable_variables)  # Compute the gradients of discriminator variables\n",
    "            self.d_opt.apply_gradients(\n",
    "                zip(gradients_of_discriminator, self.D.trainable_variables))  # Apply gradients to update discriminator weights\n",
    "\n",
    "        for i in range(2):\n",
    "            with tf.GradientTape() as gen_tape:\n",
    "                gen_loss = self.generator_loss(noise)  # Compute the generator loss\n",
    "\n",
    "            if(training):\n",
    "                gradients_of_generator = gen_tape.gradient(\n",
    "                    gen_loss, self.G.trainable_variables)  # Compute the gradients of generator variables\n",
    "                self.g_opt.apply_gradients(\n",
    "                    zip(gradients_of_generator, self.G.trainable_variables))  # Apply gradients to update generator weights\n",
    "\n",
    "        return gen_loss, disc_loss\n",
    "\n",
    "\n",
    "    def train(self):\n",
    "        # Calculate the number of steps per epoch\n",
    "        epoch_step = len(self.data) // self.batch_size\n",
    "        \n",
    "        # Select a sample from the dataset\n",
    "        sample = self.data[0:self.batch_size]\n",
    "        sample_inputs = np.array(sample).astype(np.float32)\n",
    "        sample_inputs = sample_inputs * 28.0 / 27.0\n",
    "        \n",
    "        # Generate random noise for the sample\n",
    "        sample_z = np.random.normal(\n",
    "            0.5, 0.13, (self.batch_size, self.n_component, self.n_class, self.geometric_dim))\n",
    "        \n",
    "        # Initialize counters and lists\n",
    "        counter = 1\n",
    "        start_time = time.time()\n",
    "        d_losses = []\n",
    "        g_losses = []\n",
    "        epochs = 50\n",
    "        # Main training loop\n",
    "        for epoch in range(epochs):\n",
    "            np.random.shuffle(self.data)\n",
    "            batch_idxs = len(self.data) // self.batch_size\n",
    "\n",
    "            for idx in range(0, batch_idxs):\n",
    "                # Select a batch of images\n",
    "                batch = self.data[idx*self.batch_size:(idx+1)*self.batch_size]\n",
    "                batch_images = np.array(batch).astype(np.float32)\n",
    "\n",
    "                # Preprocess batch images\n",
    "                batch_images = batch_images * 28.0 / 27.0\n",
    "                \n",
    "                # Generate random noise for the batch\n",
    "                batch_z = np.random.normal(\n",
    "                    0.5, 0.13, (self.batch_size, self.n_component, self.n_class, self.geometric_dim))\n",
    "                \n",
    "                # Perform one step of training\n",
    "                g_loss, d_loss = self.step(batch_images, batch_z)\n",
    "                counter += 1\n",
    "                \n",
    "                # Print progress and losses every 10 steps\n",
    "                if np.mod(counter, 10) == 0:\n",
    "                    print(\"Epoch: [%2d] [%4d/%4d] time: %4.4f, d_loss: %.4f, g_loss: %.4f\"\n",
    "                          % (epoch, idx, batch_idxs, time.time()-start_time, d_loss, g_loss))\n",
    "\n",
    "                # Generate and save samples every 1 step\n",
    "                if np.mod(counter, 1) == 0:\n",
    "\n",
    "                # Generate samples using the generator network\n",
    "                    samples = self.G(sample_z)\n",
    "                \n",
    "                # Perform a forward pass through the discriminator and generator networks\n",
    "                    g_loss, d_loss = self.step(sample_inputs, sample_z, training=False)\n",
    "                \n",
    "                # Reshape the generated samples\n",
    "                    samples = np.reshape(samples, (64, 128, 2))\n",
    "\n",
    "                    # Scale the samples to the desired range\n",
    "                    samples = 27.0 * samples\n",
    "\n",
    "                    # Create an empty image array to store the rendered layouts\n",
    "                    img_all = np.zeros((64, self.layout_dim[0], self.layout_dim[1], 3), dtype=np.uint8)\n",
    "\n",
    "                    # Render the layouts for each sample\n",
    "                    rendered_layout = self.D.render(samples, self.layout_dim[0], self.layout_dim[1])\n",
    "\n",
    "                    # Create a list to store individual images\n",
    "                    img_list = []\n",
    "\n",
    "                    # Process each sample individually\n",
    "                    for img_ind in range(64):\n",
    "                        # Extract the points from the sample\n",
    "                        pointset = np.rint(samples[img_ind, :, :]).astype(np.int)\n",
    "\n",
    "                        # Remove rows with all zero values\n",
    "                        pointset = pointset[~(pointset == 0).all(1)]\n",
    "\n",
    "                        # Create an empty image\n",
    "                        img = np.zeros((28, 28), dtype=np.float32)\n",
    "\n",
    "                        # Set the corresponding points to white (255)\n",
    "                        img[pointset[:, 0], pointset[:, 1]] = 255\n",
    "\n",
    "                        # Normalize the image and convert to grayscale\n",
    "                        img_list.append(img/255)\n",
    "                        img = Image.fromarray(img.astype('uint8'), 'L')\n",
    "\n",
    "                        # Convert the grayscale image to RGB and store in the image array\n",
    "                        img_all[img_ind, :, :, :] = np.array(img.convert('RGB'))\n",
    "\n",
    "                    # Merge the individual images into a single image grid\n",
    "                    img_all = np.squeeze(merge(img_all, image_manifold_size(samples.shape[0])))\n",
    "\n",
    "                    # Save the generated image\n",
    "                    plt.imsave('{}/train_{:02d}_{:04d}.jpg'.format(self.sample_dir, epoch, idx), np.array(img_all, dtype=np.uint8))\n",
    "\n",
    "                    # Print the losses every 10 steps\n",
    "                    if idx % 10 == 0:\n",
    "                        print(\"[Sample] d_loss: %.8f, g_loss: %.8f\" % (d_loss, g_loss))\n",
    "                        d_losses.append(d_loss)\n",
    "                        g_losses.append(g_loss)\n",
    "\n",
    "        # Plot the losses\n",
    "        plot_losses(d_losses, g_losses)\n",
    "\n",
    "    def render(self):\n",
    "    # Placeholder function, currently does nothing\n",
    "        pass\n",
    "\n",
    "    def build_discriminator(self):\n",
    "        # Build and return the discriminator network\n",
    "        return Discriminator(layout_dim=self.layout_dim, render=layout_point)\n",
    "\n",
    "    def build_generator(self):\n",
    "        # Build and return the generator network\n",
    "        return Generator(n_filters=512, output_dim=self.geometric_dim, n_component=self.n_component, n_class=self.n_class)\n",
    "\n",
    "    def gradient_penalty(self, real, fake):\n",
    "        # Calculate the gradient penalty term for the WGAN-GP loss\n",
    "        alpha = tf.random.uniform(shape=[real.shape[0], 1, 1], minval=0.0, maxval=1.)\n",
    "        \n",
    "        # Interpolate between real and fake samples\n",
    "        interpolated = alpha * real + (1 - alpha) * fake\n",
    "        \n",
    "        with tf.GradientTape() as tape_p:\n",
    "            # Watch the interpolated samples for gradient calculation\n",
    "            tape_p.watch(interpolated)\n",
    "            \n",
    "            # Compute the discriminator output logits for interpolated samples\n",
    "            logit = self.D(interpolated)\n",
    "\n",
    "        # Compute the gradient of the logits with respect to the interpolated samples\n",
    "        grad = tape_p.gradient(logit, interpolated)\n",
    "        \n",
    "        # Compute the L2 norm of the gradients\n",
    "        grad_norm = tf.norm(tf.reshape(grad, (real.shape[0], -1)), axis=1)\n",
    "        \n",
    "        # Compute the gradient penalty term as the squared difference between the norm and 1\n",
    "        return 10 * tf.reduce_mean(tf.square(grad_norm - 1.))\n",
    "\n",
    "\n",
    "    def generator_loss(self, z):\n",
    "        # Generate samples using the generator\n",
    "        x = self.G(z, training=True)\n",
    "        \n",
    "        # Compute the discriminator output logits for the generated samples\n",
    "        fake_score = self.D(x, training=True)\n",
    "        \n",
    "        # Compute the generator loss using the sigmoid cross-entropy loss\n",
    "        g_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "            logits=fake_score, labels=tf.ones_like(tf.sigmoid(fake_score))))\n",
    "        \n",
    "        return g_loss\n",
    "\n",
    "\n",
    "    def discriminator_loss(self, x, z):\n",
    "        # Generate samples using the generator\n",
    "        x_fake = self.G(z, training=True)\n",
    "        \n",
    "        # Compute the discriminator output logits for the real and generated samples\n",
    "        true_score = self.D(x, training=True)\n",
    "        fake_score = self.D(x_fake, training=True)\n",
    "        \n",
    "        # Compute the discriminator loss using the sigmoid cross-entropy loss\n",
    "        d_loss_real = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "            logits=true_score, labels=tf.ones_like(tf.sigmoid(true_score))))\n",
    "        d_loss_fake = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "            logits=fake_score, labels=tf.zeros_like(tf.sigmoid(fake_score))))\n",
    "        \n",
    "        # Compute the total discriminator loss as the sum of real and fake losses\n",
    "        d_loss = d_loss_real + d_loss_fake\n",
    "        \n",
    "        return d_loss\n",
    "batch_size = 64\n",
    "n_component = 128\n",
    "n_class = 1\n",
    "geometric_dim = 2\n",
    "\n",
    "# Specify the directory path to save the generated samples\n",
    "sample_dir = \"C:/Users/jay rana/downloads/samples/Mnist3\"\n",
    "\n",
    "# Create an instance of the LayoutGAN class with the specified parameters\n",
    "gan = LayoutGAN(\n",
    "    batch_size=batch_size,\n",
    "    n_component=n_component,\n",
    "    n_class=n_class,\n",
    "    geometric_dim=geometric_dim,\n",
    "    sample_dir=sample_dir,\n",
    "    dataset_path=\"C:/Users/jay rana/downloads/data/MNIST.npy\")\n",
    "# Start the training process\n",
    "gan.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "053193e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1abcea1a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
